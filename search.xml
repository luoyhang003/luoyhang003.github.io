<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[coda-introduction]]></title>
    <url>%2F2020%2F02%2F03%2Fcoda-introduction%2F</url>
    <content type="text"><![CDATA[[TOC] Coda 是什么#协议思路 前置知识协议 Keyword具体内容实现思路]]></content>
      <tags>
        <tag>技术</tag>
        <tag>区块链</tag>
        <tag>Coda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TEE 可信执行环境 Intel SGX：环境搭建（Ubuntu）]]></title>
    <url>%2F2019%2F12%2F05%2Fintel-sgx-env-setup%2F</url>
    <content type="text"><![CDATA[本文介绍了如何在 Ubuntu 上安装 Intel SGX SDK。SGX 全称 Intel Software Guard Extensions，是 Intel 在其 CPU 体系下的扩展，用于增强软件的安全性，用于可信计算 TEE。 本文所使用环境： 1操作系统：Ubuntu 16.04 LTS 按照如下步骤执行即可完成环境搭建： 执行： 123sudo apt-get updatesudo apt-get install libssl-dev libcurl4-openssl-dev libprotobuf-devsudo apt-get install build-essential python 下载 Intel SGX 驱动并安装： 1234wget https://download.01.org/intel-sgx/sgx-linux/2.7.1/distro/ubuntu16.04-server/sgx_linux_x64_driver_2.6.0_4f5bb63.binchmod +x sgx_linux_x64_driver_2.6.0_4f5bb63.binsudo ./sgx_linux_x64_driver_2.6.0_4f5bb63.binsudo reboot 下载 Intel SGX PSW 并安装： 12wget https://download.01.org/intel-sgx/sgx-linux/2.7.1/distro/ubuntu16.04-server/libsgx-enclave-common_2.7.101.3-xenial1_amd64.debsudo dpkg -i ./libsgx-enclave-common_2.7.101.3-xenial1_amd64.deb 下载并安装 Intel SGX SDK： 123wget https://download.01.org/intel-sgx/sgx-linux/2.7.1/distro/ubuntu16.04-server/sgx_linux_x64_sdk_2.7.101.3.binchmod +x ./sgx_linux_x64_sdk_2.7.101.3.bin./sgx_linux_x64_sdk_2.7.101.3.bin 安装过程中可以手动输入 SDK 要安装到的目标位置 添加环境变量，第 4 步结束会输出一行命令，执行： 1source /path/to/sgxsdk/environment 至此环境就已经搭建好了，现在我们来运行一下实例程序： 切换目录 1cd /path/to/sgxsdk/SampleCode/SampleEnclave 编辑一下 Makefile： 12345678# Intel SGX SDK 的安装位置SGX_SDK ?= /home/luoyhang003/SGX/sgxsdk# 运行类型：HW 真实环境；SIM 模拟器环境SGX_MODE ?= SIM# 运行架构：仅支持 64 位SGX_ARCH ?= x64# 是否为：Debug 调试模式SGX_DEBUG ?= 1 编译： 1sudo make 运行： 1./app 运行结果： 1234Checksum(0x0x7fff2aa60d00, 100) = 0xfffd4143Info: executing thread synchronization, please wait... Info: SampleEnclave successfully returned.Enter a character before exit ... 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>tee</tag>
        <tag>Intel SGX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何将 FIBJS 脚本打包成 exe 可执行文件]]></title>
    <url>%2F2019%2F11%2F25%2Ffibjs-wrapper%2F</url>
    <content type="text"><![CDATA[本文将会介绍如何将 FIBJS 脚本打包成Windows 上的 exe 可执行文件。 FIBJS 简介！Start it！FIBJS 是一个主要为 Web 后端开发而设计的应用服务器开发框架，它建立在 Google v8 JavaScript 引擎基础上，并且选择了和传统的 callback 不同的并发解决方案。fibjs 利用 fiber 在框架层隔离了异步调用带来的业务复杂性，极大降低了开发难度，并减少因为用户空间频繁异步处理带来的性能问题。FIBJS 的创始人为国内知名程序员@响马老师。 脚本实例！Write it！我们先从写一个简单的 FIBJS 脚本开始，然后将该脚本通过打包工具打包成 EXE 可执行文件。 先来创建一个文件 index.js，脚本内容如下： 123456789let coroutine = require('coroutine');let input = console.readLine("Please input something: ");console.log("What you just typed is: ", input);console.notice("This program will exit in 5 secends...");coroutine.sleep(5000); 这段脚本会将你输入的内容显示在屏幕上，并且将会于 5 秒后自动退出。 如果你使用 fibjs 直接执行上述脚本，你会得到： 1234$ fibjs index.jsPlease input something: 1What you just typed is: 1This program will exit in 10 secends... 开始打包！Build it！现在我们会将上述脚本打包成为Windows 上的 EXE 可执行文件。 首先，我们需要如下这段打包代码(wrap.js)： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123var Fs = require("fs");var Path = require("path");var Process = require("process");var Zip = require('zip');var Io = require("io");var Json = require('json');var Os = require("os");var LOCALCWD = Process.cwd(); //当前工作目录var IGNOREFILES = [".gitignore", "/.git/", ".db", ".idea", ".log", "fibjs.exe", "/build/", "fib-jsToZip.js"]; //默认忽略文件及文件夹function isFileBelong(fileList = [], path) &#123; return fileList.some(function (item) &#123; return path.indexOf(item) !== -1; &#125;);&#125;function isFileMatchRegex(path, regex) &#123; return path.match(regex);&#125;function buildExe(from, to, memoryStream) &#123; memoryStream.rewind(); if (Fs.exists(to)) &#123; Fs.unlink(to); &#125; Fs.copy(from, to); //fibjs.exe Fs.appendFile(to, memoryStream.readAll()); //append js&#125;// 路径存在返回true 否则警告返回falsefunction configCorrect(project) &#123; let pathArray = project.FibjsPath !== undefined ? [project.Location, project.Output, project.FibjsPath] : [project.Location, project.Output]; for (let i = 0; i &lt; pathArray.length; i++) &#123; let path = pathArray[i]; if (!Fs.exists(path)) &#123; Fs.mkdir(path); &#125; &#125;&#125;/** * Pack up projects * @param &#123;Object&#125; packConfig * @return &#123;Array&#125; outFullPathArray */function buildPack(packConfig) &#123; var projects = packConfig.Projects; var projCount = 0; var outFullPathArray = []; var systemExePath = Process.execPath; //fibjs 执行路径 console.notice("\n\rfib-jsToZip start ... \n\r"); projects.forEach(function (proj, index) &#123; // 检查配置信息 configCorrect(proj); proj.Version = proj.Version === undefined ? new Date().getTime() : proj.Version; //版本号 无则时间戳 let fileNameNoExten = proj.Name; //文件名(无扩展名) proj.Output = Path.fullpath(proj.Output); //输出路径（zip包所在目录） proj.OutZipFullPath = Path.join(proj.Output, fileNameNoExten + '.zip'); //zip包完整路径 proj.FibjsPath = proj.FibjsPath === undefined ? systemExePath : proj.FibjsPath; //打包fibjs.exe路径 无则打包者系统fibjs let ms = new Io.MemoryStream(); let zipFileInMem = Zip.open(ms, 'w'); let rootIndexData = "require('./" + fileNameNoExten + "/index');" // let dataIndex = "require('./&#123;0&#125;/index')();".format(fileNameNoExten); //how to format string in fibjs zipFileInMem.write(Buffer.from(rootIndexData), "index.js"); //create index.js in root path //递归将文件写入zip包 (function seekDir(path) &#123; // 忽略数组中的文件 if (isFileBelong(proj.Ignores, path)) return; // 忽略zip包 if (isFileMatchRegex(path, /.*\.zip/ig)) return; if (Fs.stat(path).isDirectory()) &#123; Fs.readdir(path).forEach(function (fd) &#123; seekDir(path + Path.sep + fd); &#125;); &#125; else &#123; zipFileInMem.write(path, Path.join(fileNameNoExten, path.replace(proj.Location, ''))); &#125; &#125;)(proj.Location); zipFileInMem.close(); let zipFile = Fs.openFile(proj.OutZipFullPath, 'w'); ms.rewind(); ms.copyTo(zipFile); zipFile.close(); console.log(" √ " + proj.Name + " &gt; \"" + proj.OutZipFullPath + "\""); // create exe if IsBuild is true if (proj.IsBuild === true) &#123; Os.platform() === 'win32' ? buildExe(proj.FibjsPath, Path.join(proj.Output, fileNameNoExten + ".exe"), ms) : buildExe(proj.FibjsPath, Path.join(proj.Output, fileNameNoExten), ms); &#125; ms.close(); projCount++; outFullPathArray.push(proj.OutZipFullPath); &#125;); console.notice("\n\r √ " + projCount + " projects packed up successfully!"); return outFullPathArray; //返回各项目zip包完整路径&#125;module.exports.buildPack = buildPack; 然后编写 build.js： 123456789101112131415161718192021var Wrapper = require(&quot;./wrap.js&quot;);var packConfig = &#123; Projects: [ &#123; Name: &quot;EXE 程序名称.exe&quot;, Location: &quot;源码路径&quot;, Output: &quot;EXE 文件生成路径&quot;, Version: &quot;程序版本号&quot;, Ignores: [ &quot;.gitignore&quot;, &quot;/.git/&quot;, ], IsBuild: true, FibjsPath: &quot;使用的 fibjs 二进制文件的路径&quot;, &#125; ],&#125;; var outFullPathArray = Wrapper.buildPack(packConfig);console.log(outFullPathArray); //返回各项目zip包完整路径 然后我们需要下载对应 Windows 版本的 FIBJS 二进制文件（下载地址：http://fibjs.org/download/index.html），置于上述配置的 FibjsPath 目录下。 执行： 1fibjs build.js 此时 Output 路径下将会生成对应的 EXE 文件。 运行！Run it！我们在 Windows 下运行该 EXE 文件： 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>fibjs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FIBOS 超级节点选举以及提案多签介绍]]></title>
    <url>%2F2019%2F07%2F25%2Ffibos-vote-intro%2F</url>
    <content type="text"><![CDATA[FIBOS 的链上治理很重要的一个操作就是投票，在 FIBOS 中是存在两种投票操作的： 用户进行投票选出超级节点； 超级节点进行投票通过/反对提案 用户投票用户执行投票可以选出超级节点，对于 FIBOS 主链来说，排名在前 21 的超级节点需要承担生产区块的责任，并且能够得到生产区块的奖励。 用户投票的具体过程如下： 用户抵押治理币获取 CPU、NET 资源 用户执行投票操作，使用 CPU、NET 资源进行投票 说明： 一个治理币所抵押的 CPU、NET 资源在投票之后表示一票 用户的每一票最多可以投给 30 个超级节点，最少需要投给 1 个节点（如果投给 0 个节点则表示撤票）（这几个参数可以修改智能合约来配置） 用户的票权不可分割，不能一部分票投给 A 另一部分投给 B，一旦执行投票表示所有票权都将投给选择的超级节点 执行撤票操作（即投票给 0 个节点）会将用户投给所有超级节点的票权撤销，不允许部分撤票 超级节点的排名由每个超级节点得到的总票数排序而来，用户执行投票后，排名前 21 的超级节点可以得到生产区块权，排名在后边的节点作为候选节点，在用户投票导致排名上升后可以获得生产区块权 超级节点的排名更新周期为 1 分钟，如果未发生用户投票行为或投票为导致排名变化则不更新 举例： 假设 A 用户拥有 1000 FO，他抵押 200 FO 获取 CPU 资源以及抵押 100 FO 获取 NET 资源，也就意味着 A 当前拥有 300 票。A 用户可以给超级节点 BP1，BP2 进行投票（一次操作就可以给多个超级节点投票），则 BP1，BP2 各获得 300 票。如果此时 A 用户再次执行投票，给 BP3，BP4 进行投票，则相当于自动执行了给 BP1，BP2 的撤票，并且给 BP3，BP4 各投了 300 票。 超级节点投票超级节点在 FIBOS 网络中承担着十分重要的社区治理的作用，更新系统合约等重要操作则需要提起多签提案，由超级节点投票通过后，才允许被执行。 这一过程主要由以下操作构成： 提案者提出多签提案（所有账户都可以提出提案） 超级节点对多签提案进行投票（FIBOS 主链只有排名前 21 的超级节点具有权限，这一参数可以修改智能合约来配置） 提案者对获取到 2/3 以上超级节点支持的提案进行执行 说明： 超级节点对于提案的投票，每一个超级节点能够投出一票 整个网络可以同时拥有多个提案 提案在未被执行之前可以由提案者进行撤销 提出提案需要消耗提案者的 RAM，提案被执行或者被撤销后占用的 RAM 会被释放 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>区块链</tag>
        <tag>fibos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FIBOS 链上资源模型介绍]]></title>
    <url>%2F2019%2F07%2F25%2Ffibos-resources-intro%2F</url>
    <content type="text"><![CDATA[FIBOS 链上的资源的获取是通过链上的治理币来完成的（对于 FIBOS 主链来说是 FO），其模型分为两种： 抵押型（CPU、NET） 消耗型（RAM） 抵押型资源（CPU、NET）在 FIBOS 中抵押型资源有两种： CPU：表示消耗的链上的计算资源，单位是毫秒（ms） NET：表示消耗的链上的网络带宽，单位是 KB 抵押型的资源需要用户在链上使用治理币来抵押才能获取资源，进行抵押后的治理币不可进行转账等操作，只有经过解抵押操作治理币才能进行正常转账，而解抵押的周期为 3 天。当然，如果进行解抵押操作，也就意味着释放了使用之前已抵押资源的权利。抵押型的资源可以自己给自己抵押，也可以给他人抵押。 链上的哪些操作需要抵押型的资源呢？ 广义上来讲，在 FIBOS 链上进行的所有操作都需要消耗抵押型资源：调用智能合约，代币转账，创建新账户，包括抵押资源本身等等。所有与链上合约的交互都需要消耗抵押型资源。 抵押型的资源会不会消耗完？ 既然是称其为『资源』就说明它是会消耗完的。但是不同于消耗型的资源，抵押型资源的『消耗』只是表示的是在一个时间段内资源被消耗完全。 举个简单的例子： 某用户 A 抵押了 2.0000 FO 的 CPU 以及 1.0000 FO 的 NET 资源，假设他抵押的这些资源足够进行 5 笔转账，在今天下午 16:00，A 执行了 5 笔转账消耗完了自己的抵押型资源。也就意味着再进行第 6 笔转账会失败。但是在 24 小时之后，A 『消耗』之后的资源会得到恢复，A又可以继续进行转账了。 当然，链上真正的抵押型资源的抵押和消耗要比上述例子要复杂一些。一个账户所拥有的抵押型资源能够真正允许他在链上执行多少操作并不是一个固定的值，这个是和全网的资源总抵押量和整个网络的拥堵程度是有关的。假设一个账户所拥有的 CPU、NET 资源是固定的，如果全网的总抵押量越高，他能执行的操作也就越少，网络越拥堵（单位时间内链上交易的多少）他能执行的操作也越少。 回到上边的例子，也就意味着： A 所拥有的 2.0000 FO 的 CPU 以及 1.0000 FO 的 NET 资源，满足他在今天下午 16:00 执行 5 笔操作，即便他什么操作也没有执行，也有可能这些资源在 18:00 的时候能够满足他执行 3 笔 或者 10 笔转账操作，而这具体取决于链的当前情况。 如果抵押型的资源全部消耗完了呢？ 如果在单位时间内的抵押型资源消耗完成，可以等待到下一个资源使用周期（24小时），之前消耗的资源达到恢复周期，从而继续使用已恢复的资源； 也可以继续使用治理币来进行抵押来换取资源。 消耗型资源（RAM）RAM 属于 FIBOS 链上的消耗型资源，主要用于链上的存储消耗。某账户使用了链上的智能合约存储空间就需要消耗该账户所拥有的 RAM。 RAM 该如何获得？ 在 FIBOS 链上，RAM 是需要使用治理币来进行购买的。FIBOS 的系统合约有一个基于 Bancor 算法的交易市场，用户可以使用治理币进行 RAM 的购买和卖出。用户可以给自己购买 RAM，也可以给其他账户购买 RAM。 哪些场景会消耗 RAM？ 某用户给未持有该币种用户的转账：例如 A 用户给 B 用户转账 FO 代币，而 B 用户并未持有 FO，则该笔转账会消耗 A 用户的 RAM。原因是在于，链上所有的持币信息是存储于智能合约的，当前链上并没有 B 用户的持币记录，A 给 B 转账需要使用合约存储来保存这一持币记录，因此需要消耗 RAM。但是，A 如果再给 B 转账就不再会消耗 RAM了，因为 B 已经拥有这部分存储，至于这部分存储存的是 100 FO 还是 10000 FO 并不会占用多余的存储； 多签提案：发起多签提案需要消耗提案者的 RAM； 调用需要占用存储的非系统智能合约； 创建新账户； …… RAM 可以被释放吗？ RAM 是可以被释放的。例如，发起多签者的多签被执行之后，或者被否决之后，该提案将不再占用智能合约的存储空间，对应的 RAM 会得到释放。该账户可以将未被使用的 RAM 在 RAM 交易市场中卖出以换回治理币。 FIBOS 的新账户创建FIBOS 的账户机制不同于比特币或者以太坊的地址，FIBOS 新账户的创建是依赖于 FIBOS 的旧账户的。也就是说，FIBOS 中每一个新账户的创建都是由已存在的账户来操作的。 已存在的旧账户需要给新创建的账户购买 RAM，抵押 CPU 和 NET 才能保证新账户能够正常进行各种链上操作。 FIBOS 的账户只能被创建，不能被销毁。 FIBOS 的超级节点投票机制FIBOS 中的超级节点（BP）是整个链上非常重要的角色，承载着区块产生，升级系统合约等责任。在 FIBOS 网络中，只有排名前 21 的超级节点具有生产区块的权利和义务，其余排名靠后的节点作为候选节点，排名上升后也会开始生产区块，生产区块是能够获得治理币的奖励的。 而超级节点的排名是由治理币的持币用户投票来决定的，而投票的票权是由用户所抵押的 CPU 和 NET 决定的。也就意味着，一个用户所抵押获得的 CPU、NET资源越多，它的票权就越大。超级节点可以获得各个用户的投票，根据总票权来决定自己在全部超级节点中的排名。]]></content>
      <tags>
        <tag>技术</tag>
        <tag>区块链</tag>
        <tag>fibos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以太坊智能合约开发 - 环境搭建]]></title>
    <url>%2F2018%2F07%2F10%2Fstarting-on-ethereum-smart-contract-env%2F</url>
    <content type="text"><![CDATA[在区块链的世界中，比特币被称为区块链1.0，以太坊进化为区块链2.0，这一跨越的实现缘于以太坊对智能合约的实现。智能合约在以太坊网络中扮演着至关重要的角色，目前ERC20代币的发行、多重签名乃至DApp的开发等都需要通过智能合约来进行实现等，因此学习智能合约的开发是很重要的。这篇文章会详细阐述该如何进行以太坊合约开发环境的搭建，以及编写第一个以太坊上的智能合约。 环境准备进行以太坊智能合约的开发需要我们有一个以太坊网络的环境，我建议使用自己搭建的私链进行测试，在自己的私链上，以太币的获取比较容易，对于以太坊私链的的搭建可以参考我的另一篇博文《【Ethereum基础实践】：以太坊测试私链的搭建》。 Remix的使用Remix是以太坊官方推荐使用的IDE，在Remix上我们可以进行合约的编写，并且还可以对以太坊环境进行集成，进行智能合约的部署与调试。 Remix有Web版本和Electron APP两个版本： Web：http://remix.ethereum.org/ Electron APP：https://github.com/horizon-games/remix-app 你可以选择Web版或者Electron版本，它们的功能没有任何差别。 安装Remixd服务由于Remix提供的是一个在线的Web环境，因此在本地不会存储你所编写的智能合约源文件，如果你希望文件能一直保存在本地，你可以安装Remixd服务。 1npm install -g remixd 启动remixd： 12# 使用绝对路径remixd -s /Users/username/path_you_store_contracts 点击Remix IDE左上方按钮连接至remixd服务： 这样就可以在本地编写智能合约了： 连接到以太坊节点在Remix IDE中，我们可以连接我们自己的以太坊节点进行测试，在控制面板的Run页面中可以配置自定义的以太坊节点，在Environment中选择Web3 Provider: 输入节点对应的IP地址和RPC端口即可进行连接： 在连接节点之后，我们可以看到私链中的各个账户的余额等信息： 这样我们就可以使用自己的以太坊私链进行智能合约的部署与测试了。 一个简单的智能合约接下来我们会编写和部署一个简单的智能合约来演示一下整个流程。 先来看一下合约的源文件代码： 1234567891011contract Demo &#123; uint256 public number = 0; function Demo(uint8 _initial) &#123; number = _initial; &#125; function add() &#123; number = number +1; &#125;&#125; 这个合约的功能是在合约中存储了一个数字number，并且提供了一个对该数字进行+1的方法add(). 我们先对源代码进行编译： 之后在Run面板点击Create进行部署： 由于该合约的构造方法中需要一个参数，来对number进行初始化，这里我填的是10，另外，在Account中需要选择部署该合约的账户（需要消耗gas），并且输入对应的密码对账户进行解锁： 待创建合约的交易广播至矿工节点并且被打包至区块中之后，我们就可以在面板中看到相关的合约信息了： 点击number可以查看当前的值： 点击add可以触发对应方法（该操作是一个transaction，需要消耗gas），number的值会进行+1： 我们在控制台中可以看到该交易的详细信息： 至此，我们就完成了一个简单的智能合约的部署。 部署一个ERC20的合约在这部分，我们会以以太坊上的EOS代币合约为例，进行ERC20代币的合约部署与测试。 首先，我们要获取EOS智能合约的源代码，可以在etherscan上获取对应源码： https://etherscan.io/address/0x86fa049857e0209aa7d9e616f7eb3b3b78ecfdb0#code 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376contract DSNote &#123; event LogNote( bytes4 indexed sig, address indexed guy, bytes32 indexed foo, bytes32 indexed bar, uint wad, bytes fax ) anonymous; modifier note &#123; bytes32 foo; bytes32 bar; assembly &#123; foo := calldataload(4) bar := calldataload(36) &#125; LogNote(msg.sig, msg.sender, foo, bar, msg.value, msg.data); _; &#125;&#125;contract DSAuthority &#123; function canCall( address src, address dst, bytes4 sig ) constant returns (bool);&#125;contract DSAuthEvents &#123; event LogSetAuthority (address indexed authority); event LogSetOwner (address indexed owner);&#125;contract DSAuth is DSAuthEvents &#123; DSAuthority public authority; address public owner; function DSAuth() &#123; owner = msg.sender; LogSetOwner(msg.sender); &#125; function setOwner(address owner_) auth &#123; owner = owner_; LogSetOwner(owner); &#125; function setAuthority(DSAuthority authority_) auth &#123; authority = authority_; LogSetAuthority(authority); &#125; modifier auth &#123; assert(isAuthorized(msg.sender, msg.sig)); _; &#125; modifier authorized(bytes4 sig) &#123; assert(isAuthorized(msg.sender, sig)); _; &#125; function isAuthorized(address src, bytes4 sig) internal returns (bool) &#123; if (src == address(this)) &#123; return true; &#125; else if (src == owner) &#123; return true; &#125; else if (authority == DSAuthority(0)) &#123; return false; &#125; else &#123; return authority.canCall(src, this, sig); &#125; &#125; function assert(bool x) internal &#123; if (!x) throw; &#125;&#125;contract DSStop is DSAuth, DSNote &#123; bool public stopped; modifier stoppable &#123; assert (!stopped); _; &#125; function stop() auth note &#123; stopped = true; &#125; function start() auth note &#123; stopped = false; &#125;&#125;contract DSMath &#123; /* standard uint256 functions */ function add(uint256 x, uint256 y) constant internal returns (uint256 z) &#123; assert((z = x + y) &gt;= x); &#125; function sub(uint256 x, uint256 y) constant internal returns (uint256 z) &#123; assert((z = x - y) &lt;= x); &#125; function mul(uint256 x, uint256 y) constant internal returns (uint256 z) &#123; assert((z = x * y) &gt;= x); &#125; function div(uint256 x, uint256 y) constant internal returns (uint256 z) &#123; z = x / y; &#125; function min(uint256 x, uint256 y) constant internal returns (uint256 z) &#123; return x &lt;= y ? x : y; &#125; function max(uint256 x, uint256 y) constant internal returns (uint256 z) &#123; return x &gt;= y ? x : y; &#125; /* uint128 functions (h is for half) */ function hadd(uint128 x, uint128 y) constant internal returns (uint128 z) &#123; assert((z = x + y) &gt;= x); &#125; function hsub(uint128 x, uint128 y) constant internal returns (uint128 z) &#123; assert((z = x - y) &lt;= x); &#125; function hmul(uint128 x, uint128 y) constant internal returns (uint128 z) &#123; assert((z = x * y) &gt;= x); &#125; function hdiv(uint128 x, uint128 y) constant internal returns (uint128 z) &#123; z = x / y; &#125; function hmin(uint128 x, uint128 y) constant internal returns (uint128 z) &#123; return x &lt;= y ? x : y; &#125; function hmax(uint128 x, uint128 y) constant internal returns (uint128 z) &#123; return x &gt;= y ? x : y; &#125; /* int256 functions */ function imin(int256 x, int256 y) constant internal returns (int256 z) &#123; return x &lt;= y ? x : y; &#125; function imax(int256 x, int256 y) constant internal returns (int256 z) &#123; return x &gt;= y ? x : y; &#125; /* WAD math */ uint128 constant WAD = 10 ** 18; function wadd(uint128 x, uint128 y) constant internal returns (uint128) &#123; return hadd(x, y); &#125; function wsub(uint128 x, uint128 y) constant internal returns (uint128) &#123; return hsub(x, y); &#125; function wmul(uint128 x, uint128 y) constant internal returns (uint128 z) &#123; z = cast((uint256(x) * y + WAD / 2) / WAD); &#125; function wdiv(uint128 x, uint128 y) constant internal returns (uint128 z) &#123; z = cast((uint256(x) * WAD + y / 2) / y); &#125; function wmin(uint128 x, uint128 y) constant internal returns (uint128) &#123; return hmin(x, y); &#125; function wmax(uint128 x, uint128 y) constant internal returns (uint128) &#123; return hmax(x, y); &#125; /* RAY math */ uint128 constant RAY = 10 ** 27; function radd(uint128 x, uint128 y) constant internal returns (uint128) &#123; return hadd(x, y); &#125; function rsub(uint128 x, uint128 y) constant internal returns (uint128) &#123; return hsub(x, y); &#125; function rmul(uint128 x, uint128 y) constant internal returns (uint128 z) &#123; z = cast((uint256(x) * y + RAY / 2) / RAY); &#125; function rdiv(uint128 x, uint128 y) constant internal returns (uint128 z) &#123; z = cast((uint256(x) * RAY + y / 2) / y); &#125; function rpow(uint128 x, uint64 n) constant internal returns (uint128 z) &#123; // This famous algorithm is called "exponentiation by squaring" // and calculates x^n with x as fixed-point and n as regular unsigned. // // It's O(log n), instead of O(n) for naive repeated multiplication. // // These facts are why it works: // // If n is even, then x^n = (x^2)^(n/2). // If n is odd, then x^n = x * x^(n-1), // and applying the equation for even x gives // x^n = x * (x^2)^((n-1) / 2). // // Also, EVM division is flooring and // floor[(n-1) / 2] = floor[n / 2]. z = n % 2 != 0 ? x : RAY; for (n /= 2; n != 0; n /= 2) &#123; x = rmul(x, x); if (n % 2 != 0) &#123; z = rmul(z, x); &#125; &#125; &#125; function rmin(uint128 x, uint128 y) constant internal returns (uint128) &#123; return hmin(x, y); &#125; function rmax(uint128 x, uint128 y) constant internal returns (uint128) &#123; return hmax(x, y); &#125; function cast(uint256 x) constant internal returns (uint128 z) &#123; assert((z = uint128(x)) == x); &#125;&#125;contract ERC20 &#123; function totalSupply() constant returns (uint supply); function balanceOf( address who ) constant returns (uint value); function allowance( address owner, address spender ) constant returns (uint _allowance); function transfer( address to, uint value) returns (bool ok); function transferFrom( address from, address to, uint value) returns (bool ok); function approve( address spender, uint value ) returns (bool ok); event Transfer( address indexed from, address indexed to, uint value); event Approval( address indexed owner, address indexed spender, uint value);&#125;contract DSTokenBase is ERC20, DSMath &#123; uint256 _supply; mapping (address =&gt; uint256) _balances; mapping (address =&gt; mapping (address =&gt; uint256)) _approvals; function DSTokenBase(uint256 supply) &#123; _balances[msg.sender] = supply; _supply = supply; &#125; function totalSupply() constant returns (uint256) &#123; return _supply; &#125; function balanceOf(address src) constant returns (uint256) &#123; return _balances[src]; &#125; function allowance(address src, address guy) constant returns (uint256) &#123; return _approvals[src][guy]; &#125; function transfer(address dst, uint wad) returns (bool) &#123; assert(_balances[msg.sender] &gt;= wad); _balances[msg.sender] = sub(_balances[msg.sender], wad); _balances[dst] = add(_balances[dst], wad); Transfer(msg.sender, dst, wad); return true; &#125; function transferFrom(address src, address dst, uint wad) returns (bool) &#123; assert(_balances[src] &gt;= wad); assert(_approvals[src][msg.sender] &gt;= wad); _approvals[src][msg.sender] = sub(_approvals[src][msg.sender], wad); _balances[src] = sub(_balances[src], wad); _balances[dst] = add(_balances[dst], wad); Transfer(src, dst, wad); return true; &#125; function approve(address guy, uint256 wad) returns (bool) &#123; _approvals[msg.sender][guy] = wad; Approval(msg.sender, guy, wad); return true; &#125;&#125;contract DSToken is DSTokenBase(0), DSStop &#123; bytes32 public symbol; uint256 public decimals = 18; // standard token precision. override to customize function DSToken(bytes32 symbol_) &#123; symbol = symbol_; &#125; function transfer(address dst, uint wad) stoppable note returns (bool) &#123; return super.transfer(dst, wad); &#125; function transferFrom( address src, address dst, uint wad ) stoppable note returns (bool) &#123; return super.transferFrom(src, dst, wad); &#125; function approve(address guy, uint wad) stoppable note returns (bool) &#123; return super.approve(guy, wad); &#125; function push(address dst, uint128 wad) returns (bool) &#123; return transfer(dst, wad); &#125; function pull(address src, uint128 wad) returns (bool) &#123; return transferFrom(src, msg.sender, wad); &#125; function mint(uint128 wad) auth stoppable note &#123; _balances[msg.sender] = add(_balances[msg.sender], wad); _supply = add(_supply, wad); &#125; function burn(uint128 wad) auth stoppable note &#123; _balances[msg.sender] = sub(_balances[msg.sender], wad); _supply = sub(_supply, wad); &#125; // Optional token name bytes32 public name = ""; function setName(bytes32 name_) auth &#123; name = name_; &#125;&#125; 使用上述相同的部署方法，我们就可以看到EOS合约中提供的相关方法，并且开始测试了： 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Ethereum</tag>
        <tag>以太坊</tag>
        <tag>ETH</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以太坊区块的生成]]></title>
    <url>%2F2018%2F05%2F02%2Feth-basis-block-concepts%2F</url>
    <content type="text"><![CDATA[从名称上来看，区块（Block）也是区块链系统中的核心概念，区块链简单来说就是将区块联结成链，区块中保存的是打包成的各种区块信息。在以太坊中，区块中保存的是各种交易信息。一个区块中可以包含若干个交易，也可以不包含任何交易。这篇文章主要会阐释以下问题： 区块是什么？包含了哪些信息？ 区块是如何被打包的，写入到区块链的？ 一个区块的大小是多少？可以包含多少交易？ 多长时间可以产生一个区块？ 为什么有的区块中没有交易？ 以太坊区块以太坊的区块中保存了许多信息，最主要的有该区块的区块信息以及该区块中所包含的交易的信息。我们可以在go-ethereum中的源码看到区块的结构体定义： 12345678910111213141516171819// Block represents an entire block in the Ethereum blockchain.type Block struct &#123; header *Header uncles []*Header transactions Transactions // caches hash atomic.Value size atomic.Value // Td is used by package core to store the total difficulty // of the chain up to and including the block. td *big.Int // These fields are used by package eth to track // inter-peer block relay. ReceivedAt time.Time ReceivedFrom interface&#123;&#125;&#125; 其中有下列主要属性： header：存储的是该区块的信息（结构体为Header） uncles：存储的是该区块所包含的叔块（uncle block）的信息，关于叔块的相关内容将会在之后的文章中进行讨论 其中Header结构体中是一个区块中所包含的信息，定义如下： 123456789101112131415161718// Header represents a block header in the Ethereum blockchain.type Header struct &#123; ParentHash common.Hash `json:"parentHash" gencodec:"required"` UncleHash common.Hash `json:"sha3Uncles" gencodec:"required"` Coinbase common.Address `json:"miner" gencodec:"required"` Root common.Hash `json:"stateRoot" gencodec:"required"` TxHash common.Hash `json:"transactionsRoot" gencodec:"required"` ReceiptHash common.Hash `json:"receiptsRoot" gencodec:"required"` Bloom Bloom `json:"logsBloom" gencodec:"required"` Difficulty *big.Int `json:"difficulty" gencodec:"required"` Number *big.Int `json:"number" gencodec:"required"` GasLimit uint64 `json:"gasLimit" gencodec:"required"` GasUsed uint64 `json:"gasUsed" gencodec:"required"` Time *big.Int `json:"timestamp" gencodec:"required"` Extra []byte `json:"extraData" gencodec:"required"` MixDigest common.Hash `json:"mixHash" gencodec:"required"` Nonce BlockNonce `json:"nonce" gencodec:"required"`&#125; 从代码中我们可以看到一个区块中包含了如下信息： ParentHash：该区块的父区块的Hash值 UncleHash：该区块的叔区块的Hash值 Coinbase：打包该区块矿工的地址，矿工费和发现区块的奖励会被发送到该地址 Root：Merkle树根节点的Hash，以太坊中的交易状态信息是以Merkle状态树的形式进行存储的，Root是该状态树的根节点的Hash值 TxHash：保存该区块中交易Merkle树的根节点的Hash值 ReceiptHash：一个区块中所包含的交易中的接收者也是以Merkle树的形式进行存储的，该值是该Merkle树根节点的Hash值 Bloom：用于索引与搜索的结构（详见Tips） Difficult：该区块的难度 Number：所有祖先区块的数量（也就是区块高度） GasLimit：该区块的gas上限 GasUsed：该区块使用的gas Time：区块开始打包的时间 Extra：区块相关的附加信息 MixDigest：该哈希值与Nonce值一起能够证明在该区块上已经进行了足够的计算（用于验证该区块挖矿成功与否的Hash值） Nonce：该哈希值与MixDigest值一起能够证明在该区块上已经进行了足够的计算（用于验证该区块挖矿成功与否的Hash值） Tips：Bloom的作用以太坊在设计的时候希望能够对Event能够进行快速的检索，并且在区块链上进行存储的成本是很高的，我们还希望不要有太多的重复数据（交易列表、交易产生的记录等）。Bloom就是用来解决这个问题的。在一个区块生成的时候，该区块中包含的所有的合约相关的地址以及所有交易产生的记录的索引都会被记录至Bloom中，以便之后的查找与索引。这些信息会被保存在Header结构中（Bloom字段），不保存在区块的数据段中，这样可以节省空间。当一个应用层的应用程序想要对某个合约中的数据进行检索时，它只需要在区块中的Header信息中进行查找，查看该区块中是否包含该合约相关的记录。 MixDigest和Nonce是如何进行验证的我们知道以太坊目前采用的挖矿算法是PoW（Proof of Work），简单的来说，这种方法就像是猜数字，比如说在100000个数字中有5个可行解，猜到的就算是挖到了矿，这种算法要求猜到解的难度是可以调整的，一般难度会很大，不那么容易被猜到，但是验证这个解是否正确是很容易的。Nonce值其实就是矿工猜到的解，验证过程如下：经过预处理的Header与Nonce值做一个类似SHA3的运算产生一个128B的Mix（Mix0），这个值用于计算从DAG（以太坊用于挖矿算法的伪随机数据集，目前大小大约为2GB以上）中取出哪一页的数据（大小为128B），取出的DAG的页与Mix会进行一个以太坊特定的mixing方法，会生成下一个Mix（Mix1），这个过程会重复64次，直到得到Mix64。Mix64会被处理成为32B的数据，它被称为Mix Digest。Mix Digest会与一个叫做Target Threshold的值（相当于解集）进行比较，如果Mix Digest的值小于Threshold就认为挖矿成功，如果大于，表示失败。 区块的打包过程交易在生成之后会被以太坊节点广播至网络，交易会被放到交易池（txPool）中，由矿工对交易进行验证然后放到正在打包的区块中，当选择好了区块中所要包含的交易之后，矿工就开始了挖矿过程（PoW），当矿工在挖矿竞争中取得胜利之后，该矿工的区块数据就可以被写入到区块链中。 交易池中有许多交易存在，矿工是如何从交易池中选择交易的呢？其实交易池会对各个交易进行排序，提供的矿工费（gas）高的交易会排在前面。因此，矿工会优先选择奖励高的交易打包至区块。这也就是为什么gas值高的交易会被处理的较快的原因。 区块的容量以太坊的区块大小不同于比特币的区块大小，目前比特币的区块大小是1MB。因此，比特币一个区块中能够包含多少交易是取决于区块的大小以及每个交易的大小，一个区块中所有交易的总和不能超过区块的大小。但是，以太坊并没有固定的区块大小的限制，但是这样的话是如何确定一个区块中能够包含多少交易的呢？ 以太坊的区块中有一个gasLimit，它表示的是该区块中所能包含的交易的gas值的上限。以太坊上的每一笔交易都会消耗gas值，一个区块中所包含的所有交易的gas总和不能超过区块的gasLimit。因此，通过这种方式我们就能够控制一个区块中的交易数量。 如果交易池中没有待处理的交易，那么矿工会直接进入挖矿过程，依旧会得到挖矿奖励（5 Ether），区块依旧会被打包和广播，只不过该区块中不会包含交易。 区块时间在比特币中，大约10分钟会产生一个区块。根据以太坊白皮书所写，以太坊大约12秒回产生一个区块。这个时间就是区块时间。区块时间是和挖矿难度相关的，比特币的难度调整是有对应算法的，算法会把区块时间维持在10分钟左右。以太坊也有对应的难度调整算法。 我们可以在以太坊的源码中找到计算难度的代码： 1234567891011121314// CalcDifficulty is the difficulty adjustment algorithm. It returns// the difficulty that a new block should have when created at time// given the parent block's time and difficulty.func CalcDifficulty(config *params.ChainConfig, time uint64, parent *types.Header) *big.Int &#123; next := new(big.Int).Add(parent.Number, big1) switch &#123; case config.IsByzantium(next): return calcDifficultyByzantium(time, parent) case config.IsHomestead(next): return calcDifficultyHomestead(time, parent) default: return calcDifficultyFrontier(time, parent) &#125;&#125; 我们可以看到有三个版本的代码，分别应用于不同版本的以太坊，我们先来看一下Homestead版本中的代码：我们可以看到有三个版本的代码，分别应用于不同版本的以太坊，我们先来看一下Homestead版本中的代码： 12345678910111213141516171819202122232425262728293031func calcDifficultyHomestead(time uint64, parent *types.Header) *big.Int &#123; bigTime := new(big.Int).SetUint64(time) bigParentTime := new(big.Int).Set(parent.Time) x := new(big.Int) y := new(big.Int) x.Sub(bigTime, bigParentTime) x.Div(x, big10) x.Sub(big1, x) if x.Cmp(bigMinus99) &lt; 0 &#123; x.Set(bigMinus99) &#125; y.Div(parent.Difficulty, params.DifficultyBoundDivisor) x.Mul(y, x) x.Add(parent.Difficulty, x) if x.Cmp(params.MinimumDifficulty) &lt; 0 &#123; x.Set(params.MinimumDifficulty) &#125; periodCount := new(big.Int).Add(parent.Number, big1) periodCount.Div(periodCount, expDiffPeriod) if periodCount.Cmp(big1) &gt; 0 &#123; y.Sub(periodCount, big2) y.Exp(big2, y, nil) x.Add(x, y) &#125; return x&#125; 从代码中我们可以看到，以太坊的难度值是基于当前区块的出块时间，对之后的难度值进行调整的。 具体公式如下： 1diff = (parent_diff +(parent_diff / 2048 * max(1 - (block_timestamp - parent_timestamp) // 10, -99))) + 2^(periodCount - 2) 其中2^(periodCount - 2)又称”难度炸弹“，计算公式如下： 12^(periodCount - 2) = 2**((block_number // expDiffPeriod) - 2) 目前最新的难度调整算法为Byzantium算法： 1234567891011121314151617181920212223242526272829303132333435363738func calcDifficultyByzantium(time uint64, parent *types.Header) *big.Int &#123; bigTime := new(big.Int).SetUint64(time) bigParentTime := new(big.Int).Set(parent.Time) x := new(big.Int) y := new(big.Int) x.Sub(bigTime, bigParentTime) x.Div(x, big9) if parent.UncleHash == types.EmptyUncleHash &#123; x.Sub(big1, x) &#125; else &#123; x.Sub(big2, x) &#125; if x.Cmp(bigMinus99) &lt; 0 &#123; x.Set(bigMinus99) &#125; y.Div(parent.Difficulty, params.DifficultyBoundDivisor) x.Mul(y, x) x.Add(parent.Difficulty, x) if x.Cmp(params.MinimumDifficulty) &lt; 0 &#123; x.Set(params.MinimumDifficulty) &#125; fakeBlockNumber := new(big.Int) if parent.Number.Cmp(big2999999) &gt;= 0 &#123; fakeBlockNumber = fakeBlockNumber.Sub(parent.Number, big2999999) // Note, parent is 1 less than the actual block number &#125; periodCount := fakeBlockNumber periodCount.Div(periodCount, expDiffPeriod) if periodCount.Cmp(big1) &gt; 0 &#123; y.Sub(periodCount, big2) y.Exp(big2, y, nil) x.Add(x, y) &#125; return x&#125; 算法如下： 1diff = (parent_diff + (parent_diff / 2048 * max((2 if len(parent.uncles) else 1) - ((timestamp - parent.timestamp) // 9), -99))) + 2^(periodCount - 2) 以太坊中定义了一个难度的最小值MinimumDifficulty，定义于protocol_params.go源文件中，值为131072，这个值是以太坊中难度的最小值，也是创世块的难度值。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Ethereum</tag>
        <tag>以太坊</tag>
        <tag>ETH</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Ethereum基础】：交易的生命周期]]></title>
    <url>%2F2018%2F04%2F20%2Feth-basis-transaction-life-cycle%2F</url>
    <content type="text"><![CDATA[大体上说，一个交易的生命周期要经历以下几个过程： 构造一笔交易（这里的交易要包含交易双方的地址、以太币数量、时间戳、签名等信息，它是不含任何私密信息的合法交易数据） 将消息广播到网络（几乎网络中的所有节点都会收到这笔交易数据） 验证交易的合法性（生成交易的节点要首先进行验证，其它节点也要进行验证，没有经过验证的交易是不能进入到区块链网络的） 将交易写入区块链 构造一笔交易我们先用一个简单的合约作为例子来谈论一笔交易的构造过程，这个合约的作用是在区块链上存储一个数字： 12345678910111213pragma solidity ^0.4.1;contract SimpleStorage &#123; uint storedData; function set(uint x) public &#123; storedData = x; &#125; function get() public constant returns (uint) &#123; return storedData; &#125;&#125; 然后我们要构造一笔交易，该交易的内容是调用合约中的函数set(uint x)，并且传入参数1。 首先我们知道，构造一笔交易需要以下字段（具体参照《交易与消息》一文）： nonce：交易发送者的交易序列号 gasPrice：gas价格 gasLimit：消耗的gas上限 to：交易接收者的地址 value：要发送的以太币（以wei为单位） data：可选的数据域（在该例子中是必须的字段） 获取nonce通过geth控制台我们能获取到nonce值，例如： eth.getTransactionCount(eth.account[0]) gasPrice我们能够自己随意设置gas的价格，但是有可能由于gas的价格过低，导致交易没有矿工进行处理导致失效。我们可以从这个网站来获取推荐的gas价格。 gasLimit设置你能接受的该交易能够消耗的gas的最大数量。 to在该例子中，接收者的地址应该是该合约的地址 value在该例子中，不需要发送以太币，值为0 data我们需要构造该交易的数据域。 首先，我们要调用的函数是合约中的set(uint x)，根据Solidity文档^1，我们将该函数set(uint)做Keccak-256哈希^2，结果为： cccdda2cf2895862749f1c69aa9f55cf481ea82500e4eabb4e2578b36636979b 我们取其前4字节：0xcccdda2c 然后我们所传入的函数的参数是1，填充为32字节： 0000000000000000000000000000000000000000000000000000000000000001 将这两部分连接起来： 0xcccdda2c0000000000000000000000000000000000000000000000000000000000000001 这就是数据域的内容，共计36字节。 最终我们构造好的交易是这样的： 123456789txnCount = web3.eth.getTransactionCount(web3.eth.accounts[0])var rawTxn = &#123;nonce: web3.toHex(txnCount),gasPrice: web3.toHex(800000000000),gasLimit: web3.toHex(160000),to: '0xa55fe56f2a183f795fdaae3529d58b58e57ef5ed',value: web3.toHex(0),data: '0xcccdda2c0000000000000000000000000000000000000000000000000000000000000001'&#125;; 对交易进行签名接下来我们需要使用交易发送者账号的私钥对交易进行签名： 1234const privateKey = Buffer.from('你的账户私钥', 'hex')const txn = new EthereumTx(rawTxn)txn.sign(privateKey)const serializedTxn = txn.serialize() 本地对交易进行验证签名后的交易会首先提交至你的本地以太坊的节点，你的本地节点会首先对该笔交易进行验证，它会验证签名是否有效。 把交易广播至区块链网络之后，你的本地以太坊节点会将交易广播至整个网络，在广播之后会返回一个交易id，你可以通过该id查看和追踪该交易的状态和相关信息。几乎以太坊网络上的所有节点都会收到这笔交易。有一些节点会设置一个最低的gas价格，它们会忽略低于该gasPrice值的交易。 矿工节点接收到交易生成的交易需要被区块链网络中的矿工打包到区块，才能写入到区块链中。矿工会有一个待处理的交易列表，其中的交易是按交易的gasPrice进行排序的，交易的gasPrice越高，处理的优先级就越高。如果交易的gasPrice过低，有可能一直得不到矿工的处理，从而被忽略。 矿工将交易打包至区块并广播至网络矿工会取若干交易然后打包至一个区块中，一个区块中能够包含多少条交易是和区块的gasLimit有关的，所有交易的gasLimit总和不能超过区块的gasLimit。当矿工选择好要打包的交易之后，就开始了PoW（Proof of Work）挖矿过程，最先发现新的区块的矿工能够将交易打包至区块，并且获取到相应的奖励。 其它节点同步新的区块数据由于新的区块已经产生，所有的节点都需要对区块进行同步，你的交易会随着区块的同步被同步至所有节点上。 至此，一笔交易的生命周期彻底结束，它被永远的写入到了区块链中。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Ethereum</tag>
        <tag>以太坊</tag>
        <tag>ETH</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Ethereum基础】：交易和消息]]></title>
    <url>%2F2018%2F04%2F20%2Feth-basis-transaction-and-message%2F</url>
    <content type="text"><![CDATA[交易和消息是以太坊系统中很关键的两个概念，同时也是两个非常类似的概念，它们在形式上近乎相同，但是本质上却又完全不同。这篇博客会将交易（Transaction）、消息（Message）和调用（Message Call）进行介绍和区分。 交易（Transaction）是什么？交易存储了发送者要发送至以太坊网络的经过签名的信息，它其中包含了从一个账户要传递给另一个账户（或者合约）的信息。在以太坊中，有两种类型的交易：一种是能够产生消息调用的交易，另一种是能够生成新账户的交易（比如说生成合约）。 笼统的来说，一个完整有效的以太坊交易包含以下几个部分： 交易接收者 签名（用以核实交易发送者身份） value值（发送的以太币数量，以wei为单位） 可选数据域 STARTGAS值 GASPRICE值 交易中的字段根据以太坊黄皮书^1，我们知道一个交易中有以下字段： nonce：该字段表示的是交易发送者的交易序列号，它是账号的一个交易计数器，这个字段能够防止重放攻击（replay attack）。 gasPrice：gas的价格，用于计算交易费用 gasLimit：执行这笔交易所花费的gas的上限 to：交易接收者的地址或者合约的地址 value：要发送的以太币数量，以wei为单位 v, s, r：签名相关的参数，通过这三个参数可以得到发送者的公钥和地址（更详细的内容参见以太坊黄皮书附录F） 如果该交易是一个创建合约的交易，还可能包括以下字段： init：用于初始化交易的EVM（以太坊虚拟机）操作码 data：数据域（理论上数据域的大小是不受限制的） 消息（Message）是什么？信息在以太坊中是一个“虚拟”的事物，它永远不会被记录到区块链中，它是由合约发出的。从形式上看，消息很“像”交易，但是它与交易有着本质上的区别，一笔成功的交易会被永久的记录到区块链中。在以太坊中，我们可以把消息看做在EVM中的函数调用。 一般来说，一条消息会包含以下几个部分： 消息的发送者 消息的接收者 以太币的数量（以wei为单位） 可选数据域 STARTGAS GASPRICE 交易、消息与调用（Message Call）的区别以太坊黄皮书中对交易的描述为： A piece of data, signed by an External Actor. It represents either a Message or a new Autonomous Object. Transactions are recorded into each block of the blockchain.由外部参与者签名后的一段数据。它代表了一条信息或者一个新创建的自治对象(合约)。交易会被记录至区块链的区块中。 对消息的描述为： Data (as a set of bytes) and Value (specified as Ether) that is passed between two Accounts, either through the deterministic operation of an Autonomous Object or the cryptographically secure signature of the Transaction.在两个账户之间传输的数据（一组字节）和值（以太币的数量），形式是合约的确定性操作或者经过加密安全签名的交易。 对调用的描述为： The act of passing a message from one Account to another. If the destination account is associated with non-empty EVM Code, then the VM will be started with the state of said Object and the Message acted upon. If the message sender is an Autonomous Object, then the Call passes any data returned from the VM operation.从一个账户发送至另一个账户的消息的行为。如果目标账户关联着非空的EVM操作码，VM就会按照该操作码的状态进行启动。如果消息的发送者是一个自治对象，那么该调用将会传递所有返回自VM操作的数据。 具体来说，调用是对合约的本地调用，它是只读的操作并且不会消耗以太币。它能够模拟交易的行为，但是在调用结束以后，它会返回至之前的状态。交易是会被广播至整个网络的，被矿工处理验证之后会被记录至区块链的区块中。 合约中函数的调用创建的是调用还是交易？考虑一下这四种情况： 使用调用（call）直接对合约函数进行调用 使用sendTransaction直接对合约函数进行调用 使用调用（call）通过合约对合约函数进行调用 使用sendTransaction通过合约对合约函数进行调用 第一种情况与第三种情况是很明显的调用，第二种情况由于使用的是sendTransaction方法，因此它创建了一笔交易。比较特殊的是第四种情况，它看似是生成了一笔交易，但是由于以太坊黄皮书中对交易的定义中提到，交易是需要外部参与者（External Actor）进行签名的消息，所以第四种情况没有生成交易。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Ethereum</tag>
        <tag>以太坊</tag>
        <tag>ETH</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Ethereum基础实践】：以太坊测试私链的搭建]]></title>
    <url>%2F2018%2F04%2F18%2Fset-up-eth-private-chain-for-development%2F</url>
    <content type="text"><![CDATA[以太坊测试私链的搭建这篇文档通过使用Geth来搭建Ethereum（以太坊）私有测试链。本文档两个节点的系统环境为： OS：Ubuntu Memory：8G CPU：Intel Xeon E5-2620 安装GethGeth是通过Go语言实现的一款Ethereum客户端，通过Geth我们可以搭建Ethereum的测试私链。 1234sudo apt-get install software-properties-commonsudo add-apt-repository -y ppa:ethereum/ethereumsudo apt-get updatesudo apt-get install ethereum 搭建私有测试链通过搭建私有测试链，可以预分配以太币或者调低挖矿的难度来高效的获取以太币，可以便于对以太坊的测试。 搭建私有测试链需要做的主要有下列这些事项： 自定义创世块（Genesis Block） 自定义数据存放位置 自定义网络ID 关闭节点发现（Node Discovery）（推荐） 自定义创世块（Genesis Block） CustomGenesis.json 1234567891011121314&#123; "config": &#123; "chainId": 3131, "homesteadBlock": 0, "eip155Block": 0, "eip158Block": 0 &#125;, "difficulty": "200000000", "gasLimit": "2100000", "alloc": &#123; "7df9a875a174b3bc565e6424a0050ebc1b2d1d82": &#123; "balance": "300" &#125;, "f41c74c9ae680c1aa78f42e5647a62f353b7bdde": &#123; "balance": "400" &#125; &#125;&#125; 创世块是区块链中的第一个初始区块，我们通过定义CustomGenesis.json文件来对其进行自定义。 在创世块的配置文件^1中，有四个参数是必须要指定的： config：区块链的相关参数 chainId：防止重放攻击（replay attack，简单来说就是未经授权的用户来假扮交易的发送者） homesteadBlock：Homestead^2是以太坊的第二个发行版本（Frontier^3是第一个发行版本），值为0表示的使用的是该版本的以太坊 difficult：初始挖矿难度 gasLimit：每一个区块所消耗的gas上限 alloc：可以往地址中预先分配以太币 生成创世块使用下列命令来初始化创世块： 1geth --datadir /path/to/data init /path/to/CustomGenesis.json --datadir：指定区块链的数据目录（默认为~/.ethereum） init：创世块初始化JSON文件的目录 启动以太坊私有测试链相关启动参数 启动geth有如下主要参数（可以使用geth --help进行查看）： --nodiscover：关闭节点的可发现性，可以防止使用了相同network id和创世块的节点连接到你的区块链网络中（只能通过手动来添加节点） --maxpeers 0：指定网络中的最多节点数 --rpc：启用RPC服务 --rpcapi &quot;db,eth,net,web3&quot;：指定启用的RPC API --rpcport &quot;8080&quot;：指定RPC的端口 --rpccorsdomain：指定哪些URL可以连接到你的节点 --datadir：以太坊区块链的数据目录 --port：连接到其它节点的网络监听端口 --identity &quot;FirstNode&quot;：指定节点名称 console：启动geth控制台程序 启动geth 使用以下命令来启动geth： 1geth --identity "ETH-MainNode" --rpc --rpcport "6060" --rpccorsdomain "*" --datadir "/home/lyh/privatechain-eth/data" --port "30303" --nodiscover --maxpeers 5 --rpcapi "admin,db,eth,debug,miner,net,shh,txpool,personal,web3" --networkid 3131 console 使用相同的配置对两个节点进行配置并启动。 节点连接在其中一个节点的geth控制台中执行： 1&gt; admin.nodeInfo 我们得到该节点的信息： 123456789101112131415161718192021222324252627&gt; admin.nodeInfo&#123; enode: "enode://09444457dd475ac1a81948c5066602d23abd49407cae33edef929c9d96374396496f97b1a8fb1c22d36d990e90ed16a2a4faf3fd2ae63c08f4f58ee6249bcec7@[::]:30303", id: "09444457dd475ac1a81948c5066602d23abd49407cae33edef929c9d96374396496f97b1a8fb1c22d36d990e90ed16a2a4faf3fd2ae63c08f4f58ee6249bcec7", ip: "::", listenAddr: "[::]:30303", name: "Geth/ETH-MainNode/v1.8.2-stable-b8b9f7f4/linux-amd64/go1.9.4", ports: &#123; discovery: 30303, listener: 30303 &#125;, protocols: &#123; eth: &#123; config: &#123; chainId: 3131, eip150Hash: "0x0000000000000000000000000000000000000000000000000000000000000000", eip155Block: 0, eip158Block: 0, homesteadBlock: 0 &#125;, difficulty: 92699744128, genesis: "0x54fd3f9117e7d8c5b130af59fed07ddc9eef0826016d4d5b9c07db8db1dfac23", head: "0xd67ba0763b4fc50741b33205e486d0113aa182d310ee0225332459d104ed5b58", network: 3131 &#125; &#125;&#125; 得到enode信息： enode://09444457dd475ac1a81948c5066602d23abd49407cae33edef929c9d96374396496f97b1a8fb1c22d36d990e90ed16a2a4faf3fd2ae63c08f4f58ee6249bcec7@[::]:30303 我们需要在另一台节点上添加上该节点，使用命令： 12&gt; admin.addPeer("09444457dd475ac1a81948c5066602d23abd49407cae33edef929c9d96374396496f97b1a8fb1c22d36d990e90ed16a2a4faf3fd2ae63c08f4f58ee6249bcec7@[::]:30303")true 我们需要将上述enode信息中的[::]更换为该节点的IP地址。 使用命令： 12&gt; net.peerCount1 我们看到已经添加了一个节点。 测试以太坊私有链我们可以通过在两个节点分别创建账号构造一笔转账交易来验证多节点的私链是否搭建成功。 分别在两个节点中创建账号： 1&gt; personal.newAccount() 设置密码后，得到地址： 节点一： &gt; “0xa9436991e002986f58d948d79e737df190c4f26b” 节点二： &gt; “0xf7be2382f03cf7dd8ed5e59253a7b9321aac20ec” 开始挖矿： 由于新创建的账号中是没有以太币的，因此我们需要启用矿工进行挖矿： 12&gt; miner.setEtherbase("0xa9436991e002986f58d948d79e737df190c4f26b")&gt; miner.start(1) 另一个节点同样开启挖矿： 12&gt; miner.setEtherbase("0xf7be2382f03cf7dd8ed5e59253a7b9321aac20ec")&gt; miner.start(1) 构造一笔交易： 在进行转账之前，我们需要对钱包进行解锁： 1&gt; personal.unlockAccount("0xa9436991e002986f58d948d79e737df190c4f26b") 输入密码对钱包进行解锁后，构造一笔转账交易： 1&gt; eth.sendTransaction(&#123;from: "0xa9436991e002986f58d948d79e737df190c4f26b", to: "0xf7be2382f03cf7dd8ed5e59253a7b9321aac20ec", value: web3.toWei(10, "ether")&#125;) 在交易被矿工进行验证与打包至区块之后，我们可以查询一下钱包的余额来验证交易是否完成： 1&gt; eth.getBalance("0xf7be2382f03cf7dd8ed5e59253a7b9321aac20ec") 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Ethereum</tag>
        <tag>以太坊</tag>
        <tag>ETH</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Ethereum基础】：账户、地址、私钥和公钥]]></title>
    <url>%2F2018%2F04%2F17%2Feth-basis-accounts-address-pubkey-prikey%2F</url>
    <content type="text"><![CDATA[在以太坊中，账户、地址、私钥（Private Key）和公钥（Public Key）是非常重要的概念。账户扮演着以太坊的中心角色，地址是我们与以太坊系统进行交互的标识，它是以太坊账户与外界进行交互的名字，而私钥与公钥是保护我们账户安全的重要屏障。 什么是账户（Accounts）？账户在以太坊中扮演者十分重要的角色，它是以太坊的中心概念。在以太坊中，有两种类型的账户^1：一种是外部账户（EOAs，Externally Owned Accounts），另一种是合约账户（Contracts Accounts）。当我们提到账户这个术语的时候，我们通常指的是外部账户（EOA），当提到合约账户的时候我们通常称其为“合约”。 不论是外部账户还是合约账户，它们在以太坊中所维护的都是一系列叫做状态对象（state objects）的实体。这些实体中都拥有状态信息：外部账户存储的是账户的余额（balance），合约账户存储的是余额和合约中的内容。它们存储的这些状态会通过以太坊网络进行更新以及保证数据的一致性。账户是用户在以太坊区块链上创建交易必不可少的一部分。 账户标识了以太坊网络中每一个参与者的身份，每一笔交易都需要通过账户使用公钥加密进行签名才能够正常进行，这样的话，EVM（以太坊虚拟机）才能够对交易发送者进行验证来确保交易的真实可靠。 什么是以太坊地址（Address）？一个以太坊地址就代表着一个以太坊账户，地址是账户的标识。对于外部账户来说，地址表示的是该账户公钥的后20字节（通常会以0x开头，例如，0xcd2a3d9f938e13cd947ec05abc7fe734df8dd826，该地址使用的是16进制表示法^2）。上述示例中的地址中的字母全部是小写。在EIP55^3中引入了一种大小写混用的地址表示方法，通过这种表示方法进行表示的地址隐含了一个校验和（checksum）能够验证该地址的有效性。 什么是私钥和公钥？每个账户都由一对钥匙定义，一个私钥（Private Key）和一个公钥（Public Key）。 账户以地址为索引，地址由公钥衍生而来，取公钥的最后20个字节。每对私钥/地址都编码在一个钥匙文件里。该文件是JSON格式的，下面我们将会查看一个私钥文件示例（Keystore）。 以太坊的私钥是一串64位16进制字符（32字节）。它是账户安全最重要的部分，需要妥善保管，如果丢失了私钥也就意味着你的账户丢失了。 查看一个Keystore文件Keystore文件通常保存在以太坊数据目录的keystore文件夹下，它是JSON格式的： 123456789101112131415161718192021&#123; "address":"358f94366124d9f2817b09c84921d2a653f5ac0c", "crypto":&#123; "cipher":"aes-128-ctr", "ciphertext":"41c14f88ec8f35c9fe57cd39121a76c2dadbd82ea8fec59866468bc0d7371f2e", "cipherparams":&#123; "iv":"43443bf394e8f6ebcc687e13bc0effb9" &#125;, "kdf":"scrypt", "kdfparams":&#123; "dklen":32, "n":262144, "p":1, "r":8, "salt":"aaef6847d09cb1e9f5ceadaf5865d96a7493df1cae146b24e31092cc0a7844af" &#125;, "mac":"5e9781c587db5795c6d41cb4f001bf086cc3db33b6e7eefcc2ef472145e76821" &#125;, "id":"bcd61a88-283f-4d81-8457-30ec9c11521f", "version":3&#125; 通过keystore文件中的内容，我们可以看到其中包括了私钥加密的相关信息： address：该账户的地址 cipher：加密方法使用的是AES-128-CTR算法^4 ciphertext：加密后的密文 cipherparams：AES-128-CTR算法加密所需的相关参数 kdf：秘钥生成函数，用于使用密码对keystore文件进行加密 kdfparams：kdf算法所需的参数 mac：用于验证密码的编码 私钥、公钥和地址是如何生成的？大体来说，地址的生成的流程是：私钥 -> 公钥 -> 地址。因此地址的生成需要三步： 生成一个随机的私钥（32字节） 通过私钥生成公钥（64字节） 通过公钥得到地址（20字节） 私钥的生成 私钥是一组64位的16进制字符，通过私钥我们能够访问一个账户。以太坊的私钥生成是通过secp256k1^5曲线生成的，secp256k1是一个椭圆曲线算法，比特币使用的也是相同的曲线算法。 通过OpenSSL^6我们可以生成一个椭圆曲线私钥： 123456$ openssl ecparam -name secp256k1 -genkey -noout -----BEGIN EC PRIVATE KEY-----MHQCAQEEICGlTPPQInj0R/jaa7+bjF1twiR3RDLdOChSq98L5FmWoAcGBSuBBAAKoUQDQgAERynScthXq2n4Ahkfp08s/QNogZEtVCfQE/XTvpjsnIeQEZGJIOb+LiyluF8PIerBE1CjvCs5LLU+fZz+B31+Bg==-----END EC PRIVATE KEY----- 公钥的生成 其实，通过OpenSSL我们可以同时得到私钥和公钥： 1234567891011121314$ openssl ecparam -name secp256k1 -genkey -noout | openssl ec -text -noout read EC keyPrivate-Key: (256 bit)priv: 3f:64:bb:20:0a:b5:82:e9:73:03:8a:8b:79:68:62: 41:8b:98:a7:10:00:fb:50:de:c4:4d:0d:06:3d:a2: ed:cdpub: 04:4a:18:c2:c7:40:f4:9a:77:b2:89:e9:27:0c:39: 94:8b:94:10:a1:b0:c9:81:d9:af:06:8c:06:23:93: 63:d7:26:82:fd:b0:22:fe:f6:7f:4f:8a:69:58:2f: 98:3a:b3:94:ab:5f:06:85:4c:25:f3:3d:8e:f1:35: 2f:e7:fe:50:4dASN1 OID: secp256k1 地址的生成 地址是通过对上述的公钥做Keccak-256哈希^7，然后取最后的40位16进制字符得到的。我们对上述的公钥做哈希后并取后40位的结果是：0x24602722816b6cad0e143ce9fabf31f6026ec622。得到的该结果就是一个有效的以太坊地址。 如何验证地址的有效性Geth Web3进行验证： 通过以太坊客户端Geth的Web3接口可以对以太坊地址进行有效性验证： &gt; web3.utils.isAddress(&apos;0xc1912fee45d61c87cc5ea59dae31190fffff232d&apos;); &gt; true 通过第三方JS库进行验证： wallet-address-validator^8是一个JavaScript库能够对多种加密货币的地址进行验证。 123456var WAValidator = require('wallet-address-validator');var valid1 = WAValidator.validate('0x24602722816b6cad0e143ce9fabf31f6026ec622', 'ETH');if(valid1) console.log('This is a valid address');else console.log('Address INVALID'); 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Ethereum</tag>
        <tag>以太坊</tag>
        <tag>ETH</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多节点FastCoin山寨币的搭建]]></title>
    <url>%2F2018%2F04%2F08%2Ffastcoin-multinodes%2F</url>
    <content type="text"><![CDATA[这篇文章给出了Fastcoin多节点环境的搭建文档，FastCoin是一个由@harrywu修改BitCoin源代码产生的一个简单的山寨币。该山寨币在原有BitCoin源码基础上，对BitCoin相关网络参数、创世块信息、工作量机制等进行了修改，从而构建出了一个简单的山寨币系统，该系统加快了原有的挖矿速度，能够更方便的进行区块链开发的相关测试。 1 FastCoin简介FastCoin是一个由@harrywu修改BitCoin源代码产生的一个简单的山寨币。该山寨币在原有BitCoin源码基础上，对BitCoin相关网络参数、创世块信息、工作量机制等进行了修改，从而构建出了一个简单的山寨币系统，该系统加快了原有的挖矿速度，能够更方便的进行区块链开发的相关测试。 2 系统环境该文档的采用了两个节点进行测试，两个节点的系统环境如下： 12345OS: UbuntuLinux Kernel: Linux 4.4.0Memory: 1Ggcc Version: 5.4.0g++ Version: 5.4.0 3 安装准备该文档采用两个节点对FastCoin山寨币进行搭建，两个节点做同样的配置。 3.1 获取FastCoin源码1git clone https://github.com/imharrywu/fastcoin.git 3.2 安装项目构建依赖1sudo apt-get install build-essential libtool autotools-dev autoconf pkg-config libssl-dev 3.3 安装Berkeley DB 4.812345678910111213141516171819202122cd fastcoin/BITCOIN_ROOT=$(pwd)# 选择 Berkeley DB安装路径，此处为fastcoin子目录下BDB_PREFIX="$&#123;BITCOIN_ROOT&#125;/db4"mkdir -p $BDB_PREFIX# 获取源码wget 'http://download.oracle.com/berkeley-db/db-4.8.30.NC.tar.gz'# 校验echo '12edc0df75bf9abd7f82f821795bcee50f42cb2e5f76a6a281b85732798364ef db-4.8.30.NC.tar.gz' | sha256sum -c# 输出结应该为： -&gt; db-4.8.30.NC.tar.gz: OK# 解压tar -xzvf db-4.8.30.NC.tar.gz# 构建安装cd db-4.8.30.NC/build_unix/../dist/configure --enable-cxx --disable-shared --with-pic --prefix=$BDB_PREFIXmake install 3.4 安装Boost1sudo apt-get install libboost-all-dev 3.5 安装miniupnp12345wget http://miniupnp.tuxfamily.org/files/download.php?file=miniupnpc-1.6.20120410.tar.gztar -xzvf miniupnpc-1.6.20120410.tar.gzcd miniupnpc-1.6makesudo make install 也可以使用Ubuntu源进行安装： 1sudo apt-get install libminiupnpc-dev 4 搭建过程4.1 编译源码1234./autogen.sh./configure --with-miniupnpc --without-gui --enable-upnp-default LDFLAGS="-L$&#123;BDB_PREFIX&#125;/lib/" CPPFLAGS="-I$&#123;BDB_PREFIX&#125;/include/" --enable-walletmakemake install 编译安装之后，在src目录下会生成相应的二进制文件，主要用到的二进制文件有： bitcoind：fastcoin主程序 bitcoin-cli：fastcoin RPC控制台程序 如果在编译过程中遭遇如下报错信息，详见【6.1 Boost依赖库引起的报错】： 12345/usr/include/boost/variant/get.hpp:178:5: error: invalid application of 'sizeof' to incomplete type 'boost::STATIC_ASSERTION_FAILURE&lt;false&gt;' BOOST_STATIC_ASSERT_MSG( ^Makefile:3654: recipe for target 'libbitcoin_server_a-rpcrawtransaction.o' failedmake[2]: *** [libbitcoin_server_a-rpcrawtransaction.o] Error 1 4.2 相关configuration参数 --without-gui：不使用GUI，如果需要图形化界面，详见【6.6 图形化界面钱包的构建】 --enable-wallet:启用钱包（不启用钱包--disable-wallet也可以进行挖矿，如果不启用钱包，则无需安装Berkeley DB） --enable-debug:启用debug模式 --enable-tests:对测试程序进行编译 CPPFLAGS、LDFLAGS：指定Berkeley DB的路径 5 FastCoin测试5.1 FastCoin配置文件1vi ~/.fastcoin/fastcoin.conf 在fastcoin.conf文件中添加如下配置信息： 12345678# 用户名rpcuser=user# 密码rpcpassword=passworddaemon=1txindex=1server=1 5.2 启动bitcoind在其中一个节点中执行： 12cd fastcoin/src./bincoind -gen=1 -reindex -checkpoints=0 另一个节点执行： 1./bincoind -gen=1 -reindex -checkpoints=0 -addnode="另一个节点的IP，例：192.169.1.233" 5.3 bitcoind相关启动参数 -rpcuser=：指定用户名 -rpcpassword=：指定密码 -daemon=：bitcoind作为daemon进程在后台运行 -gen=：生成山寨币（挖矿） -addnode=：添加节点 -reindex：bitcoind启动时从当前blk000??.dat文件中的index重建区块链 -server：启用RPC服务器 5.4 bitcoin-cli使用./bitcoin-cli &lt;parameters&gt;可以查看当前区块链、网络、钱包等信息。 相关参数有： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091== Blockchain ==getbestblockhashgetblock &quot;hash&quot; ( verbose )getblockchaininfogetblockcountgetblockhash indexgetchaintipsgetdifficultygetmempoolinfogetrawmempool ( verbose )gettxout &quot;txid&quot; n ( includemempool )gettxoutsetinfoverifychain ( checklevel numblocks )== Control ==getinfohelp ( &quot;command&quot; )stop== Generating ==getgeneratesetgenerate generate ( genproclimit )== Mining ==getblocktemplate ( &quot;jsonrequestobject&quot; )getmininginfogetnetworkhashps ( blocks height )prioritisetransaction &lt;txid&gt; &lt;priority delta&gt; &lt;fee delta&gt;submitblock &quot;hexdata&quot; ( &quot;jsonparametersobject&quot; )== Network ==addnode &quot;node&quot; &quot;add|remove|onetry&quot;getaddednodeinfo dns ( &quot;node&quot; )getconnectioncountgetnettotalsgetnetworkinfogetpeerinfoping== Rawtransactions ==createrawtransaction [&#123;&quot;txid&quot;:&quot;id&quot;,&quot;vout&quot;:n&#125;,...] &#123;&quot;address&quot;:amount,...&#125;decoderawtransaction &quot;hexstring&quot;decodescript &quot;hex&quot;getrawtransaction &quot;txid&quot; ( verbose )sendrawtransaction &quot;hexstring&quot; ( allowhighfees )signrawtransaction &quot;hexstring&quot; ( [&#123;&quot;txid&quot;:&quot;id&quot;,&quot;vout&quot;:n,&quot;scriptPubKey&quot;:&quot;hex&quot;,&quot;redeemScript&quot;:&quot;hex&quot;&#125;,...] [&quot;privatekey1&quot;,...] sighashtype )== Util ==createmultisig nrequired [&quot;key&quot;,...]estimatefee nblocksestimatepriority nblocksvalidateaddress &quot;fastcoinaddress&quot;verifymessage &quot;fastcoinaddress&quot; &quot;signature&quot; &quot;message&quot;== Wallet ==addmultisigaddress nrequired [&quot;key&quot;,...] ( &quot;account&quot; )backupwallet &quot;destination&quot;dumpprivkey &quot;fastcoinaddress&quot;dumpwallet &quot;filename&quot;encryptwallet &quot;passphrase&quot;getaccount &quot;fastcoinaddress&quot;getaccountaddress &quot;account&quot;getaddressesbyaccount &quot;account&quot;getbalance ( &quot;account&quot; minconf includeWatchonly )getnewaddress ( &quot;account&quot; )getrawchangeaddressgetreceivedbyaccount &quot;account&quot; ( minconf )getreceivedbyaddress &quot;fastcoinaddress&quot; ( minconf )gettransaction &quot;txid&quot; ( includeWatchonly )getunconfirmedbalancegetwalletinfoimportaddress &quot;address&quot; ( &quot;label&quot; rescan )importprivkey &quot;fastcoinprivkey&quot; ( &quot;label&quot; rescan )importwallet &quot;filename&quot;keypoolrefill ( newsize )listaccounts ( minconf includeWatchonly)listaddressgroupingslistlockunspentlistreceivedbyaccount ( minconf includeempty includeWatchonly)listreceivedbyaddress ( minconf includeempty includeWatchonly)listsinceblock ( &quot;blockhash&quot; target-confirmations includeWatchonly)listtransactions ( &quot;account&quot; count from includeWatchonly)listunspent ( minconf maxconf [&quot;address&quot;,...] )lockunspent unlock [&#123;&quot;txid&quot;:&quot;txid&quot;,&quot;vout&quot;:n&#125;,...]move &quot;fromaccount&quot; &quot;toaccount&quot; amount ( minconf &quot;comment&quot; )sendfrom &quot;fromaccount&quot; &quot;tofastcoinaddress&quot; amount ( minconf &quot;comment&quot; &quot;comment-to&quot; )sendmany &quot;fromaccount&quot; &#123;&quot;address&quot;:amount,...&#125; ( minconf &quot;comment&quot; )sendtoaddress &quot;fastcoinaddress&quot; amount ( &quot;comment&quot; &quot;comment-to&quot; )setaccount &quot;fastcoinaddress&quot; &quot;account&quot;settxfee amountsignmessage &quot;fastcoinaddress&quot; &quot;message&quot; 具体的RPC调用可以参考BitCoin RPC API文档。 6 注意事项6.1 Boost依赖库引起的报错如果在编译FastCoin源码过程中遭遇如下报错信息，则需要我们对FastCoin源码进行修改： 12345/usr/include/boost/variant/get.hpp:178:5: error: invalid application of 'sizeof' to incomplete type 'boost::STATIC_ASSERTION_FAILURE&lt;false&gt;' BOOST_STATIC_ASSERT_MSG( ^Makefile:3654: recipe for target 'libbitcoin_server_a-rpcrawtransaction.o' failedmake[2]: *** [libbitcoin_server_a-rpcrawtransaction.o] Error 1 将src/rpcrawtransaction.c文件中的第288行： 1const CScriptID&amp; hash = boost::get&lt;const CScriptID&amp;&gt;(address); 修改为： 1const CScriptID&amp; hash = boost::get&lt;CScriptID&gt;(address); 6.2 Berkeley DB安装问题如果不想对Berkeley DB的源码进行编译安装，还可以直接采用Debian源进行安装： 123sudo add-apt-repository ppa:bitcoin/bitcoinsudo apt-get updatesudo apt-get install libdb4.8-dev libdb4.8++-dev 6.3 nTXConfirmTarget参数该参数是确认目标值，用于计算矿工费用，默认值为1，适用于双节点的系统，如需对该参数进行修改。可以在执行./bitcoind时添加参数-txconfirmtarget=number进行配置。 6.4 txindex参数问题如果在~/.fastcoin/fastcoin.conf配置文件中添加了txindex参数，则需要在启动bitcoind时添加启动参数—reindex。 6.5 图形化界面钱包的构建如需使用图形化界面的钱包，需要安装QT并且在./congfiguration时不使用--without-gui选项，FastCoin默认使用QT4： 1sudo apt-get install libqt4-dev libprotobuf-dev protobuf-compiler 如需使用QT5，需要采用--with-gui=qt5选项，并安装QT5： 1sudo apt-get install libqt5gui5 libqt5core5a libqt5dbus5 qttools5-dev qttools5-dev-tools libprotobuf-dev protobuf-compiler 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Blockchain</tag>
        <tag>Bitcoin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[容错虚拟机分布式系统的设计]]></title>
    <url>%2F2017%2F05%2F20%2Fftvm-notes%2F</url>
    <content type="text"><![CDATA[这篇文章是我阅读论文《The Design of a Practical System for Fault-Tolerant Virtual Machines》时的笔记，这篇论文是 VMware 发表的论文，使用虚拟机来设计一个分布式容错系统。 在分布式系统中，容错方法有很多种，常见的传统方法有：主/副服务器方法（当主服务器宕机之后，由副服务器来接管它的工作），这种方法通常需要机器之间的高带宽。 另外还有确定（deterministic）状态机方法：将另一台服务器初始化为和主服务器一样的状态，然后让它们都接受到同样的输入，这样它们的状态始终保持一致，但是这种方法对于非确定的（non-deterministic）操作并不适用。 本文中讨论的方法是使用虚拟机作为状态机，它具有以下优点： 操作全部被虚拟化 虚拟机本身就支持 non-deterministic 操作 虚拟机管理程序（Hypervision）能够记录所有在虚拟机上的操作，所以能够记录主服务器（Primary）所有操作，然后在副服务器（Backup）上进行演绎 基本设计方案 如图就是本文提到的容错系统的架构，一个 Primary，一个 Backup，Primary 和 Backup 之间通过 Logging Channel 进行通信，Primary 和 Backup 基本保持同步，Backup 稍稍落后，它们两个之间会通过 heartbeat 进行 fail 检测，并且它们使用共享磁盘（Shared Disk）。 确定（deterministic）操作的演绎让两台机器初始状态相同，它们接受相同的输入，顺序相同，两台机器执行的任务的结果就会相同。 但是如果存在非确定的（non-deterministic）操作（比如中断事件、读取CPU时钟计数器的值操作就是非确定的），它会影响状态机的执行。 难点在于： 需要捕捉全部的输入和 non-deterministic 操作在保证 Backup 是deterministic 的 需要准确将全部输入和 non-deterministic 操作应用到 Backup 中 需要保证系统高效 设计方案为：将所有的 input 和 non-deterministic 操作写入到 log 中（file），对于 non-deterministic 操作还要记录和它相关的状态信息等，确保 non-deterministic 操作后Backup状态还是和 Primary 一致 FT（Fault-Tolerance）协议FT 协议是应用于 logging channel 的协议，协议的基本要求为： 如果 Primary 宕机了，Backup 接替它的工作，Backup 之后向外界发出所有的 Output 要和 Primary 原本应当发送的一致。 为了保证以上的要求，设计如下系统： Primary会在所有关于本次Output 的所有信息都发送给 Backup 之后（并且要确保 Backup 收到）才会把 output 发送给外界 Primary 只是推迟将 output 发送给外界，而不会暂停执行后边的任务 流程如图所示： 但是这种方法不能保证 output 只发出一次，如果 primary 宕机了，backup 不能判断它是在发送了 output 之前还是之后宕机的，因此 backup 会再发送一次 output。但是这个问题很容易解决，因为： output 是通过网络进行发送的，例如 TCP 之类的网络协议能够检测重复的数据包 即使 output 被发送了2次其实也没关系。如果 output 是一个写操作，它会在同一个位置写入两次，结果不会发生变化；如果 output 是读取操作，读的内容会被放入 bounce buffer（为了消除 DMA 竞争），数据会在 IO 中断之后被送到 宕机检测如何知道有机器宕机，在该系统中是十分重要的。该设计使用的是UDP heartbeat 机制来检测 Primary 与 Backup 之间的通信是否正常。 但是使用这种方法会存在裂脑问题（split-brain，Primary 和 Backup 同时宕机），该怎么解决呢？ 该设计中使用了共享存储（Shared Storage），对它的操作是原子的，Primary 和 Backup不能同时进行一个操作（提供原子的 test-and-set 操作） 如果检测出 Primary 宕机，Backup 会成为 Primary，接替之前的工作，然后再寻找一个 Backup。 具体实现启动/重启 Virtual Machine如何启动一个和 Primary 状态一样的 Backup？ VMware Vmotion 操作能够将一台 VM 从一个 Server 完整的迁移到另一个 Server（只需要很短的中断），在该设计中的方法对 Vmotion 做了一点修改，不是进行迁移，而是直接克隆。 管理 Logging Channel 如图，该设计使用了一个大的 buffer，来保存 logging entries，Primary 把自己的 entry 存到 buffer 中，由 logging channel 发送给Backup 的 buffer，然后 Backup 从 buffer 读取命令执行。 如果 Backup 的 buffer 空了，没有命令执行了，Backup 会等待新的 entry 如果 Primary 的 buffer 满了，Primary 会等待，等 buffer 中有空余空间再继续执行 Disk I/O问题 disk 操作是并行的，同时对 disk 的同一位置进行操作会导致 non-deterministic 解决方案：检测 IO 竞争，使这些操作串行执行 Disk IO 使用 DMA（Direct Memory Access），同时访问内存同一位置的操作会导致 non-deterministic 解决方案：对 disk 操作的内存设置内存的页保护，但是这种方法代价太高；该设计中使用了 bounce buffer，它的大小和 disk 所操作的内存部分大小是一致的，read 操作直接将内容读入 buffer，当其他操作完成，写入内存，write 操作将写内容写入 buffer，之后再写入磁盘。 总结Vmware 提出的这种 Primary/Backup 方法是分布式容错方法中非常重要的一部分，可以用在许多系统中，不仅仅是分布式存储（GFS 的容错方法），也可以用在分布式计算中，因为它是将所有的操作都记录下来，将它们重新在 Backup 上进行演绎，从而起到了备份的作用，能够做到容错（Fault-Tolerance）。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>paper</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GFS 阅读笔记]]></title>
    <url>%2F2017%2F05%2F15%2Fgfs-reading-notes%2F</url>
    <content type="text"><![CDATA[这篇博客是我阅读著名的 GFS 论文（The Google File System）所总结的笔记以及自己一些的思考。这篇论文是一篇非常经典的论文，尤其对于想要了解分布式或者刚刚开始研究分布式的人来说，是一篇非常好的读物，它里面提到了许多分布式方向的基本问题，许多分布式的研究都是围绕这些基本问题的。 分布式系统在了解谷歌文件系统（Google File System）之前，我们必须要了解一下有关分布式系统的一些概念。 Q1：一致性是什么？ 在分布式文件系统中，很重要的一部分就是数据的复制（replica），为了保证分布式文件系统的高可用性，我们常常会把文件在不同的机器上存储多份，一致性的要求就是保证这些不同机器上的复制品（replicas）能够保持一致。 Q2：如果只有一个应用程序，它对文件系统进行了一次写操作，这个应用程序在这次写操作之后的读操作会观测到什么呢？ 它会正常观测到它刚刚写入的数据。 Q3：如果另外多个应用程序执行的读操作呢，它们会观测到什么呢？ 对于弱一致性的模型来说，这次读操作有可能会读取到已经过期的数据； 对于强一致性的模型来说，读操作读到的始终是上一次写入操作进行完成之后的数据。 强一致性能保证写入操作，但是它会影响性能（强一致性协议复杂） Q4：理想化的一致性模型是怎样的？ 分布式文件系统通过在多个机器上复制文件来保证可用性，在理想化的一致性模型中，在文件系统中所进行的各种操作都要像是在一台机器上进行的操作。实现理想化一致性模型的难点在于处理高并发问题、如何处理分布式集群中的机器崩溃以及达到网络的高效利用，理想化的一致性模型还会出现裂脑问题（split-brain，如果两个存储着相同文件的机器 A，B同时崩溃，其他的机器并不知道是哪一个先崩溃的，所以就不知道该用 A 恢复 B还是用 B 恢复 A）。总之，使用理想化一致性算法会影响性能，并且它的实现非常复杂（例如：Paxos） GFS 不是采用的理想化一致性模型，但是它解决了机器崩溃恢复的问题以及能够应对高并发操作同时又能相对高效地利用网络。 GFS 是什么？GFS（Google File System ）是一个大规模分布式文件系统，具有容错的特性（机器崩溃后的处理），并且具有较高性能，能够响应众多的客户端。 GFS 设计背景 经常会有机器崩溃（因为机器众多，难免会有机器崩溃） 有些存储的文件比较大 append 操作更常见（在文件后追加，而不是 overwrite 覆盖） 主要包括两种读取 （read）操作：一种是大的顺序读取（单个文件读取几百 KB 甚至是几 MB）；另一种是小的随机读取（在随机位置读取几 KB） 需要支持并发（例如，多个客户端同时进行 append 操作） GFS 所需提供操作create（文件创建）、delete（文件删除）、open（打开文件）、close（关闭文件）、read（读取文件）、write（写入文件）、record append（追加文件）、snapshot（快照）。 GFS 架构GFS 的架构由一台 master 服务器和许多台文件服务器（chunkserver）构成，并且有若干客户端（client）与之交互。 GFS 特点概述 文件分块（chunks），每块有一个64位标识符（chunk handle），它是在 chunk 被创建时由 master 分配的，每一个 chunk 会有3个备份，分别在不同的机器上。 Master 存储所有的 metadata，包括命名空间（namespace）、访问控制信息（access control）、文件与 chunk 的映射关系（mapping）以及 chunk 的存储位置 Master 管理 chunk 租约（lease）、chunk 迁移（如果 chunkserver 挂掉）、chunkserver 之间的通信（heartbeat，它也会向 chunkserver传达master 的命令，chunkserver 通过 heartbeat 向 master 报告自己的状态） Client 会和 master 以及 chunkserver 进行交互，client向 master 请求 metadata，然后向 chunkserver 进行读写操作 client 与 chunkserver 都不会缓存文件数据，为的是防止数据出现不一致的状况。但是 client 会缓存 metadata 的信息（但是会出现一个问题，如果 metadata 过期怎么办呢？GFS 给出了自己的解决方案，也就是租约 lease） 单一 Master 架构GFS 为了简化设计，在整个系统中只有一个 master 进行管理。Master 不提供读写操作，它只会告诉 client，它所请求操作的文件在哪个 chunkserver 上，然后 client 会根据 master 提供的信息，与对应的 chunkserver 进行通信。 例如：以 client 要进行读取操作为例 client 将应用程序请求的文件名、大小转化为 chunk index，然后将文件名和 index 发送给 master master 返回文件的 chunk handle 和所有该文件备份的位置 client 将这两个 master 发送给它的信息缓存起来作为 value，文件名和 chunk index 作为 key client 向三个备份之一的 chunkserver 发送读请求（选择最近的机器），请求中包含 chunk index 和它要读取的文件的 Byte 范围 如果 client 缓存的信息没有过期（如何知道是否过期会在后面的文章进行介绍），client 就不用在与 master 进行通信了，以后可以直接与 chunkserver 进行通信 chunk 大小GFS 中将 chunk 的大小定为 64MB，它比一般的文件系统的块大小要大。 这样做的优点有： 减少 client 与 master 的交互 client 可以在一个块上执行更多的操作，通过 TCP 长连接减少网络压力 减小 metadata 的大小 但是这样做也存在缺点： 一个 chunk 可以存更多的小文件了，这样的话如果有一个块存储了许多小文件，client 和它进行操作的几率大大提高，这个 chunk 的压力会很大（然而在实际中，这个问题影响并不大） 在批处理系统中存在很大问题（如果在一个 chunk 上有一个可执行文件，同时有许多 client 都要请求执行这个文件，它的压力会很大。解决方案是把该文件在不同的 chunkserver 上多添加几个备份，更长久的方案是应该允许 client 去读取其他 client 的文件） metadataGFS 的 metadata 存储着 3 种类型的信息： 文件名以及 chunk 的名称 文件与 chunk 的映射关系 各个备份（replicas）的位置 Metadata 通常存储于内存中，前两种信息有时会存于磁盘中，它们有时会作为操作记录（operation log）备份的一部分存储于磁盘，备份于远程机器。 把 metadata 存储于内存有许多优点，查看 metadata 信息时很方便，速度快，有利于 chunk 的垃圾回收（garbage collection）、再备份（re-replication）以及 chunk 迁移（为的是负载均衡）。 但是如果如果Metadata都存放于内存的话会不会受限于内存的大小呢？ 实际上不会的，因为每一条 metadata 的大小非常小，namespace 信息也很小，并且使用了前缀压缩（prefix compression）进行存储。并且升级内存的花费实际上也很小。 chunk 位置chunk 的位置信息在 master 中不是一成不变的，master 会通过定期的 heartbeat 进行更新，这样做能够减小开销，这样做就不用 master 与 chunkserver 时刻保持同步通信（包括 chunkserver 的加入、退出、改名、宕机、重启等）。chunkserver 上有一个 final word，它表示了哪个 chunk 在它的磁盘上，哪个 chunk 不在。 操作记录（operation log）operation log 中包括了 metadata 变更的历史记录 它是 metadata 的持久化记录，备份于磁盘上 它表示了并发操作的时间线 用于 Master 恢复 一致性模型GFS 采用的一致性模型并不是强一致性模型，这是在考虑了各种问题后权衡的结果。 GFS 是如何保证一致性的？ 有关文件命名空间的操作都是原子的（由 namespace lock 保证） 我们先来介绍一下 GFS 保证一致性的前提和一些概念： 如果所有客户端不论从哪一个备份中读取同一个文件，得到的结果都是相同的，那么我们就说这个文件空间是一致的（consistent） defined：如果一个文件区域在经过一系列操作之后依旧是一致的，并且客户端完全知晓对它所做的所有操作，我们就称它为『defined』 一个操作如果没有被其他并发的写操作影响，那么这个被操作的文件区域是 defined 的 成功的并发操作也会导致文件区域 undefined，但是一定是一致的（consistent）（客户端有可能只看到了最终一致的结果，但是它并不知道过程） 失败的并发操作会导致文件区域 undefined，所以一定也是不一致的（inconsistent） GFS 并不需要是因为什么导致的 undefined（不区分是哪种 undefined），它只需要知道这个区域是 undefined 还是 defined 就可以 造成数据改变的操作可能是写入（write）或者追加（record append）： write：往应用程序指定的 offset 进行写入 record append：往并发操作进行过的 offset 处进行写入，这个 offset 是由 GFS 决定的（至于如何决定的后面会有介绍），这个 offset 会作为 defined 区域的起始位置发送给 client。 “regular” append：对应于 record append 的一个概念，普通的 append 操作通常 offset 指的是文件的末尾，但是在分布式的环境中，offset 就没有这么简单了 重要问题 GFS 通过在所有的备份（replicas）上应用顺序相同的操作来保证一个文件区域的 defined（具体细节后面会讨论） GFS 会使用 chunk version（版本号）来检测 replicas 是否过期，过期的 replicas 既不会被读取也不会被写入 GFS 通过握手（handshakes）来检测已经宕机的 chunkserver GFS 会通过校验和（checksuming）来检测文件的完整性 系统间的交互这一部分我们来谈谈系统中各个部分之间的交互（master 和 chunkserver、client 和 master、chunkserver 等），GFS 设计的目标是尽可能地让 master 更少的涉及到各种操作中。 租约（lease）和修改的顺序（mutation order） Mutation（修改）：mutation 指的是改变了 chunk 的内容或者 metadata，每一次 mutation 都应该作用于所有的备份 GFS 使用租约机制（lease）来保障 mutation 的一致性：多个备份中的一个持有 lease，这个备份被称为 primary replica（其余的备份为 secondary replicas），GFS 会把所有的 mutation 都序列化（串行化），让 primary 直行，secondary 也按相同顺序执行，primary 是由 master 选出来的。一个 lease 通常60秒会超时。 现在我们以写操作的数据流程来说明租约机制是如何进行的： client 向 master 请求持有 lease 的 chunk（primary replica）位置和其他 replicas 的位置（如果没有 chunk 持有 lease，那么 master 会授予其中一个 replica 一个 lease） master 返回 primary 的信息和其他 replicas 的位置，然后 client 将这些信息缓存起来（只有当 primary 无法通信或者该 primary replica 没有 lease 了，client 才会向 master 再次请求） client 会将数据发送到所有的 replicas，每个 chunkserver 会把数据存在 LRU 缓存中 在所有的 replicas 都收到了数据之后，client 会向 primary 发送写请求。primary 会给它所收到的所有 mutation 分配序列号（这些 mutation 有可能不是来自于同一个 client），它会在自己的机器上按序列号进行操作 primary 给 secondaries 发送写请求，secondaries 会按相同的序列执行操作 secondaries 告知 primary 操作执行完毕 primary 向 client 应答，期间的错误也会发送给 client，client 错误处理程序（error handler）会重试失败的 mutation 其他问题： 如果一次写操作要写的数据比较大，可能会跨越多个 chunk，GFS client 会把它分为几次小的操作，GFS 支持的最大的操作大小是 chunk 的1/4的大小 但是如果像上述这么做会出现 undefined 但是 consistent 的区域，这是为什么呢？GFS 的 record append 操作仅能保证数据在一个原子单位中被写了一次，并不能保证对所有的 replicas 操作的位置都是相同的，比如每次写入的 offset 相同，但是 chunk 有可能不一样 数据流GFS 对其数据流的设计目标如下： 要充分利用网络带宽 避免网络瓶颈和高延迟 减少数据流动延迟 设计方案如下： 数据以链（chain）的形式 在 chunkserver 之间线性流动（每个机器都在用自己的全部带宽与另外一个机器通信，而不是同时让多个机器分享带宽） 每个机器会把数据发送到离自己最近的还没有收到数据的机器（GFS 中可以通过机器 IP 地址进行计算） 通过 TCP 连接将数据传输流水线化（pipelining），pipelining 之所以能够有效果是因为 GFS 的网络是全双工的交换网络 Snapshot 快照GFS 通过 snapshot 来立即创建一个文件或者目录树的备份，它可以用于备份文件或者创建 checkpoint（用于恢复），同时 GFS 把写时复制技术（copy-on-write）引入到了快照操作中，原理与 Linux 进程中的写时复制基本相同。 当 master 收到 snapshot 操作请求后： 废除所有的 lease，准备 snapshot（相当于暂停了所有写操作） master 记录所有操作，并且将记录写入磁盘 master 将源文件和目录树的 metadata 进行复制，这样之前的记录就和当前的内存中所保存的状态对应起来了，新建的 snapshot 和源文件指向的会是同一个 chunk Master 职责 执行所有有关于 namespace 的操作 管理整个系统的 chunk replicas： 做出 chunk replicas 的放置决定 创建 chunk/replicas 协调各种操作，保证 chunk 被完全复制 负载均衡 回收闲置空间 管理 namespace在进行快照操作时，lease 会被废除，无法进行写操作，但是 GFS 希望其他 Master 操作不受影响，GFS 采取的方法是使用namespace 锁。 GFS 的namespace 是一个查找表（lookup table），并且采用了前缀压缩的方式存储在内存中，它是一个树结构，namespace 树中的每一个节点（文件名或者目录名）都有一个读/写锁。 在 Master 对文件或者目录进行操作之前它首先需要获取一个锁，比如要对 /d1/d2/…/dn/leaf 进行操作，需要获得 /d1, /d1/d2, /d1/d2/…/dn的读锁，需要 /d1/d2/…/dn/leaf 的读锁或者写锁（根据不同的操作，锁也不同） 例如，当/home/user 被快照备份至/save/user 时，如果此时要创建/home/user/foo 会发生什么呢？ 快照操作获得了/home, /save 的读锁和/home/user, /save/user 的写锁。创建/home/user/foo需要/home, /home/user的读锁和/home/user/foo 的写锁。因为两个操作在 /home/user的锁上产生了冲突，所以操作会依次执行，在完成 snapshot 操作之后，释放了/home/user 的写锁， /home/user/foo才会被创建。 放置 replicas如何安置replicas 的目标是： 最大化数据可靠性和可用性 最大化网络带宽的利用 这里的最大化不仅仅是机器间的问题，还要考虑机架间的问题 在以下3种情况下，Master 会进行创建 replicas 的操作： 创建了新的 chunk 需要重新备份 负载均衡 如何选择将 replicas放置到哪台机器上呢？ 优先选择磁盘利用率低的 chunkserver GFS 会限制每个 chunkserver『最近』创建的次数。换句话说，如果一个 chunkserver 近期创建 replicas 的操作比较频繁，就不会优先选择它（因为创建就意味着以后会进行读取，为了防止突然间大量的读取出现在同一台机器上） 保证可用性，尽可能跨机架进行创建操作 当可用的备份低于要求时（GFS 要求为3份），master 会对 chunk 进行重新备份，在以下情况有可能需要重新备份： chunkserver 不可用了 备份损坏了 硬盘挂掉了 所要求的最低备份数量提高了 当有多个 chunk 需要备份时，GFS 如何决定先备份哪个呢？策略如下： 优先选择可用备份少的 优先备份最近没有 delete 文件的 优先备份阻塞了 client 操作的 当 master 决定了备份哪个之后，会把当前可用的 chunk 直接克隆到目标位置（遵循replicas 放置规则） 垃圾回收文件 delete 之后，GFS 并不会立即对空间进行回收，而是等待垃圾回收机制会空间进行释放。 当文件被删除之后，Master 会想其他操作一样，把删除操作记录下来，但是不进行空间的回收，而是将这块空间命名为 hidden（并且包含被删除时的时间戳），Master 会定期进行扫描，把隐藏了一定时间的文件空间进行回收（这个时间是可以进行配置的），在此期间可以对这块空间的文件进行恢复（直接通过重命名回原来的名称就可以）。 除此之外，垃圾回收机制还会扫描孤儿 chunk（所有的文件都没有用到的非空 chunk），然后对这块 chunk 的 metadata 进行清除。具体的做法是，在 master 于 chunkserver 的 heartbeat 信息中会携带关于 chunk 的信息，master 会把 metadata 中不存在的 chunk 发送给 chunkserver，chunkserver 会把它拥有的 chunk 发送给 master。 过期 replica 检测chunkserver 宕机或者是 mutation 的丢失会导致 replica 的过期，GFS 是如何对 replicas 进行检测，判断它们是否是最新的呢？ GFS 对于每一个 chunk 都会有一个版本号，这个版本号由 master 进行管理，通过版本号可以对过期的 replica 进行甄别。当 master 授予 lease 的时候，会增加版本号并且通知所有未过期的 replicas，master 和 replicas 都会记录下最新的版本号（这些操作需要在客户端进行写入操作之前完成）。如果这时，有一个 replica 不可用了，它的版本号就不会再增加了，在 chunkserver 重启或者重新向 master报告它的版本号时，master 就会知道这个 replica 已经过期了，并且会在垃圾回收时将它进行回收。如果 master 的版本号落后了呢，它会更新自己的版本号。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>paper</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MapReduce 阅读笔记]]></title>
    <url>%2F2017%2F04%2F19%2Fmapreduce-notes%2F</url>
    <content type="text"><![CDATA[这篇文章是我阅读 MapReduce 论文：《MapReduce: Simplified Data Processing on Large Clusters》的笔记，这篇笔记概述了 MapReduce 是什么，它的工作流程，一些细节问题，以及我的个人理解与思考。 MapReduce 是什么？MapReduce 是 Google设计的一种用于大规模数据集的分布式模型，它具有支持并行计算、容错、易使用等特点。它的设计目标如下： 支持并行 用于分布式 能够进行错误处理（比如机器崩溃） 易于使用（程序员友好） 负载均衡 模型流程MapReduce 模型主要分为 2 个部分：Map 和 Reduce。 在 Map 过程中，Map 函数会获取输入的数据，产生一个临时中间值，它是一个 K/V 对，然后MapReduce Library 会按 Key 值给键值对（K/V）分组然后传递给 Reduce 函数。而后，Reduce 接收到了这些 K/V 对，会将它们合并。 以论文中的字数统计程序为例： 现在我们来考虑，如果我们有许多文档，然后我们想要统计在这些文档中每个字出现的次数，现在用 MapReduce 来解决这个问题。Map 函数所做的工作，就是进行分词，产生一组形如下表的 K/V 键值对： apple 1 apple 1 by 1 by 1 by 1 google 1 google 1 take 1 …… …… 然后将这组键值对传递给 Reduce，由 Reduce 进行合并。 具体流程如下： 由用户程序中调用的 MapReduce Library 将文件分成 M 块（M 要远大于 Map Worker 的数量，每块大小16MB~64MB），此时，进入 MapReduce 过程； 由 Master 给空闲的 Worker 分配任务，共有 M 个 Map 任务，R 个 Reduce 任务； Map Worker 读取文件，将文件处理为 K/V 键值对，K/V 键值对缓存于内存中（此时存在一个问题，如果断电怎么办？往下看后边有解释）； 将缓存于内存的 K/V 键值对写入磁盘，分成 R 堆（分堆方法有很多种，论文中提到了使用 Hash 散列函数），然后将结果发送给 Master； Master 将这些 K/V 键值对的存储地址告知 Reduce，Reduce Worker 通过 RPC（远程过程调用）进行读取，读取完毕之后会根据 Key 值进行排序（这样，相同 Key 值的就会在一起。但是存在一个问题，如果内存不够大，排序该怎么进行？可以使用外部排序）； Reduce Worker 将已经排序的结果进行遍历，将每个 Key 值所对应的一组 Value，所组成的 &lt;key, value[num]&gt;传递给用户所编写的 reduce 函数进行处理； 所有的 Map，Reduce 任务都完成后，告知用户程序，MapReduce 已经结束，返回用户程序。 容错处理（Fault-Tolerance）MapReduce 中的容错处理是非常重要的，因为MapReduce 是运行于分布式环境中的，在分布式环境中经常会有机器出现错误，我们不能让个别机器的错误影响到整体。 Worker 崩溃Master 通过定期给 Worker 发送心跳（heartbeat）来检测 Worker 是否还在正常工作，如果 Worker 无应答或者是应答有误，我们认定它已经宕机（fail）。如果正在工作的 Worker 宕机了，那么运行在它上面的 map 任务会进行初始化（初始状态为 idle，任务还有其他2种状态，in-progress处理中，completed 已完成），重新被分配到正常的 Worker 上。 如果说 Map Worker 已经完成了一些工作，我们仍然要对运行在它上面的所有任务重新进行分配，这是为什么呢？这里同时可以解决上面的那个问题。因为 Map Worker 处理后的中间结果存在于内存中，或者是 local disk 中，一旦它宕机，这些数据就获取不到了。 但是对于 Reduce Worker，它完成的任务不用重做，因为它处理后的结果是保存在全局存储中的。 如果，在 Map Worker A 宕机之后，它所做的任务被重新分配给了 Map Worker B，后边的 Reduce Worker 会被告知，A 已经宕机，要去 B 去读取数据。 Master 崩溃如果说 MapReduce 的 Master 宕机了，又该如何处理呢？ MapReduce 中的 Master 会定期进行 checkpoint 备份，如果 Master 宕机，会根据之前的 checkpoint 进行恢复，但是恢复期间，MapReduce 任务会中断。 一些细节问题1. 考虑用户编写的 reduce 函数是确定的（deterministic，对于同样的输入执行的结果是一样的），如果有多个 Reduce Worker 都执行了一个 Reduce 任务该怎么办？ 因为用户的 reduce 函数是 deterministic 的，所以即使有多个 Reduce Worker 都执行了同一个任务，但是它们执行的结果都是一样的，并不影响最后的结果。 2. 如果用户编写的 reduce 函数是不确定（non-deterministic）的呢？ 正是因为 reduce 函数是 non-deterministic 的，本来每次执行的结果也不确定，所以更不会产生影响。 3. 我们所需要处理的输入文件是如何保存的？ Input 文件保存于 GFS 中，GFS 会将它们分块保存（每块16MB~64MB），GFS 会对每个文件有3个备份，备份在不同的机器上。 4. Master 是如何分配任务的？ 遵循就『近』原则，将任务分配给离任务所保存的位置最『近』的 Worker，这里对『近』的定义是网络层面上的，比如说在同一个交换机下的两个机器就是距离『近』的。 5. MapReduce 是如何做到负载均衡的？ 一开始将文件分块时，分为 M 块，远大于 Map Worker 的数量就有助于负载均衡。同时，这样做还有一个好处，就是当一个 Worker 宕机的时候，可以将任务迅速分配开来，分到多个 Worker 上去。如果 M 比较小，有可能当一个 Worker 宕机时，它的任务不够分配到剩下的 Worker 中，会有 Worker 闲置。 6. 如何解决 straggler 问题（其他 Worker 都已经完成了自己的任务，但是有一个异常慢的机器，它还有任务没完成，拖慢了整体的速度）？ MapReduce 有一种机制应对这种情况：MapReduce 会对未完成的任务（in-progress） 定时执行备份执行操作（即，把这些正在某些 Worker 上执行但未完成的任务再次分配给其他 Worker 去执行），不论这个任务被哪个 Worker 完成都会被标记为已完成。 7. 如果在 Map 任务中有一个 key 特别多，可能会拖慢整个网络的速度，该怎么办？（例如，在字数统计的例子中，the 这个词的数量特别多） MapReduce 给用户提供了一个 Combiner 函数，这个函数可以将结果在发送到网络之前进行合并，例如发送键值对&lt;”by”, 3>。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>paper</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 79. Word Search]]></title>
    <url>%2F2017%2F03%2F26%2Fleetcode-079%2F</url>
    <content type="text"><![CDATA[这篇文章是 LeetCode 79. Word Search.md 的分析与解法。 问题描述Given a 2D board and a word, find if the word exists in the grid. The word can be constructed from letters of sequentially adjacent cell, where “adjacent” cells are those horizontally or vertically neighboring. The same letter cell may not be used more than once. For example, Given board = 12345[ [&apos;A&apos;,&apos;B&apos;,&apos;C&apos;,&apos;E&apos;], [&apos;S&apos;,&apos;F&apos;,&apos;C&apos;,&apos;S&apos;], [&apos;A&apos;,&apos;D&apos;,&apos;E&apos;,&apos;E&apos;]] word = ABCCED, -&gt; returns true, word = SEE, -&gt; returns true, word = ABCB, -&gt; returns false. 这道题的意思就是在给定的字母板上寻找给定的单词，规则是从一个字母开始垂直或者水平方向上开始寻找，同一个位置的字母只能在路径上经过一次。 问题分析这个问题首先能想到的方法就是暴力搜索，从字母板的(0, 0)位置开始搜索，到(n, n)位置结束。如果在搜索的过程中找到了给定的单词就直接返回。 以下图为例，假设我们要搜索的单词是『BED』，搜索顺序为『上下左右』： 搜索过程如下： 从(0, 0)位置的 A 开始搜索，A 与给定单词的[0]位置的字母不匹配，到(1, 0)位置； (1, 0)位置的 B 与给定单词的[0]位置的字母相同，按照 B 的上下左右的方向依次搜索，已经经过的位置不再搜索； 搜索至(1,1)位置的 E，与给定单词的[1]的字母相同，按照 E 的上下左右的方向依次搜索，已经经过的位置不再搜索； 直到搜索到 D，完成 BED 的搜索，返回。 代码实现123456789101112131415161718192021222324252627282930313233343536373839class Solution &#123;public: bool exist(vector&lt;vector&lt;char&gt;&gt;&amp; board, string word) &#123; if(board.size() == 0 || word.length() == 0 )&#123; return false; &#125; for(int i = 0; i &lt; board.size(); i++)&#123; for(int j = 0; j &lt; board[i].size(); j++)&#123; if(search(board, word, i, j, 0))&#123; return true; &#125; &#125; &#125; return false; &#125; bool search(vector&lt;vector&lt;char&gt;&gt;&amp; board, string word, int x, int y, int pos)&#123; if(pos == word.length())&#123; return true; &#125; if(x &lt; 0 || y &lt; 0 || y &gt;= board[x].size() || x &gt;= board.size())&#123; return false; &#125; if(board[x][y] != word[pos])&#123; return false; &#125; char temp = board[x][y]; board[x][y] = '*'; bool result = search(board, word, x-1, y, pos+1) || search(board, word, x+1, y, pos+1) || search(board, word, x, y+1, pos+1) || search(board, word, x, y-1, pos+1); board[x][y] = temp; return result; &#125;&#125;; 本文的完整代码详见我的 GitHub 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 131. Palindrome Partitioning]]></title>
    <url>%2F2017%2F03%2F24%2Fleetcode-131%2F</url>
    <content type="text"><![CDATA[这篇文章是 LeetCode 131. Palindrome Partitioning 的分析与解法。 问题描述Given a string s, partition s such that every substring of the partition is a palindrome. Return all possible palindrome partitioning of s. For example, given s = &quot;aab&quot;, Return 1234[ [&quot;aa&quot;,&quot;b&quot;], [&quot;a&quot;,&quot;a&quot;,&quot;b&quot;]] 这道题的意思就是将给定的字符串分成回文串的组合，就像例子中所说，aab有两种回文串组合：aa,b和a,a,b. 问题分析对于这个问题，我们很简单的将它分解为两个子问题： 拆分字符串 判断一个字符串是否是回文串 Step 1 判断回文字符串如果一个字符串正读和反读结果都一样，我们就说它是一个回文字符串。判断一个字符串是不是回文的有很多种方法，我想起来 3 种方法，都会在接下来的文章中进行介绍，并给出源码（文中的代码皆为 C++）。 反转字符串法这个方法是最容易理解的，将字符串反转，如果和原来的字符串一样，那么它就是回文的，这个方法在编码上也是最简单的： 12345678bool isPalindrome_reverse(string s, int i, int j)&#123; string r = s; reverse(s.begin(),s.end()); if(s.compare(r)!=0)&#123; return false; &#125; return true;&#125; 双指针法双指针法是通过两个指针，一个指向字符串首，另一个指向字符串尾，如果两个指针指向的字符相同，则两个指针向中间移动，继续判断。 12345678910bool isPalindrome_doublepoints(string s, int i, int j)&#123; while(i &lt; j)&#123; if(s[i] != s[j])&#123; return false; &#125; i++; j--; &#125; return true;&#125; 递归法递归法和双指针法很类似，当前字符串是否回文取决于首尾字符是否相同，然后递归的判断除去首尾的剩余字符串是否回文。 1234567891011121314151617181920bool isPalindrome_recursion(string s, int i,int j)&#123; if(i == j)&#123; return true; &#125; else&#123; if(s[i] == s[j])&#123; i++; j--; if(i &lt; j)&#123; return isPalindrome_recursion(s, i, j); &#125; else&#123; return true; &#125; &#125; else&#123; return false; &#125; &#125;&#125; Step 2 拆分字符串这一步是这个问题的关键，解决拆分字符串的方案也有 2 种：暴力回溯法 和 递归法。 暴力回溯法暴力回溯法比较好理解，它使用的是回溯法的思想，我们穷举出来字符串的所有子串组合，然后判断其中的子串是不是回文的，去掉不符合要求的组合，剩余的就是我们要的结果。 在进行穷举的时候，如果遇到不是回文的子串，我们就进行回溯。 以题目中的aab为例： 实现代码如下： 1234567891011121314void backtrace(vector&lt;vector&lt;string&gt;&gt; &amp;vec, vector&lt;string&gt; &amp;temp, string s, int start)&#123; if(start == s.length())&#123; vec.push_back(temp); &#125; else&#123; for(int i = start; i &lt; s.length(); i++)&#123; if(isPalindrome(s, start, i))&#123; temp.push_back(s.substr(start, i-start+1)); backtrace(vec, temp, s, i+1); temp.pop_back(); &#125; &#125; &#125;&#125; 递归法递归法的思路是把一个字符串分为 A+B，如果 A 为回文则递归的求 B 的回文组合，然后将 A 和 B 的回文串组合做笛卡尔积。 以字符串 aabb 为例： 将aabb 分为 a+abb，然后求 abb 的回文组合为[a, b, b], [a, bb]，所以做笛卡尔积后为：[a, a, b,b ], [a, a, bb] 将字符串分为 aa+bb，然后求 bb 的回文组合为[b, b], [bb],结果为[aa, b, b], [aa, bb] 将字符串分为 aab+b，aab 不回文 aabb 回文，结果为[aabb] 最终结果为：[a, a, b,b ], [a, a, bb], [aa, b, b], [aa, bb], [aabb] 实现代码如下： 1234567891011121314151617181920212223242526272829303132vector&lt;vector&lt;string&gt;&gt; partition_recursion(string s)&#123; vector&lt;vector&lt;string&gt;&gt; vec; if(s.length() == 0)&#123; return vec; &#125; if(isPalindrome_recursion(s, 0, s.length()-1))&#123; vector&lt;string&gt; temp; temp.push_back(s); vec.push_back(temp); &#125; for(int i = 1; i &lt;= s.length(); i++)&#123; string left = s.substr(0, i); if(isPalindrome(left, 0, left.length()-1))&#123; string right = s.substr(i, s.length()-i); vector&lt;vector&lt;string&gt;&gt; rightVec = partition_recursion(right); if(rightVec.size() &gt; 0)&#123; for(int j = 0; j &lt; rightVec.size(); j++)&#123; vector&lt;string&gt; temp; temp.push_back(left); for(int x = 0; x &lt; rightVec[j].size(); x++)&#123; temp.push_back(rightVec[j][x]); &#125; vec.push_back(temp); &#125; &#125; &#125; &#125; return vec;&#125; 结果测试将几种方法组合后的测试结果如下： 反转字符串法 双指针法 递归法 暴力回溯法 16 ms 13 ms 13 ms 递归法 89 ms 76 ms 76 ms 我们看到回溯法要明显优于递归的方法。 本文的完整代码详见我的 GitHub 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从0到1学习Java线程池】一个Java线程池的简单实现]]></title>
    <url>%2F2017%2F03%2F15%2Fthread-pool-in-java-3%2F</url>
    <content type="text"><![CDATA[这是【从0到1学习Java线程池】系列文章的第 叁 篇，该系列文章总共三篇，介绍了 Java 线程池的使用以及原理，并且最后会实现一个基本的线程池。本篇文章实现了一个简单的 Java 线程池。 【从0到1学习Java线程池】系列文章共有3篇，目录如下： 【从0到1学习Java线程池】Java线程池的简介以及使用 【从0到1学习Java线程池】Java线程池原理 【从0到1学习Java线程池】一个Java线程池的简单实现 从上两篇文章中，我们已经知道了线程池的基本原理，这篇文章我们就来具体实现一个简单的 Java 线程池。 设计先行想要实现一个线程池，我们首先要来进行设计，考虑它需要有哪些功能，如何设计和安排这些功能是至关重要的。 在我们所要实现的 Java 线程池需要有： 任务队列：它能够添加或者删除任务，并且它还需要支持原子操作，不能同时有多个线程从中取出任务。 通知机制：如果任务队列为空，工作线程将会阻塞在获取任务这一操作上；如果这时任务队列中有了新的任务，需要通知工作线程从中获取任务来执行。 线程类：线程类的例程是用来获取任务和执行任务的。 任务类：用于被线程抓取和执行的任务。 线程管理类：能够创建一定数量的线程，并且提供对任务队列进行操作的方法（获取任务、添加任务等）。 具体实现系统配置类其中的参数主要是该线程池所支持的最大线程数 1234567public class SystemConfig &#123; static final int THREAD_POOL_MAX_SIZE = 20; public static int getThreadDefalutSize()&#123; return THREAD_POOL_MAX_SIZE; &#125;&#125; 任务类123456public class Task implements Runnable &#123; @Override public void run() &#123; &#125;&#125; 线程管理类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116public class ThreadPoolManager extends ThreadGroup &#123; int isThreadPoolValid = 0; int sizeOfPoolThread = SystemConfig.getThreadDefalutSize(); List&lt;Task&gt; taskList= new LinkedList&lt;Task&gt;(); public ThreadPoolManager(String threadpoolname) &#123; super(threadpoolname); setDaemon(true); &#125; public synchronized void startThreadPool()&#123; if(sizeOfPoolThread == 0 || isThreadPoolValid != 0)&#123; try&#123; throw new Exception(); &#125; catch(Exception exception)&#123; exception.printStackTrace(); &#125; return; &#125; if(taskList == null)&#123; try &#123; throw new Exception(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return; &#125; for(int i = 0; i &lt; sizeOfPoolThread; i++)&#123; new WorkThread(i).start(); &#125; isThreadPoolValid = 1; &#125; public synchronized void stopThreadPool()&#123; if(sizeOfPoolThread == 0 || isThreadPoolValid != 0)&#123; try&#123; throw new Exception(); &#125; catch(Exception exception)&#123; exception.printStackTrace(); &#125; return; &#125; if(taskList == null)&#123; try &#123; throw new Exception(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return; &#125; taskList.clear(); sizeOfPoolThread = 0; isThreadPoolValid = 0; interrupt(); &#125; public synchronized void addTask(Task newTask)&#123; if(taskList == null)&#123; try &#123; throw new Exception(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return; &#125; taskList.add(newTask); notify(); &#125; public synchronized Task getTask()&#123; if(taskList == null)&#123; try &#123; throw new Exception(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; while(taskList.size() == 0)&#123; try&#123; wait(); &#125;catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; return taskList.remove(0); &#125; private class WorkThread extends Thread&#123; public WorkThread(int threadID)&#123; super(ThreadPoolManager.this, ""+threadID); &#125; public void run()&#123; while(!isInterrupted())&#123; Task runTask = getTask(); if(runTask == null) break; runTask.run(); &#125; &#125; &#125;&#125; 运行测试测试代码测试任务 1234567891011public class TestTask extends Task &#123; private int i; public TestTask(int i)&#123; this.i = i; &#125; public void run()&#123; System.out.println("Task " + i + " is RUNNING."); &#125;&#125; 主程序 1234567891011public class ThreadPoolTest &#123; public static void main(String[] args) &#123; ThreadPoolManager manager = new ThreadPoolManager("SimplePool"); manager.startThreadPool(); for(int i = 0; i &lt; 5; i++)&#123; Task task = new TestTask(i); manager.addTask(task); &#125; &#125;&#125; 测试结果12345Task 3 is RUNNING.Task 4 is RUNNING.Task 1 is RUNNING.Task 0 is RUNNING.Task 2 is RUNNING. 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Java</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《创新的洞见》短评&书摘]]></title>
    <url>%2F2017%2F03%2F13%2Finsight-in-innovation%2F</url>
    <content type="text"><![CDATA[短评《创新的洞见》这本书是2016年年初出版的，其中写的好多是2015年互联网世界发生的事情，而我却是在2017年年初才看完的这本书，有些内容不免有些过时，因为在近几年中我国互联网世界的发展速度令人叹为观止，这个世界的变化天翻地覆。但是此书中的不少内容不失为经典，在书中的一些报告中，有许多创业者等等对当时未来的发展做出了预测，有些在两年后的今天看来十分准确，有些就显得有比较大的偏差了。但是，不论如何这些都是对创业者们十分有益、宝贵的阅读资料。当然了，由于书中选择了众多领域的不同人的文章或是报告，其中内容良莠不齐。 书摘 实际上以利润换市场无异于饮鸩止渴，最终会陷入不烧钱数据下降，烧钱又难以为继的两难，甚至不得不为了烧钱而损害未来的利益。 仓廪实而知礼节，衣食足而知荣辱，如果一个成年人日日为填饱肚子忙活，那就不要指望未来能有多大的空间。企业也是一样，当受制于资金支持随时可能断炊时，企业唯一能做的只有活下来，而不是过更好。 在特定时期VC可以让企业催熟、早产，甚至也不排除考虑杀鸡取卵。 BAT投资无外乎四种： 现有业务互补； 新兴业务布局； 财务投资； 抹杀创新，消除竞争。 最基本创业的初始点还是满足用户的需求，但是这样一个简简单单的一句话包含了三层意思，就是什么是用户的需求，谁是你的用户，以及怎么满足。除此之外，也是结合爱乐活的经验，有三点： 第一点，团队极其重要。 第二点，时机。 第三点，产品是最重要的。 我们犯的错误都是来自于对你内心里面相信的东西，是否有足够的坚定、坚持以及决心，还是说会过于犹豫，会迫于压力和利益，最后选择了妥协。 这个世界从不在乎你输入了什么，而在乎你输出了什么。 移动互联网和我们可以预见的可穿戴设备像一只吸血鬼，它让每个人都可以消费有价值的内容，而从不产生任何有价值的内容。 白花花的银子背后是钢铁般的团队，钢铁般的团队背后是老大金子般的人品。 黑塞说：“对于每个人而言，真正的职责只有一个：找到自我，然后在心中坚守其一生，全心全意，永不停息。所有其他的路都是不完整的，是人的逃避方式，是对大众期望的懦弱回归，是随波逐流，是对内心的恐惧。”你最怕的人，其实是你自己。 元数据是描述数据属性的集合，是对数据的说明,比如，数据的类型、名称、字段等。 数据与元数据可以这样来区别，前者是内容，后者是背景。背景常常比内容显示更多的信息，尤其是把元数据集合起来的时候。 互联网的流量变现的三个途径：广告、游戏和电子商务。 一对多是追求效率的提升，追求规模的最大化才能赚到钱。而一对一是追求个性化的匹配，因为打败极致效率的唯一方法就是个性化。 一鱼多吃，就是拿入口向产业链的上下游的延伸；一鱼三吃，就是锁定同样的人群，满足他们不同的跨行业的需求，表面跨行业，但是相对顺理成章。 理想的组织永远在跟着组织目标走，如果需要颗粒度更密集，那就把组织单位更加细小；如果发生阶段性变化，那适度弹性的组织更能胜任。其中，快速沟通和响应机制是必须的，尤其在瞬息万变的互联网行业。既然目标很难量化，那招合适的人适度放权就是一个必须的选择。 巨头试图通过扶植代理人的形式扩大制定游戏规则的边界，而那些倍受期许的独立势力正在左右逢源争取更高的收编价码。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>书摘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从0到1学习Java线程池】Java线程池原理]]></title>
    <url>%2F2017%2F02%2F27%2Fthread-pool-in-java-2%2F</url>
    <content type="text"><![CDATA[这是【从0到1学习Java线程池】系列文章的第 贰 篇，该系列文章总共三篇，介绍了 Java 线程池的使用以及原理，并且最后会实现一个基本的线程池。本篇文章介绍了 Java 线程池的原理。 【从0到1学习Java线程池】系列文章共有3篇，目录如下： 【从0到1学习Java线程池】Java线程池的简介以及使用 【从0到1学习Java线程池】Java线程池原理 【从0到1学习Java线程池】一个Java线程池的简单实现 在上一篇文章中（【从0到1学习Java线程池】Java线程池的简介以及使用），我们总结了线程池的3个优点： 线程复用 控制最大并发数 管理线程 这篇文章会分别从这三个方面，结合具体的代码实现来剖析 Java 线程池的原理以及它的具体实现。 线程复用我们知道线程池的一个作用是创建和销毁线程的次数，每个工作线程可以多次使用。这个功能就是线程复用。想要了解 Java 线程池是如何进行线程复用的，我们首先需要了解线程的生命周期。 线程生命周期下图描述了线程完整的生命周期： 在一个线程完整的生命周期中，它可能经历五种状态：新建（New）、就绪（Runnable）、运行（Running）、阻塞（Blocked）、终止（Zombie）。 在 Java中，Thread 通过new来新建一个线程，这个过程是是初始化一些线程信息，如线程名、id、线程所属group等，可以认为只是个普通的对象。调用Thread的start()后Java虚拟机会为其创建方法调用栈和程序计数器，同时将hasBeenStarted为true，之后如果再次调用start()方法就会有异常。 处于这个状态中的线程并没有开始运行，只是表示该线程可以运行了。至于该线程何时开始运行，取决于 JVM 里线程调度器的调度。当线程获取CPU后，run()方法会被调用。不要自己去调用Thread的run()方法。之后根据CPU的调度，线程就会在就绪—运行—阻塞间切换，直到run()方法结束或其他方式停止线程，进入终止状态。 因此，如果要实现线程的复用，我们必须要保证线程池中的线程保持存活状态（就绪、运行、阻塞）。接下来，我们就来看看ThreadPoolExecutor是如何实现线程复用的。 Worker 类ThreadPoolExecutor主要是通过一个类来控制线程复用的：Worker 类。 我们来看一下简化后的 Worker 类代码： 12345678910111213141516171819202122232425private final class Worker implements Runnable &#123; final Thread thread; Runnable firstTask; Worker(Runnable firstTask) &#123; this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; public void run() &#123; runWorker(this); &#125; final void runWorker(Worker w) &#123; Runnable task = w.firstTask; w.firstTask = null; while (task != null || (task = getTask()) != null)&#123; task.run(); &#125; &#125; ……&#125; 从代码中，我们可以看到 Worker 实现了 Runnable 接口，并且它还有一个 Thread成员变量 thread，这个 thread 就是要开启运行的线程。我们看到 Worker 的构造方法中传递了一个 Runnable 参数，同时它把自己作为参数传入 newThread()，这样的话，当 Thread 的start()方法得到调用时，执行的其实是 Worker 的run()方法，即runWorker()方法。 runWorker()方法之中有一个 while 循环，使用 getTask()来获取任务，并执行。接下来，我们将会看到getTask()是如何获取到 Runnable 对象的。 getTask()我们来看一下简化后的getTask()代码： 1234567private Runnable getTask() &#123; if(一些特殊情况) &#123; return null; &#125; Runnable r = workQueue.take(); return r;&#125; 我们可以看到任务是从 workQueue中获取的，这个 workQueue 就是我们初始化 ThreadPoolExecutor 时存放任务的 BlockingQueue队列，这个队列里的存放的都是将要执行的 Runnable任务。因为 BlockingQueue 是个阻塞队列，BlockingQueue.take()返回的是空，则进入等待状态直到 BlockingQueue 有新的对象被加入时唤醒阻塞的线程。所以一般情况下，Thread的run()方法不会结束，而是不断执行workQueue里的Runnable任务，这就达到了线程复用的目的了。 控制最大并发数我们现在已经知道了 Java 线程池是如何做到线程复用的了，但是Runnable 是什么时候被放入 workQueue 队列中的呢，Worker里的Thread的又是什么时候调用start()开启新线程来执行Worker的run()方法的呢？从上面的分析中我们可以看出Worker里的runWorker()执行任务时是一个接一个，串行进行的，那并发是怎么体现的呢？它又是如何做到控制最大并发数的呢？ execute()通过查看 execute()就能解答上述的一些问题，同样是简化后的代码： 12345678910111213141516171819202122232425public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // 当前线程数 &lt; corePoolSize if (workerCountOf(c) &lt; corePoolSize) &#123; // 直接启动新的线程。 if (addWorker(command, true)) return; c = ctl.get(); &#125; // 活动线程数 &gt;= corePoolSize // runState为RUNNING &amp;&amp; 队列未满 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // 再次检验是否为RUNNING状态 // 非RUNNING状态 则从workQueue中移除任务并拒绝 if (!isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 采用线程池指定的策略拒绝任务 // 两种情况： // 1.非RUNNING状态拒绝新的任务 // 2.队列满了启动新的线程失败（workCount &gt; maximumPoolSize） &#125; else if (!addWorker(command, false)) reject(command);&#125; addWorker()我们再来看一下addWorker()的简化代码： 123456789private boolean addWorker(Runnable firstTask, boolean core) &#123; int wc = workerCountOf(c); if (wc &gt;= (core ? corePoolSize : maximumPoolSize)) &#123; return false; &#125; w = new Worker(firstTask); final Thread t = w.thread; t.start();&#125; 根据上面的代码，线程池工作过程中是如何添加任务的就很清晰了： 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务； 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列； 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务； 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常RejectExecutionException 如果通过addWorker()成功创建新的线程，则通过start()开启新线程，同时将firstTask作为这个Worker里的run()中执行的第一个任务。虽然每个Worker的任务是串行处理，但如果创建了多个Worker，因为共用一个workQueue，所以就会并行处理了。所以可以根据corePoolSize和maximumPoolSize来控制最大并发数。 过程如下图所示： 一个例子如果是做 Android 开发的，并且对 Handler 原理比较熟悉，你可能会觉得这个图挺熟悉，其中的一些过程和Handler，Looper，Meaasge使用中，很相似。Handler.send(Message)相当于execute(Runnuble)，Looper中维护的Meaasge队列相当于BlockingQueue，只不过需要自己通过同步来维护这个队列，Looper中的loop()函数循环从Meaasge队列取Meaasge和Worker中的runWork()不断从BlockingQueue取Runnable是同样的道理。 管理线程上边的文章已经讲了，通过线程池可以很好的管理线程的复用，控制并发数，以及销毁等过程，而线程的管理过程已经穿插在其中了，也很好理解。 在 ThreadPoolExecutor 有个AtomicInteger变量 ctl，这一个变量保存了两个内容： 所有线程的数量 每个线程所处的状态 其中低29位存线程数，高3位存runState，通过位运算来得到不同的值。 12345678910private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));//得到线程的状态private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;//得到Worker的的数量private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;// 判断线程是否在运行private static boolean isRunning(int c) &#123; return c &lt; SHUTDOWN; &#125; 这里主要通过shutdown和shutdownNow()来分析线程池的关闭过程。首先线程池有五种状态来控制任务添加与执行。主要介绍以下三种： RUNNING状态：线程池正常运行，可以接受新的任务并处理队列中的任务； SHUTDOWN状态：不再接受新的任务，但是会执行队列中的任务； STOP状态：不再接受新任务，不处理队列中的任务 shutdown()这个方法会将runState置为SHUTDOWN，会终止所有空闲的线程，而仍在工作的线程不受影响，所以队列中的任务人会被执行；shutdownNow()方法将runState置为STOP。和shutdown()方法的区别是，这个方法会终止所有的线程，所以队列中的任务也不会被执行了。 参考资料：http://www.kuqin.com/shuoit/20160829/352799.html 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Java</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从0到1学习Java线程池】Java线程池的简介以及使用]]></title>
    <url>%2F2017%2F02%2F26%2Fthread-pool-in-java-1%2F</url>
    <content type="text"><![CDATA[这是【从0到1学习Java线程池】系列文章的第 壹 篇，该系列文章总共三篇，介绍了 Java 线程池的使用以及原理，并且最后会实现一个基本的线程池。本篇文章主要介绍了 Java 线程池以及它的使用。 【从0到1学习Java线程池】系列文章共有3篇，目录如下： 【从0到1学习Java线程池】Java线程池的简介以及使用 【从0到1学习Java线程池】Java线程池原理 【从0到1学习Java线程池】一个Java线程池的简单实现 线程池是什么？线程池用于多线程处理中，它可以根据系统的情况，可以有效控制线程执行的数量，优化运行效果。线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量超出数量的线程排队等候，等其它线程执行完毕，再从队列中取出任务来执行。 线程池的作用在面向对象的编程过程中，创建对象和销毁对象是非常消耗时间和资源的。因此想要最小化这种消耗的一种思想就是『池化资源』。线程池就是这样的一种思想。我们通过重用线程池中的资源来减少创建和销毁线程所需要耗费的时间和资源。 线程池的一个作用是创建和销毁线程的次数，每个工作线程可以多次使用；另一个作用是可根据系统情况调整执行的线程数量，防止消耗过多内存。另外，通过线程池，能有效的控制线程的最大并发数，提高系统资源利用率，同时避免过多的资源竞争，避免堵塞。 线程池的优点总结如下几个方面： 线程复用 控制最大并发数 管理线程 线程池的组成一般的线程池主要分为以下4个组成部分： 线程池管理器：用于创建并管理线程池 工作线程：线程池中的线程 任务接口：每个任务必须实现的接口，用于工作线程调度其运行 任务队列：用于存放待处理的任务，提供一种缓冲机制 线程池的常见应用场景许多服务器应用常常需要处理大量而短小的请求（例如，Web 服务器，数据库服务器等等），通常它们收到的请求数量很大，一个简单的模型是，当服务器收到来自远程的请求时，为每一个请求开启一个线程，在请求完毕之后再对线程进行销毁。这样处理带来的问题是，创建和销毁线程所消耗的时间往往比任务本身所需消耗的资源要大得多。那么应该怎么办呢？ 线程池为线程生命周期开销问题和资源不足问题提供了解决方案。我们可以通过线程池做到线程复用，不需要频繁的创建和销毁线程，让线程池中的线程一直存在于线程池中，然后线程从任务队列中取得任务来执行。而且这样做的另一个好处有，通过适当地调整线程池中的线程数目，也就是当请求的数目超过某个阈值时，就强制其它任何新到的请求一直等待，直到获得一个线程来处理为止，从而可以防止资源不足。 Java线程池的简介Java中提供了实现线程池的框架Executor，并且提供了许多种类的线程池，接下来的文章中将会做详细介绍。 Java线程池框架Java中的线程池是通过Executor框架实现的，该框架中用到了Executor，Executors，ExecutorService，ThreadPoolExecutor ，Callable和Future、FutureTask这几个类。 Executor：所有线程池的接口，只有一个方法 Executors：Executor 的工厂类，提供了创建各种不同线程池的方法，返回的线程池都实现了ExecutorService 接口 ThreadPoolExecutor：线程池的具体实现类，一般所有的线程池都是基于这个类实现的 其中ThreadPoolExecutor的构造方法如下： 12345678910public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);&#125; 其中： corePoolSize：线程池的核心线程数，线程池中运行的线程数也永远不会超过 corePoolSize 个，默认情况下会永远存活 maximumPoolSize：线程池中允许的最大线程数 keepAliveTime：空闲线程结束的超时时间 unit：是一个枚举，它表示的是 keepAliveTime 的单位 workQueue：工作队列，用于任务的存放 Java线程池的工作过程Java线程池的工作过程如下： 线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们。 当调用 execute() 方法添加一个任务时，线程池会做如下判断： 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务； 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列； 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务； 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常RejectExecutionException。 当一个线程完成任务时，它会从队列中取下一个任务来执行。 当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。 常见的Java线程池生成线程池使用的是Executors的工厂方法，以下是常见的 Java 线程池： SingleThreadExecutorSingleThreadExecutor是单个线程的线程池，即线程池中每次只有一个线程在运行，单线程串行执行任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0,Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; FixedThreadPoolFixedThreadPool是固定数量的线程池，只有核心线程，每提交一个任务就是一个线程，直到达到线程池的最大数量，然后后面进入等待队列，直到前面的任务完成才继续执行。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; CachedThreadPoolCachedThreadPool是可缓存线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。其中，SynchronousQueue是一个是缓冲区为1的阻塞队列。 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0,Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; ScheduledThreadPoolScheduledThreadPool是核心线程池固定，大小无限制的线程池，支持定时和周期性的执行线程。创建一个周期性执行任务的线程池。如果闲置,非核心线程池会在DEFAULT_KEEPALIVEMILLIS时间内回收。 12345public static ExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPool(corePoolSize, Integer.MAX_VALUE, DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS, new DelayedWorkQueue());&#125; Java 线程池的创建和使用我们可以通过Executors的工厂方法来创建一个线程池。但是我们该如何让线程池执行任务呢？ 线程池最常用的提交任务的方法有两种： execute： 1ExecutorService.execute(Runnable runable)； submit： 123FutureTask task = ExecutorService.submit(Runnable runnable);FutureTask&lt;T&gt; task = ExecutorService.submit(Runnable runnable,T Result);FutureTask&lt;T&gt; task = ExecutorService.submit(Callable&lt;T&gt; callable); 可以看出submit开启的是有返回结果的任务，会返回一个FutureTask对象，这样就能通过get()方法得到结果。submit最终调用的也是execute(Runnable runable)，submit只是将Callable对象或Runnable封装成一个FutureTask对象，因为FutureTask是个Runnable，所以可以在execute中执行。 下面的示例代码演示了如何创建一个线程池，并且使用它管理线程： 123456public class MyThread extends Thread &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + " is running."); &#125;&#125; 1234567891011121314151617181920public class TestSingleThreadExecutor &#123; public static void main(String[] args) &#123; //创建一个可重用固定线程数的线程池 ExecutorService pool = Executors.newFixedThreadPool(2); //创建实现了Runnable接口对象 Thread tt1 = new MyThread(); Thread tt2 = new MyThread(); Thread tt3 = new MyThread(); Thread tt4 = new MyThread(); Thread tt5 = new MyThread(); //将线程放入池中并执行 pool.execute(tt1); pool.execute(tt2); pool.execute(tt3); pool.execute(tt4); pool.execute(tt5); //关闭 pool.shutdown(); &#125;&#125; 运行结果： 12345pool-1-thread-1 is running.pool-1-thread-2 is running.pool-1-thread-1 is running.pool-1-thread-2 is running.pool-1-thread-1 is running. 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Java</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[山东大学人工智能课程复习提要（2017）]]></title>
    <url>%2F2017%2F02%2F03%2FAI-sdu-2016-summary%2F</url>
    <content type="text"><![CDATA[本篇博客为山东大学人工智能课程（2016-2017）的复习提要，希望对大家的考试复习有所帮助。 填空部分 构成产生式系统的基本元素有综合数据库、规则库、控制系统，控制策略按执行规则的方式分类，分为正向、逆向、双向三类。 归结过程中控制策略的作用是给出控制策略，以使仅对选择合适的子句间方可做归结，避免多余的、不必要的归结式出现。常见的控制策略有线性归结策略、支持集策略、单元归结策略、输入归结策略。 公式 G 和公式的子句集并不等值，但他们在不可满足的意义下是一致的。 与或图的启发式搜索算法 AO*算法的两个过程分别是分解（将复杂的大问题分解为一组简单的小问题）和变换（将较难问题变换为较容易的等价的或等效的问题） 人工智能的研究途径主要有两种不同的观点，一种观点称为符号主义，认为人类智能基本单元是符号。另一种观点称为连接主义，认为职能的基本单元是神经元。 集合{P(a, x, f(g(y)), P(z, f(z), f(u)))} 的 mgu（最一般合一置换）为 {z/a, f(x)/x, u/g(y)}。 语义网络是对知识的有向图表示方法，一个最简单的语义网络是一个形如节点、弧、节点的三元组，语义网络可以描述事物间多种复杂的语义关系，常用 ISA、AKO 弧表示节点间具有类属的分类关系。语义网络下的推理是通过匹配、继承实现的。 当前人工智能研究的热点之一就是机器学习。常见的机器学习方法课分为决策树学习、神经网络、蚁群算法、粒子群算法和遗传算法等。一个机器学习系统应该有环境、知识库、学习环节和执行环节四个基本部分组成。 常用的知识表示法有逻辑表示法、语义网络、框架理论、过程表示、脚本表示等。 有两个算法 A*算法 A1 和 A2，若 A1比 A2有较多的启发信息，则 h1(n) 大于 h2(n) 关于 A 算法与 A*算法，若规定 h(n)&gt;=0,并且定义启发函数：f*(n) = g*(n)+h*(n) 表示初始状态 S0 经点 n 到目标状态 Sg最优路径的费用。其中 g*(n) 为 S0 到 n 的最小费用，h*(n) 为到 Sg 的实际最小费用。若另 h(n)==0 ，则 A算法相当于宽度优先搜索。若另 g(n)==h(n)==0 ，则相当于随机算法。若另 g(n)==0 ，则相当于最佳优先算法。特别是当要求 h(n)&lt;=h*(n)，就称这种 A 算法为 A* 算法。 群智能是指无智能或简单智能的主题通过任何形式的聚集协同二表现出智能行为的特点。群智能潜在的两大特点是并行性和分布式。其典型算法有蚁群算法和粒子群算法。已知的群智能理论的研究和应用证明群智能算法是一种能够有效解决大多数优化问题的新方法。 蚁群算法是模拟自然界中蚂蚁寻找从巢穴到食物的最佳路径的行为而设计的，蚂蚁在遇到食物返回的路上会分泌信息素，信息素会随着时间慢慢挥发，且关键路径上的信息素相对浓度高，蚁群算法已被广泛应用于许多优化问题中，其中有聚类问题、路由算法设计、图着色、车辆调度、机器人路径规划。 粒子群优化算法是模拟鸟群或蜂群或个体之间的协作和信息共享的觅食行为而设计的，其基本思想是通过群体中广泛应用于各类优化问题上和在军事领域中的应用来寻找最优解。粒子群优化算法的应用领域有对巡航导弹的飞行高度进行优化、车辆路径问题的应用、邮政投递、火车及汽车的调度、港口装卸集装箱。 遗传算法是以达尔文的自然选择学说为基础发展起来的。遗传算法的三种基本操作是复制、交叉、变异；在遗传算法中，衡量个体优劣的尺度是适应度，它决定某些个体是繁殖或是消亡，同时也是驱动遗传算法的动力。 蚁群算法是模拟自然界中蚂蚁寻找从巢穴到食物的最佳路径的行为而设计的，依据蚁群算法的基本原理，蚁群算法中的行为因子有觅食规则、移动规则、避障规则、信息素规则、范围、环境等。 近年有学者提出的人工鱼群算法（Artificial Fish Swarm Algorith - AFSA）是模仿自然界中鱼群的行为而提出来的解决问题的算法，从模拟鱼群的聚集行为、觅食行为、跟随行为和移动行为等方面来模拟自然界中的鱼群行为。 遗传算法将『优胜劣汰，适者生存』的生物进化原理引入优化参数形成的编码串群体中，按所选择的适应度函数并通过遗传中的复制、交叉以及变异对个体进行筛选，适应度高的个体被保留下来，组成新的群体，新的群体既继承了上一代的信息，又优于上一代。 决策树是一种知识概念表示方法，能表示与或规则；是一种图形表示的监督学习方法。而人工神经网络（ANNs）是非图形符号表示法，又是一种函数表示法；即从大量的数据中学习值为实数、离散值或向量的函数。人工神经网络对于训练数据中『错误』数据的错误健壮性很好。人工神经网络的训练学习过程中有一个称为『学习速率 n』的常数，n取值过大会引起漂移，n 取值过小会收敛速度太慢，学习效率不高。大量的数据中抽取规则函数，错误健壮性很好。 多层神经网络的学习过程中有一种是反向传播算法（Back Propagation-BP）， 其基本思想是利用输出单元的误差再计算上一层单元的误差，以次向上传播以次向上传播，俗称反向传播。又称逆推学习算法。 归纳学习需要的预先假定，称为归纳偏置，归纳学习算法隐含了归纳偏置， 候选消除算法的归纳偏置是目标概念可以在假设空间中找到，所以又称限定偏置。ID3是一种典型的决策树学习方法，ID3的归纳偏置有两点，分别是搜索完整的假设空间，优先选择较小的树。Find-S 算法寻找极大特殊假设使用一般到特殊序，在偏序结构的一个分支上 执行一般到特殊搜索搜索，寻找一个与样例一致的最特殊假设。 自然语言处理是研究用机器处理人类语言的理论和技术,又叫自然语言理解, 它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法, 自然语言处理研究面临的两大困难是歧义病构和音歧义,其中歧义分为分词歧义、短语歧义、词义歧义、 语用歧义四个方面。 在证据理论(Evident Theory)中引入了信任函数(BeL)，它满足了概率论弱公理。在概率论中，当先验概率很难获得，但又要被迫给出时，用证据理论能区分不确定性和不知道的差别。因而它比概率论更 适合于专家系统推理方法。概率论是证据理论的一个特例，有时也称证据理论为广义概率论。 贝叶斯网是一个在弧的连接关系上加入连接强度 的因果关系网络。由两个部分组成，其一是 DAG，即 有向无环图 ;其二是 CPT， 即 概率分配表 。贝叶斯网络通常使用三种推理是 因果推理 、 诊断推理 、 辩解推理 。 在确定性推理模型中的可信度因子 CF(H,E) 证据 e 得到的假设 h 的确定性因子 的取值范围为[-1,+1] ;主观 Bayes 方法中规定规 则的静态强度 LS,LN 的值应 [0,∞)。 简答部分 人工智能方法与传统程序的不同有哪些？ 答：传统方法解决问题利用已有知识 , 问题可以方便的结构化数据结构 , 数学形式表达， 数学公式、算法。利用知识特别是依赖人类经验的启发知识是人工智能方法与传统数学方法的根本不同之处，基于此，人工智能可以解决众多的难以数学表达的非结构化 的实际问题 , 人工智能首先研究的是以符号表示的知识 , 而不是数值为研究对象 , 其次采用的是启发式推理的方法而不是常规的算法 , 控制结构和领域知识是分离的，同时还允许出现相对正确的答案。 在与或图的问题求解过程中，哪几类节点称为能解节点? 答：终节点是能解节点；若非终节点有”或”子节点时，当且仅当其子节点至少有一能解时，该非终节点才能解；若非终节点有”与”子节点时，当且仅当其子节点均能解时，该非终节点才能解。 宽度优先搜索和深度优先搜索有何不同?在何种情况下宽度优先搜索优于深度优先搜索?在何种情况下深度优先搜索优于宽度优先搜索?两种搜索策略是否都是完备的? 答：宽度优先搜索就是逐层穷举搜索。深度优先搜索就是分支优先搜索待搜索问题的解存在且关键路径较短时宽 度优先搜索优于深度优先搜索;待搜索问题的解存在且关键路径较长，而深度优先搜索过程中优先发展的正好是解所在的路径时深度优先搜索优于宽度优先搜索。宽度优先搜索是完备的 。 举例解释语义网络(Semantic Network)与知识图谱(Knowledge graph)的区别与联系。 答：知识图谱是通过将数学、图形学、可视化技术、信息科学等的理论与方法与计量学的引文分析、共现分析等方法结合，并利用可视化的图谱形象地展示知识体系的方法。 它把复杂的知识领域通过数据挖掘、信息处理、知识计量和图形绘制而显示出来，揭示知识领域的动态发展规律， 为学科研究供切实的、有价值的参考。 据不完全统计，Google 知识图谱到目前为止包含了 5 亿个实体和 35 亿条事实(形如实体-关系-实体， 和实体-属性值)。 语义网络 特点 (1) 结构性好: 语义网络是一种结构化的知识表示方法，它能够把事物的属性和事物间的各种语义关系显示地表示出来; (2)联想性: 语义网络作为人类联想记忆模型提出来，强调的就是事物之间的语义关系。 (3)自然性: 语义网络实际上是一个带有标示的有向图，可直观的把事物的属性及事物间的语义联系表示出来，便于理解。 利用语义网络表示知识的问题有:自然语言理解，问答系统， 专家系统等。 缺点:推理规则不十分明显，表达范围有限，一旦结点个数太多，网络结构复杂。 举例说明大型应用软件系统开发过程中采用的软件技术(体系)架构是如何体现框架理论知识表示思想的。 答：软件开发过程中框架理论的使用软件框架(架构)特点: 为某一特定目的实现一个基本的、可执行的 构架 ；包含了应用程序从启动到运行的主要流程；流程中那些无法确定的步骤留给用户来实现；程序运行时框架系统自动调用用户实现的功能组件；系统的行为是主动的。 软件开发过程中框架理论的使用：人们将相同类型问题的解决途径进行抽象， 抽取成一个应用框架 Framework；提供了一套明确机制；让开发人员很容易的扩展和控制整个 Framework 开发上的结构。 软件开发过程中框架理论的使用： 系统级框架： MFC 框架、 .NET 中的应用框架、 JavaAWT 中间件框架： Spring 框架、 Struts 框架、 Hibernate 框架、 EXTjs 框架 企业应用框架为不同行业的应用开发专用的企业级框架系统 ：JBOSS, eBOSS, websphere等 软件开发过程中框架理论的使用： Struts 框架: Struts 对 Model，View 和 Controller 都提供了对应的组件; Mode 槽:ActionForm 和 JavaBean 组成; View 槽: JSP(或 HTML、PHP……)实现; Controller 槽:核心控制器，业务逻辑控制器。 简要说明粒子群优化算法与遗传算法的共性和差异。 共性：( 1 )都属于仿生算法;( 2 )都属于全局优化方法;( 3 )都属于随机搜索算法;( 4 )都隐含并行性;( 5 )根据个体的适配信息进行搜索，因此不受函数约束条件的限制， 如连续性、可导性等;( 6 )对高维复杂问题，往往会遇到早熟收敛和收敛性能差的缺点，都无法保证收敛到最优点。 差异：(1) PSO 有记忆，所有粒子都保存较优解的知识，而 GA ，以前的知识随着种群的改变被改变; (2) PSO 中的粒子是一种单向共享信息机制。而 GA 中的染色体之间相互共享信息，使得整个种群都向最优区域移动; (3) GA 需要编码和遗传操作，而 PSO 没有交叉和变异操作，粒子只是通过内部速度进行更新，因此原理更简单、参数更少、实现更容易。 影响算法 A 启发能力的重要因素有哪些。 ( 1 )路径的耗散值; ( 2 )求解路径时所扩展的节点数; ( 3 )计算 h 所需的工作量。 因此选择 h 函数时，应综合考虑这些因素以便使启发能力最大 决策树学习法与神经网络学习法的区别。 决策树是知识一种图形符号表示，能表示与或规则;形象直观地图形符号 神经网络学习是非图形符号表示法，是一种函数表示法;从大量的数据中抽取规则函数 为什么说遗传算法是一种“智能式搜索”，又是一种“渐进式优化搜索”。 遗传算法的搜索策略，既不是盲目式的乱搜索，也不是穷举式的全面搜索， 它是有指导的搜索。指导遗传算法执行搜索的依据是适应度，也就是它的目标函数。利用适应度，使遗传算法逐步逼近目标值。 渐进式优化 : 遗传算法利用复制、交换、突变等操作，使新一代的结果优越于旧一代，通过不断迭代，逐渐得出最优的结果，它是一种反复迭代的过程 简述α-β过程的剪枝规则。 后辈节点的值≤祖先节点的值时，α剪枝 后辈节点的值≥祖先节点的值时，β剪枝 简述关于群智能理论(算法)研究存在那些问题。 数学理论基础相对薄弱，涉及的各种参数设置没有确切的理论依据带有随机性，每次的求解不一定一样，当处理突发事件时，系统的反映可能是不可预测的，这在一定程度上增加了其应用风险。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>AI</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 Raspberry3 上搭建 Go 环境]]></title>
    <url>%2F2017%2F02%2F02%2Frun-go-on-raspberry-3%2F</url>
    <content type="text"><![CDATA[这篇博客讲的是如何在 Raspberry3（树莓派3）上搭建 Go 语言环境，所使用的 Go 语言的版本是1.7.4 搭建Go环境 ssh 登录树莓派 1ssh pi@YOUR_RASPBERRY_IP 下载源码 1wget https://storage.googleapis.com/golang/go1.7.4.linux-armv6l.tar.gz 解压源码 1sudo tar -C /usr/local/ -xzf go/go1.7.4.linux-armv6l.tar.gz 修改环境变量 1sudo nano /etc/profile 在文件中加入： 1export PATH=$PATH:/usr/local/go/bin 测试安装在控制台输入： 1go version 控制台输出： 1go version go1.7.4 linux/arm 即为安装成功。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>raspberry</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raft 一致性算法论文译文]]></title>
    <url>%2F2017%2F02%2F02%2Fraft-paper-in-zh-CN%2F</url>
    <content type="text"><![CDATA[本篇博客为著名的 RAFT 一致性算法论文的中文翻译，论文名为《In search of an Understandable Consensus Algorithm (Extended Version)》(寻找一种易于理解的一致性算法) 摘要Raft 是一种用来管理日志复制的一致性算法。它和 Paxos 的性能和功能是一样的，但是它和 Paxos 的结构不一样；这使得 Raft 更容易理解并且更易于建立实际的系统。为了提高理解性，Raft 将一致性算法分为了几个部分，例如领导选取（leader selection），日志复制（log replication）和安全性（safety），同时它使用了更强的一致性来减少了必须需要考虑的状态。从用户学习的结果来看，Raft 比 Paxos 更容易学会。Raft 还包括了一种新的机制来使得动态改变集群成员，它使用重叠大多数（overlapping majorities）来保证安全。 1 引言一致性算法允许一组机器像一个整体一样工作，即使其中的一些机器出了错误也能正常工作。正因为此，他们扮演着建立大规模可靠的软件系统的关键角色。在过去的十年中 Paxos 一直都主导着有关一致性算法的讨论：大多数一致性算法的实现都基于它或者受它影响，并且 Paxos 也成为了教学生关于一致性知识的主要工具。 不幸的是，尽管在降低它的复杂性方面做了许多努力，Paxos 依旧很难理解。并且，Paxos 需要经过复杂的修改才能应用于实际中。这些导致了系统构构建者和学生都十分头疼。 在被 Paxos 折磨之后，我们开始寻找一种在系统构建和教学上更好的新的一致性算法。我们的首要目标是让它易于理解：我们能不能定义一种面向实际系统的一致性算法并且比 Paxos 更容易学习呢？并且，我们希望这种算法能凭直觉就能明白，这对于一个系统构建者来说是十分必要的。对于一个算法，不仅仅是让它工作起来很重要，知道它是如何工作的更重要。 我们工作的结果是一种新的一致性算法，叫做 Raft。在设计 Raft 的过程中我们应用了许多专门的技巧来提升理解性，包括算法分解（分为领导选取（leader selection），日志复制（log replication）和安全性（safety））和减少状态（state space reduction）（相对于 Paxos，Raft 减少了非确定性的程度和服务器互相不一致的方式）。在两所学校的43个学生的研究中发现，Raft 比 Paxos 要更容易理解：在学习了两种算法之后，其中的33个学生回答 Raft 的问题要比回答 Paxos 的问题要好。 Raft 算法和现在一些已经有的算法在一些地方很相似（主要是 Oki 和 Liskov 的 Viewstamped Replication。但是 Raft 有几个新的特性： 强领导者（Strong Leader）：Raft 使用一种比其他算法更强的领导形式。例如，日志条目只从领导者发送向其他服务器。这样就简化了对日志复制的管理，使得 Raft 更易于理解。 领导选取（Leader Selection）：Raft 使用随机定时器来选取领导者。这种方式仅仅是在所有算法都需要实现的心跳机制上增加了一点变化，它使得在解决冲突时更简单和快速。 成员变化（Membership Change）：Raft 为了调整集群中成员关系使用了新的联合一致性（joint consensus）的方法，这种方法中大多数不同配置的机器在转换关系的时候会交迭（overlap）。这使得在配置改变的时候，集群能够继续操作。 我们认为，Raft 在教学方面和实际实现方面比 Paxos 和其他算法更出众。它比其他算法更简单、更容易理解；它能满足一个实际系统的需求；它拥有许多开源的实现并且被许多公司所使用；它的安全特性已经被证明；并且它的效率和其他算法相比也具有竞争力。 这篇论文剩下的部分会讲如下内容：复制状态机（replicated state machine）问题（第2节），讨论 Paxos 的优缺点（第3节），讨论我们用的为了达到提升理解性的方法（第4节），陈述 Raft 一致性算法（第5~8节），评价 Raft 算法（第9节），对相关工作的讨论（第10节）。 2 复制状态机（Replicated State Machine）一致性算法是在复制状态机的背景下提出来的。在这个方法中，在一组服务器的状态机产生同样的状态的副本因此即使有一些服务器崩溃了这组服务器也还能继续执行。复制状态机在分布式系统中被用于解决许多有关容错的问题。例如，GFS，HDFS还有 RAMCloud 这些大规模的系统都是用一个单独的集群领导者，使用一个单独的复制状态机来进行领导选取和存储配置信息来应对领导者的崩溃。使用复制状态机的例子有 Chubby 和 ZooKeeper。 图-1：复制状态机的架构。一致性算法管理来自客户端状态命令的复制日志。状态机处理的日志中的命令的顺序都是一致的，因此会得到相同的执行结果。 如图-1所示，复制状态机是通过复制日志来实现的。每一台服务器保存着一份日志，日志中包含一系列的命令，状态机会按顺序执行这些命令。因为每一台计算机的状态机都是确定的，所以每个状态机的状态都是相同的，执行的命令是相同的，最后的执行结果也就是一样的了。 如何保证复制日志一致就是一致性算法的工作了。在一台服务器上，一致性模块接受客户端的命令并且把命令加入到它的日志中。它和其他服务器上的一致性模块进行通信来确保每一个日志最终包含相同序列的请求，即使有一些服务器宕机了。一旦这些命令被正确的复制了，每一个服务器的状态机都会按同样的顺序去执行它们，然后将结果返回给客户端。最终，这些服务器看起来就像一台可靠的状态机。 应用于实际系统的一致性算法一般有以下特性： 确保安全性（从来不会返回一个错误的结果），即使在所有的非拜占庭（Non-Byzantine）情况下，包括网络延迟、分区、丢包、冗余和乱序的情况下。 高可用性，只要集群中的大部分机器都能运行，可以互相通信并且可以和客户端通信，这个集群就可用。因此，一般来说，一个拥有 5 台机器的集群可以容忍其中的 2 台的失败（fail）。服务器停止工作了我们就认为它失败（fail）了，没准一会当它们拥有稳定的存储时就能从中恢复过来，重新加入到集群中。 不依赖时序保证一致性，时钟错误和极端情况下的消息延迟在最坏的情况下才会引起可用性问题。 通常情况下，一条命令能够尽可能快的在大多数节点对一轮远程调用作出相应时完成，一少部分慢的机器不会影响系统的整体性能。 3 Paxos 算法的不足在过去的10年中，Leslie Lamport 的 Paxos 算法几乎已经成为了一致性算法的代名词：它是授课中最常见的算法，同时也是许多一致性算法实现的起点。Paxos 首先定义了一个能够达成单一决策一致的协议，例如一个单一复制日志条目（single replicated log entry）。我们把这个子集叫做单一决策 Paxos（single-decree Paxos）。之后 Paxos通过组合多个这种协议来完成一系列的决策，例如一个日志（multi-Paxos）。Paxos 确保安全性和活跃性（liveness），并且它支持集群成员的变更。它的正确性已经被证明，通常情况下也很高效。 不幸的是，Paxos 有两个致命的缺点。第一个是 Paxos 太难以理解。它的完整的解释晦涩难懂；很少有人能完全理解，只有少数人成功的读懂了它。并且大家做了许多努力来用一些简单的术语来描述它。尽管这些解释都关注于单一决策子集问题，但仍具有挑战性。在 NSDI 2012 会议上的一次非正式调查显示，我们发现大家对 Paxos 都感到不满意，其中甚至包括一些有经验的研究员。我们自己也曾深陷其中，我们在读过几篇简化它的文章并且设计了我们自己的算法之后才完全理解了 Paxos，而整个过程花费了将近一年的时间。 我们假定 Paxos 的晦涩来源于它将单决策子集作为它的基础。单决策（Single-decree）Paxos 是晦涩且微妙的：它被划分为两个没有简单直观解释的阶段，并且难以独立理解。正因为如此，它不能很直观的让我们知道为什么单一决策协议能够工作。为多决策 Paxos 设计的规则又添加了额外的复杂性和精巧性。我们相信多决策问题能够分解为其它更直观的方式。 Paxos 的第二个缺点是它难以在实际环境中实现。其中一个原因是，对于多决策 Paxos （multi-Paxos） ，大家还没有一个一致同意的算法。Lamport 的描述大部分都是有关于单决策 Paxos （single-decree Paxos）；他仅仅描述了实现多决策的可能的方法，缺少许多细节。有许多实现 Paxos 和优化 Paxos 的尝试，但是他们都和 Lamport 的描述有些出入。例如，Chubby 实现的是一个类似 Paxos 的算法，但是在许多情况下的细节没有公开。 另外，Paxos 的结构也是不容易在一个实际系统中进行实现的，这是单决策问题分解带来的又一个问题。例如，从许多日志条目中选出条目然后把它们融合到一个序列化的日志中并没有带来什么好处，它仅仅增加了复杂性。围绕着日志来设计一个系统是更简单、更高效的：新日志按照严格的顺序添加到日志中去。另一个问题是，Paxos 使用对等的点对点的实现作为它的核心（尽管它最终提出了一种弱领导者的形式来优化性能）。这种方法在只有一个决策被制定的情况下才显得有效，但是很少有现实中的系统使用它。如果要做许多的决策，选择一个领导人，由领带人来协调是更简单有效的方法。 因此，在实际的系统应用中和 Paxos 算法都相差很大。所有开始于 Paxos 的实现都会遇到很多问题，然后由此衍生出了许多与 Paxos 有很大不同的架构。这是既费时又容易出错的，并且理解 Paxos 的难度又非常大。Paxos 算法在它正确性的理论证明上是很好的，但是在实现上的价值就远远不足了。来自 Chubby 的实现的一条评论就能够说明： Paxos 算法的描述与实际实现之间存在巨大的鸿沟…最终的系统往往建立在一个没有被证明的算法之上。 正因为存在这些问题，我们认为 Paxos 不仅对于系统的构建者来说不友好，同时也不利于教学。鉴于一致性算法对于大规模软件系统的重要性，我们决定试着来设计一种另外的比 Paxos 更好的一致性算法。Raft 就是这样的一个算法。 4 易于理解的设计设计 Raft 的目标有如下几个： 它必须提供一个完整的、实际的基础来进行系统构建，为的是减少开发者的工作； 它必须在所有情况下都能保证安全可用； 它对于常规操作必须高效； 最重要的目标是：易于理解，它必须使得大多数人能够很容易的理解； 另外，它必须能让开发者有一个直观的认识，这样才能使系统构建者们去对它进行扩展。 在设计 Raft 的过程中，我们不得不在许多种方法中做出选择。当面临这种情况时，我们通常会权衡可理解性：每种方法的可理解性是如何的？（例如，它的状态空间有多复杂？它是不是有很细微的含义？）它的可读性如何？读者能不能轻易地理解这个方法和它的含义？ 我们意识到对这种可理解性的分析具有高度的主观性；尽管如此，我们使用了两种适用的方式。第一种是众所周知的问题分解：我们尽可能将问题分解成为若干个可解决的、可被理解的小问题。例如，在 Raft 中，我们把问题分解成为了领导选取（leader election）、日志复制（log replication）、安全（safety）和成员变化（membership changes）。 我们采用的第二个方法是通过减少需要考虑的状态的数量将状态空间简化，这能够使得整个系统更加一致并且尽可能消除不确定性。特别地，日志之间不允许出现空洞，并且 Raft 限制了限制了日志不一致的可能性。尽管在大多数情况下，我们都都在试图消除不确定性，但是有时候有些情况下，不确定性使得算法更易理解。尤其是，随机化方法使得不确定性增加，但是它减少了状态空间。我们使用随机化来简化了 Raft 中的领导选取算法。 5 Raft 一致性算法Raft 是一种用来管理第 2 章中提到的复制日志的算法。表-2 为了方便参考是一个算法的总结版本，表-3 列举了算法中的关键性质；表格中的这些元素将会在这一章剩下的部分中分别进行讨论。 状态： 在所有服务器上持久存在的：（在响应远程过程调用 RPC 之前稳定存储的） 名称 描述 currentTerm 服务器最后知道的任期号（从0开始递增） votedFor 在当前任期内收到选票的候选人 id（如果没有就为 null） log[] 日志条目；每个条目包含状态机的要执行命令和从领导人处收到时的任期号 在所有服务器上不稳定存在的： 名称 描述 commitIndex 已知的被提交的最大日志条目的索引值（从0开始递增） lastApplied 被状态机执行的最大日志条目的索引值（从0开始递增） 在领导人服务器上不稳定存在的：（在选举之后初始化的） 名称 描述 nextIndex[] 对于每一个服务器，记录需要发给它的下一个日志条目的索引（初始化为领导人上一条日志的索引值+1） matchIndex[] 对于每一个服务器，记录已经复制到该服务器的日志的最高索引值（从0开始递增） 表-2-i 附加日志远程过程调用 （AppendEntries RPC） 由领导人来调用复制日志（5.3节）；也会用作heartbeat 参数 描述 term 领导人的任期号 leaderId 领导人的 id，为了其他服务器能重定向到客户端 prevLogIndex 最新日志之前的日志的索引值 prevLogTerm 最新日志之前的日志的领导人任期号 entries[] 将要存储的日志条目（表示 heartbeat 时为空，有时会为了效率发送超过一条） leaderCommit 领导人提交的日志条目索引值 返回值 描述 term 当前的任期号，用于领导人更新自己的任期号 success 如果其它服务器包含能够匹配上 prevLogIndex 和 prevLogTerm 的日志时为真 接受者需要实现： 如果 term &lt; currentTerm返回 false（5.1节） 如果在prevLogIndex处的日志的任期号与prevLogTerm不匹配时，返回 false（5.3节） 如果一条已经存在的日志与新的冲突（index 相同但是任期号 term 不同），则删除已经存在的日志和它之后所有的日志（5.3节） 添加任何在已有的日志中不存在的条目 如果leaderCommit &gt; commitIndex，将commitIndex设置为leaderCommit和最新日志条目索引号中较小的一个 表-2-ii 投票请求 RPC（RequestVote RPC） 由候选人发起收集选票（5.2节） 参数 描述 term 候选人的任期号 candidateId 请求投票的候选人 id lastLogIndex 候选人最新日志条目的索引值 lastLogTerm 候选人最新日志条目对应的任期号 返回值 描述 term 目前的任期号，用于候选人更新自己 voteGranted 如果候选人收到选票为 true 接受者需要实现： 如果term &lt; currentTerm返回 false（5.1节） 如果votedFor为空或者与candidateId相同，并且候选人的日志和自己的日志一样新，则给该候选人投票（5.2节 和 5.4节） 表-2-iii 服务器需要遵守的规则： 所有服务器： 如果commitIndex &gt; lastApplied，lastApplied自增，将log[lastApplied]应用到状态机（5.3节） 如果 RPC 的请求或者响应中包含一个 term T 大于 currentTerm，则currentTerm赋值为 T，并切换状态为追随者（Follower）（5.1节） 追随者（followers）: 5.2节 响应来自候选人和领导人的 RPC 如果在超过选取领导人时间之前没有收到来自当前领导人的AppendEntries RPC或者没有收到候选人的投票请求，则自己转换状态为候选人 候选人：5.2节 转变为选举人之后开始选举： currentTerm自增 给自己投票 重置选举计时器 向其他服务器发送RequestVote RPC 如果收到了来自大多数服务器的投票：成为领导人 如果收到了来自新领导人的AppendEntries RPC（heartbeat）：转换状态为追随者 如果选举超时：开始新一轮的选举 领导人： 一旦成为领导人：向其他所有服务器发送空的AppendEntries RPC（heartbeat）;在空闲时间重复发送以防止选举超时（5.2节） 如果收到来自客户端的请求：向本地日志增加条目，在该条目应用到状态机后响应客户端（5.3节） 对于一个追随者来说，如果上一次收到的日志索引大于将要收到的日志索引（nextIndex）：通过AppendEntries RPC将 nextIndex 之后的所有日志条目发送出去 如果发送成功：将该追随者的 nextIndex和matchIndex更新 如果由于日志不一致导致AppendEntries RPC失败：nextIndex递减并且重新发送（5.3节） 如果存在一个满足N &gt; commitIndex和matchIndex[i] &gt;= N并且log[N].term == currentTerm的 N，则将commitIndex赋值为 N 表-2-iv 表-2：Raft 一致性算法的总结（不包括成员变化 membership changes 和日志压缩 log compaction） 性质 描述 选举安全原则（Election Safety） 一个任期（term）内最多允许有一个领导人被选上（5.2节） 领导人只增加原则（Leader Append-Only） 领导人永远不会覆盖或者删除自己的日志，它只会增加条目 日志匹配原则（Log Matching） 如果两个日志在相同的索引位置上的日志条目的任期号相同，那么我们就认为这个日志从头到这个索引位置之间的条目完全相同（5.3 节） 领导人完全原则（Leader Completeness) 如果一个日志条目在一个给定任期内被提交，那么这个条目一定会出现在所有任期号更大的领导人中 状态机安全原则（State Machine Safety） 如果一个服务器已经将给定索引位置的日志条目应用到状态机中，则所有其他服务器不会在该索引位置应用不同的条目（5.4.3节） 表-3：Raft 算法保证这些特性任何时刻都成立 Raft 通过首先选出一个领导人来实现一致性，然后给予领导人完全管理复制日志（replicated log）的责任。领导人接收来自客户端的日志条目，并把它们复制到其他的服务器上，领带人还要告诉服务器们什么时候将日志条目应用到它们的状态机是安全的。通过选出领导人能够简化复制日志的管理工作。例如，领导人能够决定将新的日志条目放到哪，而并不需要和其他的服务器商议，数据流被简化成从领导人流向其他服务器。如果领导人宕机或者和其他服务器失去连接，就可以选取下一个领导人。 通过选出领导人，Raft 将一致性问题分解成为三个相对独立的子问题： 领导人选取（Leader election）： 在一个领导人宕机之后必须要选取一个新的领导人（5.2节） 日志复制（Log replication）： 领导人必须从客户端接收日志然后复制到集群中的其他服务器，并且强制要求其他服务器的日志保持和自己相同 安全性（Safety）： Raft 的关键的安全特性是 表-3 中提到的状态机安全原则（State Machine Safety）:如果一个服务器已经将给定索引位置的日志条目应用到状态机中，则所有其他服务器不会在该索引位置应用不同的条目。5.4节阐述了 Raft 是如何保证这条原则的，解决方案涉及到一个对于选举机制另外的限制，这一部分会在 5.2节 中说明。 在说明了一致性算法之后，本章会讨论有关可用性（availability）的问题和系统中时序（timing）的问题。 5.1 Raft 基础一个 Raft 集群包括若干服务器；对于一个典型的 5 服务器集群，该集群能够容忍 2 台机器不能正常工作，而整个系统保持正常。在任意的时间，每一个服务器一定会处于以下三种状态中的一个：领导人、候选人、追随者。在正常情况下，只有一个服务器是领导人，剩下的服务器是追随者。追随者们是被动的：他们不会发送任何请求，只是响应来自领导人和候选人的请求。领导人来处理所有来自客户端的请求（如果一个客户端与追随者进行通信，追随者会将信息发送给领导人）。候选人是用来选取一个新的领导人的，这一部分会在 5.2节 进行阐释。图-4 阐述了这些状态，和它们之间的转换；它们的转换会在下边进行讨论。 图-4：服务器的状态。追随者只响应其他服务器的请求。如果追随者没有收到任何消息，它会成为一个候选人并且开始一次选举。收到大多数服务器投票的候选人会成为新的领导人。领导人在它们宕机之前会一直保持领导人的状态。 图-5：时间被分为一个个的任期（term），每一个任期的开始都是领导人选举。在成功选举之后，一个领导人会在任期内管理整个集群。如果选举失败，该任期就会因为没有领带人而结束。这个转变会在不同的时间的不同服务器上观察到。 如 图-5 所示，Raft 算法将时间划分成为任意不同长度的任期（term）。任期用连续的数字进行表示。每一个任期的开始都是一次选举（election），就像 5.2节 所描述的那样，一个或多个候选人会试图成为领导人。如果一个候选人赢得了选举，它就会在该任期的剩余时间担任领导人。在某些情况下，选票会被瓜分，有可能没有选出领导人，那么，将会开始另一个任期，并且立刻开始下一次选举。Raft 算法保证在给定的一个任期最少要有一个领导人。 不同的服务器可能会在任期内观察到多次不同的状态转换，在某些情况下，一台服务器可能看不到一次选举或者一个完整的任期。任期在 Raft 中充当逻辑时钟的角色，并且它们允许服务器检测过期的信息，比如过时的领导人。每一台服务器都存储着一个当前任期的数字，这个数字会单调的增加。当服务器之间进行通信时，会互相交换当前任期号；如果一台服务器的当前任期号比其它服务器的小，则更新为较大的任期号。如果一个候选人或者领导人意识到它的任期号过时了，它会立刻转换为追随者状态。如果一台服务器收到的请求的任期号是过时的，那么它会拒绝此次请求。 Raft 中的服务器通过远程过程调用（RPC）来通信，基本的 Raft 一致性算法仅需要 2 种 RPC。RequestVote RPC 是候选人在选举过程中触发的（5.2节），AppendEntries RPC 是领导人触发的，为的是复制日志条目和提供一种心跳（heartbeat）机制（5.3节）。第7章加入了第三种 RPC 来在各个服务器之间传输快照（snapshot）。如果服务器没有及时收到 RPC 的响应，它们会重试，并且它们能够并行的发出 RPC 来获得最好的性能。 5.2 领导人选取Raft 使用一种心跳机制（heartbeat）来触发领导人的选取。当服务器启动时，它们会初始化为追随者。一太服务器会一直保持追随者的状态只要它们能够收到来自领导人或者候选人的有效 RPC。领导人会向所有追随者周期性发送心跳（heartbeat，不带有任何日志条目的 AppendEntries RPC）来保证它们的领导人地位。如果一个追随者在一个周期内没有收到心跳信息，就叫做选举超时（election timeout）,然后它就会假定没有可用的领导人并且开始一次选举来选出一个新的领导人。 为了开始选举，一个追随者会自增它的当前任期并且转换状态为候选人。然后，它会给自己投票并且给集群中的其他服务器发送 RequestVote RPC。一个候选人会一直处于该状态，直到下列三种情形之一发生： 它赢得了选举； 另一台服务器赢得了选举； 一段时间后没有任何一台服务器赢得了选举 这些情形会在下面的章节中分别讨论。 一个候选人如果在一个任期内收到了来自集群中大多数服务器的投票就会赢得选举。在一个任期内，一台服务器最多能给一个候选人投票，按照先到先服务原则（first-come-first-served）（注意：在 5.4节 针对投票添加了一个额外的限制）。大多数原则使得在一个任期内最多有一个候选人能赢得选举（表-3 中提到的选举安全原则）。一旦有一个候选人赢得了选举，它就会成为领导人。然后它会像其他服务器发送心跳信息来建立自己的领导地位并且组织新的选举。 当一个候选人等待别人的选票时，它有可能会收到来自其他服务器发来的声明其为领导人的 AppendEntries RPC。如果这个领导人的任期（包含在它的 RPC 中）比当前候选人的当前任期要大，则候选人认为该领导人合法，并且转换自己的状态为追随者。如果在这个 RPC 中的任期小于候选人的当前任期，则候选人会拒绝此次 RPC， 继续保持候选人状态。 第三种情形是一个候选人既没有赢得选举也没有输掉选举：如果许多追随者在同一时刻都成为了候选人，选票会被分散，可能没有候选人能获得大多数的选票。当这种情形发生时，每一个候选人都会超时，并且通过自增任期号和发起另一轮 RequestVote RPC 来开始新的选举。然而，如果没有其它手段来分配选票的话，这种情形可能会无限的重复下去。 Raft 使用随机的选举超时时间来确保第三种情形很少发生，并且能够快速解决。为了防止在一开始是选票就被瓜分，选举超时时间是在一个固定的间隔内随机选出来的（例如，150~300ms）。这种机制使得在大多数情况下只有一个服务器会率先超时，它会在其它服务器超时之前赢得选举并且向其它服务器发送心跳信息。同样的机制被用于选票一开始被瓜分的情况下。每一个候选人在开始一次选举的时候会重置一个随机的选举超时时间，在超时进行下一次选举之前一直等待。这能够减小在新的选举中一开始选票就被瓜分的可能性。9.3节 展示了这种方法能够快速的选出一个领导人。 选举是一个理解性引导我们设计替代算法的一个例子。最开始时，我们计划使用一种排名系统：给每一个候选人分配一个唯一的排名，用于在竞争的候选人之中选择领导人。如果一个候选人发现了另一个比它排名高的候选人，那么它会回到追随者的状态，这样排名高的候选人会很容易地赢得选举。但是我们发现这种方法在可用性方面有一点问题（一个低排名的服务器在高排名的服务器宕机后，需要等待超时才能再次成为候选人，但是如果它这么做的太快，它能重置选举领带人的过程）。我们对这个算法做了多次调整，但是每次调整后都会出现一些新的问题。最终我们认为随机重试的方法是更明确并且更易于理解的。 5.3 日志复制一旦选出了领导人，它就开始接收客户端的请求。每一个客户端请求都包含一条需要被复制状态机（replicated state machine）执行的命令。领导人把这条命令作为新的日志条目加入到它的日志中去，然后并行的向其他服务器发起 AppendEntries RPC ，要求其它服务器复制这个条目。当这个条目被安全的复制之后（下面的部分会详细阐述），领导人会将这个条目应用到它的状态机中并且会向客户端返回执行结果。如果追随者崩溃了或者运行缓慢或者是网络丢包了，领导人会无限的重试 AppendEntries RPC（甚至在它向客户端响应之后）知道所有的追随者最终存储了所有的日志条目。 图-6：日志由有序编号的日志条目组成。每个日志条目包含它被创建时的任期号（每个方块中的数字），并且包含用于状态机执行的命令。如果一个条目能够被状态机安全执行，就被认为可以提交了。 日志就像 图-6 所示那样组织的。每个日志条目存储着一条被状态机执行的命令和当这条日志条目被领导人接收时的任期号。日志条目中的任期号用来检测在不同服务器上日志的不一致性，并且能确保 图-3 中的一些特性。每个日志条目也包含一个整数索引来表示它在日志中的位置。 领导人决定什么时候将日志条目应用到状态机是安全的；这种条目被称为可被提交（commited）。Raft 保证可被提交（commited）的日志条目是持久化的并且最终会被所有可用的状态机执行。一旦被领导人创建的条目已经复制到了大多数的服务器上，这个条目就称为可被提交的（例如，图-6中的7号条目）。领导人日志中之前的条目都是可被提交的（commited），包括由之前的领导人创建的条目。5.4节将会讨论当领导人更替之后这条规则的应用问题的细节，并且也讨论了这种提交方式是安全的。领导人跟踪记录它所知道的被提交条目的最大索引值，并且这个索引值会包含在之后的 AppendEntries RPC 中（包括心跳 heartbeat 中），为的是让其他服务器都知道这条条目已经提交。一旦一个追随者知道了一个日志条目已经被提交，它会将该条目应用至本地的状态机（按照日志顺序）。 我们设计了 Raft 日志机制来保证不同服务器上日志的一致性。这样做不仅简化了系统的行为使得它更可预测，并且也是保证安全性不可或缺的一部分。Raft 保证以下特性，并且也保证了 表-3 中的日志匹配原则（Log Matching Property）: 如果在不同日志中的两个条目有着相同的索引和任期号，则它们所存储的命令是相同的。 如果在不同日志中的两个条目有着相同的索引和任期号，则它们之间的所有条目都是完全一样的。 第一条特性源于领导人在一个任期里在给定的一个日志索引位置最多创建一条日志条目，同时该条目在日志中的位置也从来不会改变。第二条特性源于 AppendEntries 的一个简单的一致性检查。当发送一个 AppendEntries RPC 时，领导人会把新日志条目紧接着之前的条目的索引位置和任期号都包含在里面。如果追随者没有在它的日志中找到相同索引和任期号的日志，它就会拒绝新的日志条目。这个一致性检查就像一个归纳步骤：一开始空的日志的状态一定是满足日志匹配原则的，一致性检查保证了当日志添加时的日志匹配原则。因此，只要 AppendEntries 返回成功的时候，领导人就知道追随者们的日志和它的是一致的了。 图-7：当最上边的领导人掌权之后，追随者日志可能有以下情况（a~f）。一个格子表示一个日志条目；格子中的数字是它的任期。一个追随者可能会丢失一些条目（a, b）；可能多出来一些未提交的条目（c, d）；或者两种情况都有（e, f）。例如，场景 f 在如下情况下就会发生：如果一台服务器在任期2时是领导人并且往它的日志中添加了一些条目，然后在将它们提交之前就宕机了，之后它很快重启了，成为了任期3的领导人，又往它的日志中添加了一些条目，然后在任期2和任期3中的条目提交之前它又宕机了并且几个任期内都一直处于宕机状态。 在一般情况下，领导人和追随者们的日志保持一致，因此 AppendEntries 一致性检查通常不会失败。然而，领导人的崩溃会导致日志不一致（旧的领导人可能没有完全复制完日志中的所有条目）。这些不一致会导致一系列领导人和追随者崩溃。图-7 阐述了一些追随者可能和新的领导人日志不同的情况。一个追随者可能会丢失掉领导人上的一些条目，也有可能包含一些领导人没有的条目，也有可能两者都会发生。丢失的或者多出来的条目可能会持续多个任期。 在 Raft 算法中，领导人通过强制追随者们复制它的日志来处理日志的不一致。这就意味着，在追随者上的冲突日志会被领导者的日志覆盖。5.4节会说明当添加了一个额外的限制之后这是安全的。 为了使得追随者的日志同自己的一致，领导人需要找到追随者同它的日志一致的地方，然后删除追随者在该位置之后的条目，然后将自己在该位置之后的条目发送给追随者。这些操作都在 AppendEntries RPC 进行一致性检查时完成。领导人给每一个追随者维护了一个nextIndex，它表示领导人将要发送给该追随者的下一条日志条目的索引。当一个领导人开始掌权时，它会将nextIndex初始化为它的最新的日志条目索引数+1（图-7 中的 11）。如果一个追随者的日志和领导者的不一致，AppendEntries 一致性检查会在下一次 AppendEntries RPC 时返回失败。在失败之后，领导人会将nextIndex递减然后重试 AppendEntries RPC。最终nextIndex会达到一个领导人和追随者日志一致的地方。这时，AppendEntries 会返回成功，追随者中冲突的日志条目都被移除了，并且添加所缺少的上了领导人的日志条目。一旦 AppendEntries 返回成功，追随者和领导人的日志就一致了，这样的状态会保持到该任期结束。 如果需要的话，算法还可以进行优化来减少 AppendEntries RPC 失败的次数。例如，当拒绝了一个 AppendEntries 请求，追随者可以记录下冲突日志条目的任期号和自己存储那个任期的最早的索引。通过这些信息，领导人能够直接递减nextIndex跨过那个任期内所有的冲突条目；这样的话，一个冲突的任期需要一次 AppendEntries RPC，而不是每一个冲突条目需要一次 AppendEntries RPC。在实践中，我们怀疑这种优化是否是必要的，因为AppendEntries 一致性检查很少失败并且也不太可能出现大量的日志条目不一致的情况。 通过这种机制，一个领导人在掌权时不需要采取另外特殊的方式来恢复日志的一致性。它只需要使用一些常规的操作，通过响应 AppendEntries 一致性检查的失败能使得日志自动的趋于一致。一个领导人从来不会覆盖或者删除自己的日志（表-3 中的领导人只增加原则）。 这个日志复制机制展示了在第2章中阐述的所希望的一致性特性：Raft 能够接受，复制并且应用新的日志条目只要大部分的服务器是正常的。在通常情况下，一条新的日志条目可以在一轮 RPC 内完成在集群的大多数服务器上的复制；并且一个速度很慢的追随者并不会影响整体的性能。 ##5.4 安全性 之前的章节中讨论了 Raft 算法是如何进行领导选取和复制日志的。然而，到目前为止这个机制还不能保证每一个状态机能按照相同的顺序执行同样的指令。例如，当领导人提交了若干日志条目的同时一个追随者可能宕机了，之后它又被选为了领导人然后用新的日志条目覆盖掉了旧的那些，最后，不同的状态机可能执行不同的命令序列。 这一节通过在领带人选取部分加入了一个限制来完善了 Raft 算法。这个限制能够保证对于固定的任期，任何的领导人都拥有之前任期提交的全部日志条目（表-3 中的领导人完全原则）。有了这一限制，日志提交的规则就更清晰了。最后，我们提出了对于领导人完全原则的简单证明并且展示了它是如何修正复制状态机的行为的。 ###5.4.1 选举限制 在所有的以领导人为基础的一致性算法中，领导人最终必须要存储全部已经提交的日志条目。在一些一致性算法中，例如：Viewstamped Replication，即使一开始没有包含全部已提交的条目也可以被选为领导人。这些算法都有一些另外的机制来保证找到丢失的条目并将它们传输给新的领导人，这个过程要么在选举过程中完成，要么在选举之后立即开始。不幸的是，这种方式大大增加了复杂性。Raft 使用了一种更简单的方式来保证在新的领导人开始选举的时候在之前任期的所有已提交的日志条目都会出现在上边，而不需要将这些条目传送给领导人。这就意味着日志条目只有一个流向：从领导人流向追随者。领导人永远不会覆盖已经存在的日志条目。 Raft 使用投票的方式来阻止没有包含全部日志条目的服务器赢得选举。一个候选人为了赢得选举必须要和集群中的大多数进行通信，这就意味着每一条已经提交的日志条目最少在其中一台服务器上出现。如果候选人的日志至少和大多数服务器上的日志一样新（up-to-date，这个概念会在下边有详细介绍），那么它一定包含有全部的已经提交的日志条目。RequestVote RPC 实现了这个限制：这个 RPC（远程过程调用）包括候选人的日志信息，如果它自己的日志比候选人的日志要新，那么它会拒绝候选人的投票请求。 Raft 通过比较日志中最后一个条目的索引和任期号来决定两个日志哪一个更新。如果两个日志的任期号不同，任期号大的更新；如果任期号相同，更长的日志更新。 ###5.4.2 提交之前任期的日志条目 图-8：如图的时间序列说明了为什么领导人不能通过之前任期的日志条目判断它的提交状态。（a）中的 S1 是领导人并且部分复制了索引2上的日志条目。（b）中 S1 崩溃了；S5 通过 S3，S4 和自己的选票赢得了选举，并且在索引2上接收了另一条日志条目。（c）中 S5 崩溃了，S1 重启了，通过 S2，S3 和自己的选票赢得了选举，并且继续索引2处的复制，这时任期2的日志条目已经在大部分服务器上完成了复制，但是还并没有提交。如果在（d）时刻 S1 崩溃了，S5 会通过 S2，S3，S4 的选票成为领导人，然后用它自己在任期3的日志条目覆盖掉其他服务器的日志条目。然而，如果在崩溃之前，S1 在它的当前任期在大多数服务器上复制了一条日志条目，就像在（e）中那样，那么这条条目就会被提交（S5就不会赢得选举）。在这时，之前的日志条目就会正常被提交。 正如 5.3节 中描述的那样，只要一个日志条目被存在了在多数的服务器上，领导人就知道当前任期就可以提交该条目了。如果领导人在提交之前就崩溃了，之后的领导人会试着继续完成对日志的复制。然而，领导人并不能断定存储在大多数服务器上的日志条目一定在之前的任期中被提交了。图-8 说明了一种情况，一条存储在了大多数服务器上的日志条目仍然被新上任的领导人覆盖了。 为了消除 图-8 中描述的问题，Raft 从来不会通过计算复制的数目来提交之前人气的日志条目。只有领导人当前任期的日志条目才能通过计算数目来进行提交。一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配原则（Log Matching Property），之前的日志条目也都会被间接的提交。在某些情况下，领导人可以安全的知道一个老的日志条目是否已经被提交（例如，通过观察该条目是否存储到所有服务器上），但是 Raft 为了简化问题使用了一种更加保守的方法。 因为当领导人从之前任期复制日志条目时日志条目保留了它们最开始的任期号，所以这使得 Raft 在提交规则中增加了额外的复杂性。在其他的一致性算法中，如果一个新的领导人要从之前的任期中复制日志条目，它必须要使用当前的新任期号。Raft 的方法使得判断日志更加容易，因为它们全程都保持着同样的任期号。另外，和其它的一致性算法相比，Raft 算法中的新领导人会发送更少的之前任期的日志条目（其他算法必须要发送冗余的日志条目并且在它们被提交之前来重新排序）。 5.4.3 安全性论证 图-9：如果 S1（任期 T 的领导人）在它的任期提交了一条日志条目，并且 S5 在之后的任期 U 成为了领导人，那么最少会有一台服务器（S3）接收了这条日志条目并且会给 S5 投票。 给出了完整的 Raft 算法，现在我们能够更精确的论证领导人完全原则（Leader Completeness)（这基于 9.2节 提出的安全性证明）。我们假定领导人完全原则是不成立的，然后推导出矛盾。假定任期 T 的领导人 leaderT在它的任期提交了一个日志条目，但是这条日志条目并没有存储在之后的任期中的领导人上。我们设大于 T 的最小的任期 U 的领导人（leaderU） 没有存储这条日志条目。 在 leaderU 选举时一定没有那条被提交的日志条目（领导人从来不会删除或者覆盖日志条目）。 leaderT 复制了这个条目到集群的大多数的服务器上。因此，只是有一台服务器（投票者）即接收了来自 leaderT 的日志条目并且给 leaderU 投票，就像 图-9 中所示那样。这个投票者是产生矛盾的关键。 投票者必须在给 leaderU 投票之前接收来自 leaderT 的日志条目；否则它会拒绝来自 leaderT 的 AppendEntries 请求（它的当前任期会比 T 要大）。 投票者会在它给 leaderU 投票时存储那个条目，因为任何中间的领导人都保有该条目（基于假设），领导人从来不会移除这个条目，并且追随者也只会在和领导人冲突时才会移除日志条目。 投票者给 leaderU 投票了，所以 leaderU 的日志必须和投票者的一样新。这就导致了一个矛盾。 首先，如果投票者和 leaderU 最后一条日志条目的任期号相同，那么 leaderU 的日志一定和投票者的一样长，因此它的日志包含全部投票者的日志条目。这是矛盾的，因为在假设中投票者和 leaderU 包含的已提交条目是不同的。 除此之外， leaderU 的最后一条日志的任期号一定比投票者的大。另外，它也比 T 要大，因为投票者的最后一条日志条目的任期号最小也要是 T（它包含了所有任期 T 提交的日志条目）。创建 leaderU 最后一条日志条目的上一任领导人必须包含已经提交的日志条目（基于假设）。那么，根据日志匹配原则（Log Matching），leaderU 也一定包含那条提交的日志条目，这也是矛盾的。 这时就完成了矛盾推导。因此，所有比任期 T 大的领导人一定包含所有在任期 T 提交的日志条目。 日志匹配原则（Log Matching）保证了未来的领导人也会包含被间接提交的日志条目，就像 图-8 中（d）时刻索引为2的条目。 通过给出了 领导人完全原则（Leader Completeness)，我们能够证明 表-3 中的状态机安全原则（State Machine Safety），状态机安全原则（State Machine Safety）讲的是如果一台服务器将给定索引上的日志条目应用到了它自己的状态机上，其它服务器的同一索引位置不可能应用的是其它条目。在一个服务器应用一条日志条目到它自己的状态机中时，它的日志必须和领导人的日志在该条目和之前的条目上相同，并且已经被提交。现在我们来考虑在任何一个服务器应用一个指定索引位置的日志的最小任期；日志完全特性（Log Completeness Property）保证拥有更高任期号的领导人会存储相同的日志条目，所以之后的任期里应用某个索引位置的日志条目也会是相同的值。因此，状态机安全特性是成立的。 最后，Raft 算法需要服务器按照日志中索引位置顺序应用日志条目。和状态机安全特性结合起来看，这就意味着所有的服务器会应用相同的日志序列集到自己的状态机中，并且是按照相同的顺序。 ##5.5 追随者和候选人崩溃 截止到目前，我们只讨论了领导人崩溃的问题。追随者和候选人崩溃的问题解决起来要比领导人崩溃要简单得多，这两者崩溃的处理方式是一样的。如果一个追随者或者候选人崩溃了，那么之后的发送给它的 RequestVote RPC 和 AppendEntries RPC 会失败。Raft 通过无限的重试来处理这些失败；如果崩溃的服务器重启了，RPC 就会成功完成。如果一个服务器在收到了 RPC 之后但是在响应之前崩溃了，那么它会在重启之后再次收到同一个 RPC。因为 Raft 中的 RPC 都是幂等的，因此不会有什么问题。例如，如果一个追随者收到了一个已经包含在它的日志中的 AppendEntries 请求，它会忽视这个新的请求。 ##5.6 时序和可用性 我们对于 Raft 的要求之一就是安全性不依赖于时序（timing）：系统不能仅仅因为一些事件发生的比预想的快一些或慢一些就产生错误。然而，可用性（系统可以及时响应客户端的特性）不可避免的要依赖时序。例如，如果消息交换在服务器崩溃时花费更多的时间，候选人不会等待太长的时间来赢得选举；没有一个稳定的领导人，Raft 将无法工作。 领导人选取是 Raft 中对时序要求最关键的地方。Raft 会选出并且保持一个稳定的领导人只有系统满足下列时序要求（timing requirement）： broadcastTime &lt;&lt; electionTimeout &lt;&lt; MTBF 在这个不等式中，broadcastTime指的是一台服务器并行的向集群中的其他服务器发送 RPC 并且收到它们的响应的平均时间；electionTimeout指的就是在 5.2节 描述的选举超时时间；MTBF指的是单个服务器发生故障的间隔时间的平均数。broadcastTime应该比electionTimeout小一个数量级，为的是使领导人能够持续发送心跳信息（heartbeat）来阻止追随者们开始选举；根据已经给出的随机化选举超时时间方法，这个不等式也使得瓜分选票的情况变成不可能。electionTimeout也要比MTBF小几个数量级，为的是使得系统稳定运行。当领导人崩溃时，整个大约会在electionTimeout的时间内不可用；我们希望这种情况仅占全部时间的很小的一部分。 broadcastTime和MTBF是由系统决定的性质，但是electionTimeout是我们必须做出选择的。Raft 的 RPC 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，这取决于存储的技术。因此，electionTimeout一般在 10ms 到 500ms 之间。大多数的服务器的MTBF都在几个月甚至更长，很容易满足这个时序需求。 #6 集群成员变化 截止到目前，我们都假定集群的配置（加入到一致性算法的服务器集合）是固定的。在实际中，我们会经常更改配置，例如，替换掉那些崩溃的机器或者更改复制级别。虽然通过关闭整个集群，升级配置文件，然后重启整个集群也可以解决这个问题，但是这回导致在更改配置的过程中，整个集群不可用。另外，如果存在需要手工操作，那么就会有操作失误的风险。为了避免这些问题，我们决定采用自动改变配置并且把这部分加入到了 Raft 一致性算法中。 为了让配置修改机制能够安全，那么在转换的过程中在任何时间点两个领导人不能再同一个任期被同时选为领导人。不幸的是，服务器集群从旧的配置直接升级到新的配置的任何方法都是不安全的，一次性自动的转换所有服务器是不可能的，所以集群可以在转换的过程中划分成两个单独的组（如 图-10 所示）。 图-10：从一个配置切换到另一个配置是不安全的因为不同的服务器会在不同的时间点进行切换。在这个例子中，集群数量从三台转换成五台。不幸的是，在一个时间点有两个服务器能被选举成为领导人，一个是在使用旧的配置的机器中（Cold）选出的领导人，另一个领导人是通过新的配置（Cnew）选出来的。 为了保证安全性，集群配置的调整必须使用两阶段（two-phase）方法。有许多种实现两阶段方法的实现。例如，一些系统在第一个阶段先把旧的配置设为无效使得它无法处理客户端请求，然后在第二阶段启用新的配置。在 Raft 中，集群先切换到一个过渡配置，我们称其为共同一致（joint consensus）；一旦共同一致被提交了，然后系统再切换到新的配置。共同一致是旧的配置和新的配置的组合： 日志条目被复制给集群中新、老配置的所有服务器。 新、老配置的服务器都能成为领导人。 需要分别在两种配置上获得大多数的支持才能达成一致（针对选举和提交） 共同一致允许独立的服务器在不影响安全性的前提下，在不同的时间进行配置转换过程。此外，共同一致可以让集群在配置转换的过程中依然能够响应服务器请求。 图-11：集群配置变更的时间线。虚线表示的是已经被创建但是还没提交的配置条目，实线表示的是最新提交的配置条目。领导人首先在它的日志中创建 Cold,new配置条目并且将它提交到Cold,new（使用旧配置的大部分服务器和使用新配置的大部分服务器）。然后创建它创建Cnew配置条目并且将它提交到使用新配置的大部分机器上。这样就不存在Cold和Cnew能够分别同时做出决定的时刻。 集群配置在复制日志中用特殊的日志条目来存储和通信；图-11 展示了配置变更的过程。当一个领导人接收到一个改变配置 Cold 为 Cnew 的请求，它会为了共同一致以前面描述的日志条目和副本的形式将配置存储起来（图中的 Cold,new）。一旦一个服务器将新的配置日志条目增加到它的日志中，它就会用这个配置来做出未来所有的决定（服务器总是使用最新的配置，无论它是否已经被提交）。这意味着领导人要使用 Cold,new 的规则来决定日志条目 Cold,new 什么时候需要被提交。如果领导人崩溃了，被选出来的新领导人可能是使用 Cold 配置也可能是 Cold,new 配置，这取决于赢得选举的候选人是否已经接收到了 Cold,new 配置。在任何情况下， Cnew 配置在这一时期都不会单方面的做出决定。 一旦 Cold,new 被提交，那么无论是 Cold 还是 Cnew，在没有经过他人批准的情况下都不可能做出决定，并且领导人完全特性（Leader Completeness Property）保证了只有拥有 Cold,new 日志条目的服务器才有可能被选举为领导人。这个时候，领导人创建一条关于 Cnew 配置的日志条目并复制给集群就是安全的了。另外，每个服务器在收到新的配置的时候就会立即生效。当新的配置在 Cnew 的规则下被提交，旧的配置就变得无关紧要，同时不使用新的配置的服务器就可以被关闭了。如 图-11，Cold 和 Cnew 没有任何机会同时做出单方面的决定；这就保证了安全性。 针对重新配置提出了三个问题。第一个问题是一开始的时候新的服务器可能没有任何日志条目。如果它们在这个状态下加入到集群中，那么它们需要一段时间来更新追赶，在这个阶段它们还不能提交新的日志条目。为了避免这种可用性的间隔时间，Raft 在配置更新的时候使用了一种额外的阶段，在这个阶段，新的服务器以没有投票权的身份加入到集群中来（领导人复制日志给他们，但是不把它们考虑到大多数中）。一旦新的服务器追赶上了集群中的其它机器，重新配置可以像上面描述的一样处理。 第二个问题是，集群的领导人可能不是新配置的一员。在这种情况下，领导人就会在提交了 Cnew 日志之后退位（回到跟随者状态）。这意味着有这样的一段时间，领导人管理着集群，但是不包括自己；它复制日志但是不把它自己看作是大多数之一。当 Cnew 被提交时，会发生领导人过渡，因为这时是新的配置可以独立工作的最早的时间点（总是能够在 Cnew 配置下选出新的领导人）。在此之前，可能只能从 Cold 中选出领导人。 第三个问题是，移除不在 Cnew 中的服务器可能会扰乱集群。这些服务器将不会再接收到心跳（heartbeat），所以当选举超时时，它们就会进行新的选举过程。它们会发送带有新的任期号的 RequestVote RPC，这样会导致当前的领导人回退成跟随者状态。新的领导人最终会被选出来，但是被移除的服务器将会再次超时，然后这个过程会再次重复，导致整体可用性大幅降低。 为了避免这个问题，当服务器确认当前领导人存在时，服务器会忽略 RequestVote RPC。特别的，当服务器在当前最小选举超时时间内收到一个 RequestVote RPC，它不会更新当前的任期号或者投出选票。这不会影响正常的选举，每个服务器在开始一次选举之前，至少等待一个最小选举超时时间。然而，这有利于避免被移除的服务器扰乱：如果领导人能够发送心跳给集群，那么它就不会被更大的任期号废除。 #7 日志压缩 Raft 产生的日志在持续的正常操作中不断增长，但是在实际的系统中，它不会无限的增长下去。随着日志的不断增长，它会占据越来越多的空间并且花费更多的时间重置。如果没有一个机制使得它能够废弃在日志中不断累积的过时的信息就会引起可用性问题。 快照（snapshot）是最简单的压缩方式。在快照中，全部的当前系统状态都被写入到快照中，存储到持久化的存储中，然后在那个时刻之前的全部日志都可以被丢弃。在 Chubby 和 ZooKeeper 中都使用了快照技术，这一章的剩下的部分会介绍 Raft 中使用的快照技术。 增量压缩（incremental approaches）的方法，例如日志清理（log cleaning）或者日志结构合并树（log-structured merge trees），都是可行的。这些方法每次只对一小部分数据进行操作，这样就分散了压缩的负载压力。首先，他们先选择一个已经积累的大量已经被删除或者被覆盖对象的区域，然后重写那个区域还活跃的对象，之后释放那个区域。和简单操作整个数据集合的快照相比，需要增加复杂的机制来实现。状态机可以使用和快照相同的接口来实现 LSM tree ，但是日志清除方法就需要修改 Raft 了。 图-12：一个服务器用新的快照替换了从 1 到 5 的条目，快照值存储了当前的状态。快照中包含了最后的索引位置和任期号。 图-12 展示了 Raft 中快照的基础思想。每个服务器独立的创建快照，只包括已经被提交的日志。主要的工作包括将状态机的状态写入到快照中。Raft 也将一些少量的元数据包含到快照中：最后被包含的索引（last included index）指的是被快照取代的最后的条目在日志中的索引值（状态机最后应用的日志），最后被包含的任期（last included term）指的是该条目的任期号。保留这些数据是为了支持快照前的第一个条目的附加日志请求时的一致性检查，因为这个条目需要最后的索引值和任期号。为了支持集群成员更新（第 6 章），快照中也将最后的一次配置作为最后一个条目存下来。一旦服务器完成一次快照，他就可以删除最后索引位置之前的所有日志和快照了。 尽管通常服务器都是独立的创建快照，但是领导人必须偶尔的发送快照给一些落后的跟随者。这通常发生在当领导人已经丢弃了下一条需要发送给跟随者的日志条目的时候。幸运的是这种情况不是常规操作：一个与领导人保持同步的跟随者通常都会有这个条目。然而一个运行非常缓慢的跟随者或者新加入集群的服务器（第 6 章）将不会有这个条目。这时让这个跟随者更新到最新的状态的方式就是通过网络把快照发送给它们。 安装快照 RPC（InstallSnapshot RPC） 在领导人发送快照给跟随者时使用调用。领导人总是按顺序发送。 参数 描述 term 领导人的任期 leaderId 为了追随者能重定向到客户端 lastIncludedIndex 快照中包含的最后日志条目的索引值 lastIncludedTerm 快照中包含的最后日志条目的任期号 offset 分块在快照中的偏移量 data[] 快照块的原始数据 done 如果是最后一块数据则为真 返回值 描述 term currentTerm，用于领导人更新自己 接受者需要实现： 如果term &lt; currentTerm立刻回复 如果是第一个分块（offset 为 0）则创建新的快照 在指定的偏移量写入数据 如果 done为 false，则回复并继续等待之后的数据 保存快照文件，丢弃所有存在的或者部分有着更小索引号的快照 如果现存的日志拥有相同的最后任期号和索引值，则后面的数据继续保留并且回复 丢弃全部日志 能够使用快照来恢复状态机（并且装载快照中的集群配置） 表-13：InstallSnapshot RPC 的总结。为了便于传输，快照都是被分成分块的；每个分块都给了跟随者生存的信号，所以跟随者可以重置选举超时计时器。 在这种情况下领导人使用一种叫做安装快照（InstallSnapshot）的新的 RPC 来发送快照给太落后的跟随者；见 表-13。当跟随者通过这种 RPC 接收到快照时，它必须自己决定对于已经存在的日志该如何处理。通常快照会包含没有在接收者日志中存在的信息。在这种情况下，跟随者直接丢弃它所有的日志；这些会被快照所取代，但是可能会和没有提交的日志产生冲突。如果接收到的快照是自己日志的前面部分（由于网络重传或者错误），那么被快照包含的条目将会被全部删除，但是快照之后的条目必须是正确的和并且被保留下来。 这种快照的方式背离了 Raft 的强领导人原则（strong leader principle），因为跟随者可以在不知道领导人情况下创建快照。但是我们认为这种背离是值得的。领导人的存在，是为了解决在达成一致性的时候的冲突，但是在创建快照的时候，一致性已经达成，这时不存在冲突了，所以没有领导人也是可以的。数据依然是从领导人传给跟随者，只是跟随者可以重新组织它们的数据了。 我们考虑过一种替代的基于领导人的快照方案，即只有领导人创建快照，然后发送给所有的跟随者。但是这样做有两个缺点。第一，发送快照会浪费网络带宽并且延缓了快照处理的时间。每个跟随者都已经拥有了所有产生快照需要的信息，而且很显然，自己从本地的状态中创建快照比通过网络接收别人发来的要经济。第二，领导人的实现会更加复杂。例如，领导人需要发送快照的同时并行的将新的日志条目发送给跟随者，这样才不会阻塞新的客户端请求。 还有两个问题影响了快照的性能。首先，服务器必须决定什么时候应该创建快照。如果快照创建的过于频繁，那么就会浪费大量的磁盘带宽和其他资源；如果创建快照频率太低，它就要承受耗尽存储容量的风险，同时也增加了从日志重建的时间。一个简单的策略就是当日志大小达到一个固定大小的时候就创建一次快照。如果这个阈值设置的显著大于期望的快照的大小，那么快照对磁盘压力的影响就会很小了。 第二个影响性能的问题就是写入快照需要花费显著的一段时间，并且我们还不希望影响到正常操作。解决方案是通过写时复制（copy-on-write）的技术，这样新的更新就可以被接收而不影响到快照。例如，具有函数式数据结构的状态机天然支持这样的功能。另外，操作系统的写时复制技术的支持（如 Linux 上的 fork）可以被用来创建完整的状态机的内存快照（我们的实现就是这样的）。 #8 客户端交互 这一节将介绍客户端是如何和 Raft 进行交互的，包括客户端是如何发现领导人的和 Raft 是如何支持线性化语义（linearizable semantics）的。这些问题对于所有基于一致性的系统都存在，并且 Raft 的解决方案和其他的也差不多。 Raft 中的客户端将所有请求发送给领导人。当客户端启动的时候，它会随机挑选一个服务器进行通信。如果客户端第一次挑选的服务器不是领导人，那么那个服务器会拒绝客户端的请求并且提供它最近接收到的领导人的信息（附加条目请求包含了领导人的网络地址）。如果领导人已经崩溃了，那么客户端的请求就会超时；客户端之后会再次重试随机挑选服务器的过程。 我们 Raft 的目标是要实现线性化语义（linearizable semantics）（每一次操作立即执行，在它调用和收到回复之间只执行一次）。但是，如上述所说，Raft 是可以多次执行同一条命令的：例如，如果领导人在提交了这条日志之后，但是在响应客户端之前崩溃了，那么客户端会和新的领导人重试这条指令，导致这条命令就被再次执行了。解决方案就是客户端对于每一条指令都赋予一个唯一的序列号。然后，状态机跟踪每条指令最新的序列号和相应的响应。如果接收到一条指令，它的序列号已经被执行了，那么就立即返回结果，而不重新执行指令。 只读（read-only）的操作可以直接处理而不需要记录日志。但是，在不增加任何限制的情况下，这么做可能会冒着返回过期数据(stale data)的风险，因为领导人响应客户端请求时可能已经被新的领导人作废了，但是它还不知道。线性化的读操作必须不能返回过期数据，Raft 需要使用两个额外的措施在不使用日志的情况下保证这一点。首先，领导人必须有关于被提交日志的最新信息。领导人完全原则（Leader Completeness Property）保证了领导人一定拥有所有已经被提交的日志条目，但是在它任期开始的时候，它可能不知道哪些是已经被提交的。为了知道这些信息，它需要在它的任期里提交一条日志条目。Raft 中通过领导人在任期开始的时候提交一个空白的没有任何操作的日志条目到日志中去来进行实现。第二，领导人在处理只读的请求之前必须检查自己是否已经被废除了（如果一个更新的领导人被选举出来，它自己的信息就已经过期了）。Raft 中通过让领导人在响应只读请求之前，先和集群中的大多数节点交换一次心跳（heartbeat）信息来处理这个问题。另外，领导人可以依赖心跳机制来实现一种租约的机制，但是这种方法依赖时序来保证安全性（它假设时间误差是有界的）。 #9 实现和评价 我们已经为 RAMCloud 实现了 Raft 算法作为存储配置信息的复制状态机的一部分，并且帮助 RAMCloud 协调故障转移。这个 Raft 实现包含大约 2000 行 C++ 代码，其中不包括测试、注释和空行。这些代码是开源的。同时也有大约 25 个其他独立的第三方的基于这篇论文草稿的开源实现，针对不同的开发场景。同时，很多公司已经部署了基于 Raft 的系统。 这一章会从三个方面来评估 Raft 算法：可理解性、正确性和性能。 ##9.1 可理解性 为了比较 Paxos 和 Raft 算法的可理解性，我们针对高层次的本科生和研究生，在斯坦福大学的高级操作系统课程和加州大学伯克利分校的分布式计算课程上，进行了一次学习的实验。我们分别拍了针对 Raft 和 Paxos 的视频课程，并准备了相应的小测验。Raft 的视频讲课覆盖了这篇论文除了日志压缩之外的所有内容；Paxos 课程包含了足够的资料来创建一个等价的复制状态机，包括单决策 Paxos，多决策 Paxos，重新配置和一些实际系统需要的性能优化（例如领导人选举）。小测验测试一些对算法的基本理解和解释一些示例。每个学生都是看完第一个视频，回答相应的测试，再看第二个视频，回答相应的测试。大约有一半的学生先进行 Paxos 部分，然后另一半先进行 Raft 部分，这是为了说明两者独立的区别从第一个算法处学来的经验。我们计算参加人员的每一个小测验的得分来看参与者是否对 Raft 的理解更好。 因素 消除偏见的手段 复习材料 相同的讲课质量 使用相同的讲师。Paxos 的讲义是基于之前在几所大学中使用的材料的并且做了改进。Paxos 的讲义要长 14% 视频 相同的测试难度 用难度给问题分组，在测试中成对出现 测验 公平的打分 使用红字标题。随机顺序打分，两个测验交替进行。 红字标题 表-1：考虑到的可能造成偏见的因素，以及解决方案和对应的复习材料 我们尽可能的使得 Paxos 和 Raft 的比较更加公平。这个实验偏爱 Paxos 表现在两个方面：43 个参加者中有 15 个人在之前有一些 Paxos 的经验，并且 Paxos 的视频要长 14%。如表-1 总结的那样，我们采取了一些措施来减轻这种潜在的偏见。我们所有的材料都可供审查。 图-14：表示了 43 个学生在 Paxos 和 Raft 的小测验中的成绩的散点图。在对角线之上的点表示在 Raft 获得了更高分数的学生。 参加者平均在 Raft 的测验中比 Paxos 高 4.9 分（总分 60，那么 Raft 的平均得分是 25.7，而 Paxos 是 20.8）；图-14 展示了每个参与者的得分。一对 t -测试表明，拥有 95% 的可信度，真实的 Raft 分数分布至少比 Paxos 高 2.5 分。 我们也建立了一个线性回归模型来预测一个新的学生的测验成绩，基于以下三个因素：他们使用的是哪个小测验，之前对 Paxos 的经验，和学习算法的顺序。模型显示，对小测验的选择会产生 12.5 分的差别在对 Raft 的好感度上。这显著的高于之前的 4.9 分，因为很多学生在之前都已经有了对于 Paxos 的经验，这相当明显的帮助 Paxos，对 Raft 就没什么太大影响了。但是奇怪的是，模型预测对于先进行 Paxos 小测验的人而言，Raft 的小测验得分会比 Paxos 低 6.3 分；我们不知道为什么，但这在统计学上是这样的。 图-15：通过一个 5 分制的问题，参与者（左边）被问哪个算法他们觉得在一个高效正确的系统里更容易实现，右边被问哪个更容易向学生解释。 我们同时也在测验之后调查了参与者，他们认为哪个算法更加容易实现和解释；这个的结果在图-15 上。压倒性的结果表明 Raft 算法更加容易实现和解释（41 人中的 33个）。但是，这种自己报告的结果不如参与者的成绩更加可信，并且参与者可能因为我们的 Raft 更加易于理解的假说而产生偏见。 关于 Raft 用户学习有一个更加详细的讨论，详见http://ramcloud.stanford.edu/ ̃ongaro/thesis.pdf ##9.2 正确性 在第5章，我们已经进行了一个正式的说明，和对一致性机制的安全性证明。这个正式说明通过 TLA+ 让 表-2 中的信息非常清晰。它大约有 400 行并且充当了证明的主题。同时对于任何想实现的人也是十分有用的。我们非常机械的通过 TLA 证明系统证明了日志完全特性（Log Completeness Property）。然而，这个证明依赖的约束前提还没有被机械证明（例如，我们还没有证明这个说明中的类型安全 type safety）。而且，我们已经写了一个非正式的证明关于状态机安全性质是完备的，并且是相当清晰的（大约 3500 个词）。 ##9.3 性能 Raft 和其他一致性算法例如 Paxos 有着差不多的性能。在性能方面，最重要的关注点是，当领导人被选举成功时，什么时候复制新的日志条目。Raft 通过很少数量的消息包（一轮从领导人到集群大多数机器的消息）就达成了这个目的。同时，进一步提升 Raft 的性能也是可行的。例如，很容易通过支持批量操作和管道操作来提高吞吐量和降低延迟。对于其他一致性算法已经提出过很多性能优化方案；其中有很多也可以应用到 Raft 中来，但是我们暂时把这个问题放到未来的工作中去。 我们使用我们自己的 Raft 实现来衡量 Raft 领导人选举的性能并且回答以下两个问题。首先，领导人选举的过程收敛是否快速？第二，在领导人宕机之后，最小的系统宕机时间是多久？ 图-16：发现并替换一个已经崩溃的领导人的时间。上面的图考察了在选举超时时间上的随机化程度，下面的图考察了最小超时时间。每条线代表了 1000 次实验（除了 150-150 毫秒只试了 100 次），和相应的确定的选举超时时间。例如，150-155 毫秒意思是，选举超时时间从这个区间范围内随机选择并确定下来。这个实验在一个拥有 5 个节点的集群上进行，其广播时延大约是 15 毫秒。对于 9 个节点的集群，结果也差不多。 为了衡量领导人选举，我们反复的使一个拥有五个节点的服务器集群的领导人宕机，并计算需要多久才能发现领导人已经宕机并选出一个新的领导人（见图-16）。为了构建一个最坏的场景，在每一的尝试里，服务器都有不同长度的日志，意味着有些候选人是没有成为领导人的资格的。另外，为了促成选票瓜分的情况，我们的测试脚本在终止领导人之前同步的发送了一次心跳广播（这大约和领导人在崩溃前复制一个新的日志给其他机器很像）。领导人均匀的随机的在心跳间隔里宕机，也就是最小选举超时时间的一半。因此，最小宕机时间大约就是最小选举超时时间的一半。 图-16 上面的图表表明，只需要在选举超时时间上使用很少的随机化就可以大大避免选票被瓜分的情况。在没有随机化的情况下，在我们的测试里，选举过程由于太多的选票瓜分的情况往往都需要花费超过 10 秒钟。仅仅增加 5 毫秒的随机化时间，就大大的改善了选举过程，现在平均的宕机时间只有 287 毫秒。增加更多的随机化时间可以大大改善最坏情况：通过增加 50 毫秒的随机化时间，最坏的完成情况（1000 次尝试）只要 513 毫秒。 图-16 中下面的图显示，通过减少选举超时时间可以减少系统的宕机时间。在选举超时时间为 12-24 毫秒的情况下，只需要平均 35 毫秒就可以选举出新的领导人（最长的一次花费了 152 毫秒）。然而，进一步降低选举超时时间的话就会违反 Raft 的时间不等式需求：在选举新领导人之前，领导人就很难发送完心跳包。这会导致没有意义的领导人改变并降低了系统整体的可用性。我们建议使用更为保守的选举超时时间，比如 150-300 毫秒；这样的时间不大可能导致没有意义的领导人改变，而且依然提供不错的可用性。 #10 相关工作 已经有很多关于一致性算法的工作被发表出来，其中很多都可以归到下面的类别中： Lamport 关于 Paxos 的原始描述，和尝试描述的更清晰的论文。 关于 Paxos 的更详尽的描述，补充遗漏的细节并修改算法，使得可以提供更加容易的实现基础。 实现一致性算法的系统，例如 Chubby，ZooKeeper 和 Spanner。对于 Chubby 和 Spanner 的算法并没有公开发表其技术细节，尽管他们都声称是基于 Paxos 的。ZooKeeper 的算法细节已经发表，但是和 Paxos 有着很大的差别。 Paxos 可以应用的性能优化。 Oki 和 Liskov 的 Viewstamped Replication（VR），一种和 Paxos 差不多的替代算法。原始的算法描述和分布式传输协议耦合在了一起，但是核心的一致性算法在最近的更新里被分离了出来。VR 使用了一种基于领导人的方法，和 Raft 有很多相似之处。 Raft 和 Paxos 最大的不同之处就在于 Raft 的强领导特性：Raft 使用领导人选举作为一致性协议里必不可少的部分，并且将尽可能多的功能集中到了领导人身上。这样就可以使得算法更加容易理解。例如，在 Paxos 中，领导人选举和基本的一致性协议是正交的：领导人选举仅仅是性能优化的手段，而且不是一致性所必须要求的。但是，这样就增加了多余的机制：Paxos 同时包含了针对基本一致性要求的两阶段提交协议和针对领导人选举的独立的机制。相比较而言，Raft 就直接将领导人选举纳入到一致性算法中，并作为两阶段一致性的第一步。这样就减少了很多机制。 像 Raft 一样，VR 和 ZooKeeper 也是基于领导人的，因此他们也拥有一些 Raft 的优点。但是，Raft 比 VR 和 ZooKeeper 拥有更少的机制因为 Raft 尽可能的减少了非领导人的功能。例如，Raft 中日志条目都遵循着从领导人发送给其他人这一个方向：附加条目 RPC 是向外发送的。在 VR 中，日志条目的流动是双向的（领导人可以在选举过程中接收日志）；这就导致了额外的机制和复杂性。根据 ZooKeeper 公开的资料看，它的日志条目也是双向传输的，但是它的实现更像 Raft。 和上述我们提及的其他基于一致性的日志复制算法中，Raft 的消息类型更少。例如，我们数了一下 VR 和 ZooKeeper 使用的用来基本一致性需要和成员改变的消息数（排除了日志压缩和客户端交互，因为这些都比较独立且和算法关系不大）。VR 和 ZooKeeper 都分别定义了 10 中不同的消息类型，相对的，Raft 只有 4 中消息类型（两种 RPC 请求和对应的响应）。Raft 的消息都稍微比其他算法的要信息量大，但是都很简单。另外，VR 和 ZooKeeper 都在领导人改变时传输了整个日志；所以为了能够实践中使用，额外的消息类型就很必要了。 Raft 的强领导人模型简化了整个算法，但是同时也排斥了一些性能优化的方法。例如，平等主义 Paxos （EPaxos）在某些没有领导人的情况下可以达到很高的性能。平等主义 Paxos 充分发挥了在状态机指令中的交换性。任何服务器都可以在一轮通信下就提交指令，除非其他指令同时被提出了。然而，如果指令都是并发的被提出，并且互相之间不通信沟通，那么 EPaxos 就需要额外的一轮通信。因为任何服务器都可以提交指令，所以 EPaxos 在服务器之间的负载均衡做的很好，并且很容易在 WAN 网络环境下获得很低的延迟。但是，他在 Paxos 上增加了非常明显的复杂性。 一些集群成员变换的方法已经被提出或者在其他的工作中被实现，包括 Lamport 的原始的讨论，VR 和 SMART。我们选择使用共同一致（joint consensus）的方法因为它对一致性协议的其他部分影响很小，这样我们只需要很少的一些机制就可以实现成员变换。Raft 没有采用 Lamport 的基于 α 的方法是因为它假设在没有领导人的情况下也可以达到一致性。和 VR 和 SMART 相比较，Raft 的重新配置算法可以在不限制正常请求处理的情况下进行；相比较而言，VR 需要停止所有的处理过程，SMART 引入了一个和 α 类似的方法，限制了请求处理的数量。和 VR、SMART 比较而言，Raft 的方法同时需要更少的额外机制来实现。 #11 总结 算法的设计通常会把正确性，效率或者简洁作为主要的目标。尽管这些都是很有意义的目标，但是我们相信，可理解性也是一样的重要。在开发者把算法应用到实际的系统中之前，这些目标没有一个会被实现，这些都会必然的偏离发表时的形式。除非开发人员对这个算法有着很深的理解并且有着直观的感觉，否则将会对他们而言很难在实现的时候保持原有期望的特性。 在这篇论文中，我们尝试解决分布式一致性问题，但是一个广为接受但是十分令人费解的算法 Paxos 已经困扰了无数学生和开发者很多年了。我们创造了一种新的算法 Raft，显而易见的比 Paxos 要容易理解。我们同时也相信，Raft 也可以为实际的实现提供坚实的基础。把可理解性作为设计的目标改变了我们设计 Raft 的方式；这个过程是我们发现我们最终很少有技术上的重复，例如问题分解和简化状态空间。这些技术不仅提升了 Raft 的可理解性，同时也使我们坚信其正确性。 #12 鸣谢 这项研究必须感谢以下人员的支持：Ali Ghodsi，David Mazie res，和伯克利 CS 294-91 课程、斯坦福 CS 240 课程的学生。Scott Klemmer 帮我们设计了用户调查，Nelson Ray 建议我们进行统计学的分析。在用户调查时使用的关于 Paxos 的幻灯片很大一部分是从 Lorenzo Alvisi 的幻灯片上借鉴过来的。特别的，非常感谢 DavidMazieres 和 Ezra Hoch，他们找到了 Raft 中一些难以发现的漏洞。许多人提供了关于这篇论文十分有用的反馈和用户调查材料，包括 Ed Bugnion，Michael Chan，Hugues Evrard，Daniel Giffin，Arjun Gopalan，Jon Howell，Vimalkumar Jeyakumar，Ankita Kejriwal，Aleksandar Kracun，Amit Levy，Joel Martin，Satoshi Matsushita，Oleg Pesok，David Ramos，Robbert van Renesse，Mendel Rosenblum，Nicolas Schiper，Deian Stefan，Andrew Stone，Ryan Stutsman，David Terei，Stephen Yang，Matei Zaharia 以及 24 位匿名的会议审查人员（可能有重复），并且特别感谢我们的领导人 Eddie Kohler。Werner Vogels 发了一条早期草稿链接的推特，给 Raft 带来了极大的关注。我们的工作由 Gigascale 系统研究中心和 Multiscale 系统研究中心给予支持，这两个研究中心由关注中心研究程序资金支持，一个是半导体研究公司的程序，由 STARnet 支持，一个半导体研究公司的程序由 MARCO 和 DARPA 支持，在国家科学基金会的 0963859 号批准，并且获得了来自 Facebook，Google，Mellanox，NEC，NetApp，SAP 和 Samsung 的支持。Diego Ongaro 由 Junglee 公司，斯坦福的毕业团体支持。 #引用 BOLOSKY, W. J., BRADSHAW, D., HAAGENS, R. B., KUSTERS, N. P., AND LI, P. Paxos replicated state machines as the basis of a high-performance data store. In Proc. NSDI’11, USENIX Conference on Networked Systems Design and Implementation (2011), USENIX, pp. 141–154. BURROWS, M. The Chubby lock service for loosely- coupled distributed systems. In Proc. OSDI’06, Sympo- sium on Operating Systems Design and Implementation (2006), USENIX, pp. 335–350. CAMARGOS, L. J., SCHMIDT, R. M., AND PEDONE, F. Multicoordinated Paxos. In Proc. PODC’07, ACM Sym- posium on Principles of Distributed Computing (2007), ACM, pp. 316–317. CHANDRA, T. D., GRIESEMER, R., AND REDSTONE, J. Paxos made live: an engineering perspective. In Proc. PODC’07, ACM Symposium on Principles of Distributed Computing (2007), ACM, pp. 398–407. CHANG, F., DEAN, J., GHEMAWAT, S., HSIEH, W. C., WALLACH, D. A., BURROWS, M., CHANDRA, T., FIKES, A., AND GRUBER, R. E. Bigtable: a distributed storage system for structured data. In Proc. OSDI’06, USENIX Symposium on Operating Systems Design and Implementation (2006), USENIX, pp. 205–218. CORBETT, J. C., DEAN, J., EPSTEIN, M., FIKES, A., FROST, C., FURMAN, J. J., GHEMAWAT, S., GUBAREV, A., HEISER, C., HOCHSCHILD, P., HSIEH, W., KAN- THAK, S., KOGAN, E., LI, H., LLOYD, A., MELNIK, S., MWAURA, D., NAGLE, D., QUINLAN, S., RAO, R., ROLIG, L., SAITO, Y., SZYMANIAK, M., TAYLOR, C., WANG, R., AND WOODFORD, D. Spanner: Google’s globally-distributed database. In Proc. OSDI’12, USENIX Conference on Operating Systems Design and Implemen- tation (2012), USENIX, pp. 251–264. COUSINEAU, D., DOLIGEZ, D., LAMPORT, L., MERZ, S., RICKETTS, D., AND VANZETTO, H. TLA+ proofs. In Proc. FM’12, Symposium on Formal Methods (2012), D. Giannakopoulou and D. Me ́ry, Eds., vol. 7436 of Lec- ture Notes in Computer Science, Springer, pp. 147–154. GHEMAWAT, S., GOBIOFF, H., AND LEUNG, S.-T. The Google file system. In Proc. SOSP’03, ACM Symposium on Operating Systems Principles (2003), ACM, pp. 29–43. GRAY,C.,ANDCHERITON,D.Leases:Anefficientfault- tolerant mechanism for distributed file cache consistency. In Proceedings of the 12th ACM Ssymposium on Operating Systems Principles (1989), pp. 202–210. HERLIHY, M. P., AND WING, J. M. Linearizability: a correctness condition for concurrent objects. ACM Trans- actions on Programming Languages and Systems 12 (July 1990), 463–492. HUNT, P., KONAR, M., JUNQUEIRA, F. P., AND REED, B. ZooKeeper: wait-free coordination for internet-scale systems. In Proc ATC’10, USENIX Annual Technical Con- ference (2010), USENIX, pp. 145–158. JUNQUEIRA, F. P., REED, B. C., AND SERAFINI, M. Zab: High-performance broadcast for primary-backup sys- tems. In Proc. DSN’11, IEEE/IFIP Int’l Conf. on Depend- able Systems &amp; Networks (2011), IEEE Computer Society, pp. 245–256. KIRSCH, J., AND AMIR, Y. Paxos for system builders. Tech. Rep. CNDS-2008-2, Johns Hopkins University, 2008. LAMPORT, L. Time, clocks, and the ordering of events in a distributed system. Commununications of the ACM 21, 7 (July 1978), 558–565. LAMPORT, L. The part-time parliament. ACM Transac- tions on Computer Systems 16, 2 (May 1998), 133–169. LAMPORT, L. Paxos made simple. ACM SIGACT News 32, 4 (Dec. 2001), 18–25. LAMPORT, L. Specifying Systems, The TLA+ Language and Tools for Hardware and Software Engineers. Addison- Wesley, 2002. LAMPORT, L. Generalized consensus and Paxos. Tech. Rep. MSR-TR-2005-33, Microsoft Research, 2005. LAMPORT, L. Fast paxos. Distributed Computing 19, 2 (2006), 79–103. LAMPSON, B. W. How to build a highly available system using consensus. In Distributed Algorithms, O. Baboaglu and K. Marzullo, Eds. Springer-Verlag, 1996, pp. 1–17. LAMPSON, B. W. The ABCD’s of Paxos. In Proc. PODC’01, ACM Symposium on Principles of Distributed Computing (2001), ACM, pp. 13–13. LISKOV, B., AND COWLING, J. Viewstamped replica- tion revisited. Tech. Rep. MIT-CSAIL-TR-2012-021, MIT, July 2012. LogCabin source code. logcabin/logcabin. LORCH, J. R., ADYA, A., BOLOSKY, W. J., CHAIKEN, R., DOUCEUR, J. R., AND HOWELL, J. The SMART way to migrate replicated stateful services. In Proc. Eu- roSys’06, ACM SIGOPS/EuroSys European Conference on Computer Systems (2006), ACM, pp. 103–115. MAO, Y., JUNQUEIRA, F. P., AND MARZULLO, K. Mencius: building efficient replicated state machines for WANs. In Proc. OSDI’08, USENIX Conference on Operating Systems Design and Implementation (2008), USENIX, pp. 369–384. MAZIE` RES, D. Paxos made practical.http://www.scs.stanford.edu/~dm/home/papers/paxos.pdf , Jan. 2007. MORARU, I., ANDERSEN, D. G., AND KAMINSKY, M. There is more consensus in egalitarian parliaments. In Proc. SOSP’13, ACM Symposium on Operating System Principles (2013), ACM. Raft user study. http://ramcloud.stanford.edu/~ongaro/userstudy/. OKI, B. M., AND LISKOV, B. H. Viewstamped replication: A new primary copy method to support highly-available distributed systems. In Proc. PODC’88, ACM Symposium on Principles of Distributed Computing (1988), ACM, pp. 8–17. O’NEIL, P., CHENG, E., GAWLICK, D., AND ONEIL, E. The log-structured merge-tree (LSM-tree). Acta Informat- ica 33, 4 (1996), 351–385. ONGARO, D. Consensus: Bridging Theory and Practice. PhD thesis, Stanford University, 2014 (work in progress).http://ramcloud.stanford.edu/~ongaro/thesis.pdf ONGARO, D., AND OUSTERHOUT, J. In search of an understandable consensus algorithm. In Proc ATC’14, USENIX Annual Technical Conference (2014), USENIX. OUSTERHOUT, J., AGRAWAL, P., ERICKSON, D., KOZYRAKIS, C., LEVERICH, J., MAZIE`RES, D., MI- TRA, S., NARAYANAN, A., ONGARO, D., PARULKAR, G., ROSENBLUM, M., RUMBLE, S. M., STRATMANN, E., AND STUTSMAN, R. The case for RAMCloud. Com- munications of the ACM 54 (July 2011), 121–130. Raft consensus algorithm website. http://raftconsensus.github.io. REED, B. Personal communications, May 17, 2013. ROSENBLUM, M., AND OUSTERHOUT, J. K. The design and implementation of a log-structured file system. ACM Trans. Comput. Syst. 10 (February 1992), 26–52. SCHNEIDER, F. B. Implementing fault-tolerant services using the state machine approach: a tutorial. ACM Com- puting Surveys 22, 4 (Dec. 1990), 299–319. SHVACHKO, K., KUANG, H., RADIA, S., AND CHANSLER, R. The Hadoop distributed file system. In Proc. MSST’10, Symposium on Mass Storage Sys- tems and Technologies (2010), IEEE Computer Society, pp. 1–10. VAN RENESSE, R. Paxos made moderately complex. Tech. rep., Cornell University, 2012. 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>paper</tag>
        <tag>raft</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《精进》短评&书摘]]></title>
    <url>%2F2017%2F02%2F01%2Fjingjin-reading-notes%2F</url>
    <content type="text"><![CDATA[《精进：如何成为一个很厉害的人》是一本自我管理类的书籍，作者提出了一种提升自我的方式：用持续精确的努力，来不断进步，逐渐提升自我，这就是精进。在看过这本书之后对于作者提出的一些概念十分惊喜，并且表示赞同；但是对于有些观点不敢苟同。毕竟自我管理这样的书籍，不论作者提出了多么独到的观点，如果比应用于个人的实践中去的话，都是纸上谈兵。以下是我读书时整理的一些书摘，并且整理出了一些书中提到的概念。 概念索引 变构学习模型（24） 必要难度（32） 常规型专长（22） 沉没成本谬误（18） 产品（16） 多线程工作（20） 混乱（27） 侯世达定律（10） 近期未来（5） 精益创业（15） 矩阵方法（28） 帕金森第一定律（9） 求知（25） 社会认同陷阱（39） 收益半衰期（6） 适应性专长（22） 收益值（6） 心智独特性（38） 远期未来（5） 自我决定论（34） 最小化可行产品（15） 书摘 我们总是在惯性中生活，在教导下学习，在成规中思考，在劝解中决定，并在无助的结果中自责。我们着实需要一种智识和能力，去观察、反思自己被局限的生活，去发现和实践更多成长和成才的路径。 郑重是这样一种态度:不敷衍、不迟疑、不摇摆，认真地聚焦于当下的事情，自觉而专注地投入；郑重是这样一种态度:因恪守本心而知事情轻重缓急，因尽全力无保留而使其事竟成、光阴未曾虚度。 根据不同的时间视角可以划分出五种人: 第一种是积极过去视角 第二种是消极过去视角 第三种是享乐主义视角 第四种是以宿命的观点看待当下的人，即具有宿命论视角 第五种是习惯往前看、为未来谋划的人，这种视角被称为未来视角 更好对待时间的十条建议： 生活在当下——不瞻前顾后，不左顾右盼，不患得患失; 严肃地对待时间——审慎、郑重地思考时间对我们的价值并用好它; 留意自己拥有的空间 并享受它——找到自己的“独享时刻”，不要疲于奔命; 反思自己和其他人的时间视角——认识到自己和他人时间视角的异同，换位思考; 从现在出发联结过去——过去并没有远去，它对今天仍具有意义; 并不完全沉浸于过去——比过去更重要的是现在; 制订实现目标的计划——未来视角让我们的行动更加有序; 平衡计划和非计划时间——由于随机性和不可预见因素的影响，我们的生活并不能完全被计划，平衡计划和非计划就是在未来视角和现在视角之间找到 平衡点; 视未来存在于当下——未来并非遥不可及，它就出现在即将到来的每一分每一秒; 对未来保持积极的态度——既然未来难以预测，那么以 积极的心态面对它能让我们在当下更有行动力。 要想处理好“远期未来”和“近期未来”，我们可以采用下面两个策略: 使远期未来的目标更加具体化、情境化和可实施; 降低近期未来中的“非期望行为 ”的便利性，主动增加挑战的难度。 在分析一件事情值不值得去做、花多少精力去做的时候，可以从两个角度来评估:一是这件事在当下将给“我”带来的收益大小，这个收益可以是心智、情感层面的，也可以是身体、物质层面的，我称之为“收益值”;二是这项收益随时间衰减的速度，我称之为“收益半衰期”，半衰期长的事件，其影响会持续较久。 现代社会的快节奏、碎片化和功利性等特点，使得现代人很容易陷入“两个无能”之中，一是“选择无能”，二是“执行无能” 辨认“信息噪音”有一个立竿见影的方法，就是调整评估信息价值的时间尺度。 帕金森第一定律:工作会自动膨胀，直至占满所有可用的时间。 侯世达定律:“实际做事花费的时间总是比预期的要长，即使预期中考虑了侯世达定律。” 仅仅是好的选择是不够的，我们需要的是最好的选择。 说到“格局为何”，电影《一代宗师》已经做了很好的回答，即“看自己、看天地、看众生”。 开始并完成一件事情，比做好它更重要。 种一棵树最好的时间是十年前，其次是现在。即刻行动应该是我们最重要的一条行动法则。 “精益创业”(Lean Startup)是当前互联网创业最流行的方法之一。“精益创业”中有个关键概念叫 “最小化可行产品”(minimum viable product，MVP)，它指的是可以使用最少资源、被最快制作出来的、可执行基本功能的、能被用户使用的试验性产品，创业者应该尽快把最小化可行产品 发布出去，然后根据用户使用它的反馈来进行优化，这一过程称为“构建—测量—学习”(Build-Measure-Learn)的循环。 那么，对一个个体来讲，他的最小化可行产品是什么呢? 回答这个问题就要搞清楚“产品”这个概念的内涵: 1.“产品”不是过程，而是结果; 2.“产品”不是对 原料、素材的简单堆积，而是对它们结构性的整合和组织; 3.“产品”不是创制者锁在自己保险箱里的东西，而要能被其他人使用和检验; 4.“产品”能独立对世界产生影响，它应该能创造出正向的价值，使人受益; 5.“产品”也是一种媒介。 法国作家莫里哀说:“我们越是爱自己的朋友，就越是会批评他们。” 产品迭代需要推倒重来的勇气，这并不容易，因为人们总是留恋自己已经付出的努力，而不管这些曾经的努力对未来是否已经失去了价值，这也称为“沉没成本谬误”。 所以以精益创业的方式去走向人生的成功，便要做到这三点: 克服“过度准备”的惯性，向前一步，把未完成的事情完成; 克服“自我防卫”的心态，乐于接受反面意见并加以慎重地审视; 克服“沉没成本”的固执，有勇气否定并重新构造自己的产品。 多线程工作，首先需要一段专注不受干扰的时间，完成工作中最核心部分的思考。 只有最后能够作用于现实的学习，才是唯一有效的学习。 教育心理学家把在某一领域有专长的人士，分为“常规型专长”(routing expertise)和“适应型专长”(adaptive expertise)两类，其中具有常规型专长的人 具有一个基本固定的知识系统，可以以很高的效率把他们所接触到的信息材料按照已有的框架进行分析，而具有适应型专长的人则可以让自己的能力不断地“进化”，通过对知识的广度和深度的扩展来适应问题解决的需要。 学习应该是深度和广度的结合。广度能够让人不闭塞，深度能够让人不只是学之皮毛。 “变构学习模型”(allosteric learning model):“构成学习者思维独特性的并非是他所录入的观点序列，而是他有能力启动和调用的关联。” 求知分为三个层级:信息、知识和技能。技能是学习的终点，信息和知识是迈向这个终点的路与桥。 学会有意识地去分析不同领域知识之间的潜在关联，通过不同知识的迁移、印证、互补，获得启发，甚至生成新的思想或者发现。 混乱是秩序的另一种形式。通过混乱颠覆固有的、模式化的思维习惯，最终构建出新的秩序。 使用矩阵方法，我们可以采用如下三个步骤: 抽象出尽可能完整的分解问题的维度(比如产品的最终形态无法穷举，但是决定产品形态的抽象维度可以 穷举); 对每一维度，通过取反、细分等操作，找出尽可能多的表现值，以构成维度矩阵; 在维度矩阵中不同维度的表现值之间尝试建立各种组合。 努力不是一场意志力的较量，而是一种需要学习的策略。 专心做好一件事，哪怕这件事看上去极不起眼。三心二意、畏葸不前、瞻前顾后、贪多求快、跟风冒进都是大忌。 胡适说，不苟且就是“狷介”。胡适认为，狷介不仅是一种德行，也是一种做学问的品格，也就是“一丝一毫不草率不苟且的工作习惯”。 一条重要的提升学习效果的原则，叫“必要难度”(desirable difficulties)，通俗点讲，就是学习的时候，要给自己增加一些难度，这对提升学习效果是非常必要的。 人总是喜欢轻易地作评判、下定论、贴标签，用过于简单的概括来代替细致深入的观察。 当代心理学中有一个著名的理论叫“自我决定论”，说人有三种基本的心理需要，分别是自主的需要(autonomy)、能力的需要(competence)和归属的需要(relatedness)，如果这些需要得到了满足，那么人就会更加主动、积极和愉快地工作和学习。 在新思想或新技术刚刚开始兴起无人问津之时就投入进去，成为某一个新知识领域的先驱，实现知识能力的“低买高卖”。 如何求解现实问题? 1.正确地认识问题，而不是简单地使用别人的问题表述。 2.对问题进行完全独立的思考，不借助书本和搜索引擎，因为你面前的问题是独一无二的、全新的。 3.继续独立地思考，但是你可以在希望比较大的求解方向下，有针对性地寻找相关联的知识，此时你需要快速筛选和学习新知识，甚至需要不带偏见的、 尽可能多地寻找各种可能有益的知识，也包括与他人交流意见。 4.在结合知识以分析问题的过程中，你可能会试着提出一些假设性的理论或者模型。 5.你提出的理论必定需要修正，这时你可以用你的理论去尝试解决问题，也可以试用于各种扩展情境，如果发现其bug就立即修正。 6.但由于理论毕竟是对现实的抽象，所以你还需要去关注各种细节性的问题，去通盘考虑现实情况，去穷尽和评估各种因素。 在现实世界中思考理论问题，在理论世界中思考现实问题。 具有心智独特性的人所具有的优势: 在主流观点之外洞察出别人未曾发现的机会; 形成个人核心竞争力，避免低层次的同质化竞争，使自己不可替代 ; 拒绝他人和大众给自己贴上的标签，以更开放和自由的心态发展自己; 因为不必迎合社会主流而节约了大量时间精力，可以专注于做好自己的事情; 为大众带来新鲜的见解和启发，形成对公众的影响力; 具有更高的可 辨识性，更易于形成个人品牌; 吸引到其他独特而优秀的人，与他们成为朋友或者合作伙伴。 当我们避开了追求社会认同的陷阱，也意识到去做酷事的价值以后，我们可能便走上了因独特而成功的道路。在这条道路上，下面七个方法能够助我们一 臂之力: 1.抗拒自己的欲望，或者延迟满足欲望; 2.质疑貌似最可信的言论，不盲从任何人; 3.屏蔽流行信息，或者只在固定的时段接收流行信息; 4.思考最不可能的事，为其发展出可能性; 5.保留和发展自己的“怪癖”，并将其发展成自己的竞争力; 6.为小事物狂热，并在小事物中发现大世界; 7.开展思想试验和行动试验，让思想和行动相互激发。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>书摘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《极简经济学》书摘]]></title>
    <url>%2F2017%2F01%2F07%2Fthe-instant-economist-clippings%2F</url>
    <content type="text"><![CDATA[这篇博客是我阅读《极简经济学》时所摘录的书摘。与诸君分享。 研究经济学的理由就是“为了避免被经济学家欺骗”。 经济学研究的三个基本问题： 社会应该生产什么? 应该如何生产? 谁来消费所生产的东西? 寻找问题的可能答案时，沿着一条光谱来思考是有帮助的。光谱的一端是政府完全管制:政府机关决定生产什么、如何生产以及谁来消费。在光谱的另一端，你可以想象有一个社会，由个人决定这三个问题的所有答案。 很多经济取舍都有一个特色:它能帮助某些人，却同时伤害了其他人。经济学家关心的是统计受到伤害或帮助的所有人，而不只是新闻报道里的几张脸孔。 “看不见的手”(invisible hand)的概念，就是你在追求自己的利益时，可能也会给别人带来好处。 所有成本都是机会成本(opportunity cost)。当你做一个选择时，你没有选择的东西就是经济学家所谓的“机会成本”。 用机会成本来思考，将包含没有用钱来衡量的成本。 没有哪个人可以得到想要的每样东西，也没有哪个社会可以得到想要的每样东西，因此，取舍是不可避免的。在人们有各种技能与欲望的现代经济社会中，问题在于如何协调决定生产什么、如何生产以及为谁生产。 分工为生产商品的厂商与国家经济创造了显著的经济利益。它是如何办到的? 分工使工人能聚焦于他们最适合做的事，又使企业能充分利用当地资源。 分工使企业得以利用规模经济(economics of scale)。“规模经济”是个专有名词，用 来说明大厂相对于小厂可以用较低的平均成本来生产。 关于国际贸易的利害得失当然是复杂的议题，稍后会深入探讨。但整体而言，每个国家专精于特定产品乃至于特定服务，这样的分工对所有参与者都更有利。 在市场经济里，送进仓库及从中取出的商品的价值，是由供给与需求决定的。 你应该开始了解一下经济学家是如何看这个世界的:分工导致商品与服务的交换，社会必须以某种方式协调所有的生产与消费。 当经济学家谈到价格时，指的就是交换价值。一个商品的交换价值与其稀有性有关— —商品值多少钱，和多少人想要拥有它有关。 如果商品的价格高于均衡点，那么该商品的供给量将超出需求量，东西将开始滞销;如果商品价格落在均衡点下方，那么需求量将超出供给量。 需求弹性的定义是需求量变动的百分比除以价格变动的百分比，为什么弹性是用价格与数量变动的百分比来计算的?这个方法的主要优点是可以用来比较各种不同的市场，其商品可能是以不同度量衡单位计数，或可能是以不同货币计价。 在商品市场，企业是供给者，家庭和个人是需求者;在劳动力市场，家庭和个人是供给者，企业是需求者。 工会提供两个基本功能： 第一，找机会通过劳动契约的协商提高会员工资，并以罢工威胁为后盾。 工会的第二个功能是培养一个更好的、更具生产力的劳动力 有时，“投资”是指购买股票与债券等金融工具，有时则指企业购买实物资本(physical capital)，例如机器或厂房。前者指的是投资人，他们是在最小风险下追求最大报酬的资金供给者。后者其实指的是厂商，他们是把资金转换成有形资产的资金需求者。 经济学家认为，资本供给是家庭的资金供给量(也就是家庭储蓄)与它们提供资金所得到的价钱(也就是报酬率)之间的关系。 完全竞争产业的主要特征是价格接受(price taking)，也就是说，完全竞争的企业必须接受市场给定的价格。 竞争让商人过得非常辛苦。相反，消费者应该赞成竞争，因为竞争可以提供更低成本的创新产品，市场竞争是对消费者最有利的方式。 一份价格维持(price maintenance)合约里，制造商把东西卖给一群经销商，坚持某个最低转售价格，以防止经销商彼此竞争过头。 当制造商要求经销商只能卖自己的产品，而不能卖竞争者的产品时，称作独家交易 (exclusive dealing)。 ·搭售(tie-in sale)或捆绑销售(bundling)，是指顾客只有在买了某个产品搭售(tie-in sale)或捆绑销售(bundling)，是指顾客只有在买了某个产品时，才能买另一个产品。 ·掠夺性定价(predatory pricing)，是指既有厂商大幅削减价格，幅度够低且时间够长，把新的竞争者赶出市场后，再提高价格以达到独占水平。 然而，想出减少碳排放的方法不难，真正的困难是:用市场导向、弹性的方法来执行， 用最低的经济成本来限制碳排放。 合理的政策目标是平衡生产效益与污染成本，换言之，让生产的社会成本与社会效益彼此平衡。 推动创新的关键因素，是创新者从研发投资中得到大部分经济利益的能力，经济学家称之为“专属性”(appropriability)。 专利是用来预防竞争的，但对其他想进入市场的竞争者而言，这些专利可能会变成巨大的(有时是永远的)障碍，并且阻碍额外的创新。 公共物品有两个重要特性:它们是非竞争性(nonrivalrous)与非排他性 (nonexcludable)。非竞争性是指商品本身不会因为更多人使用而变少。非排他性是指卖家无法排除那些没付钱也能使用商品的人。 如何解决贫穷陷阱?有几个方法可用。 其一是逐步淘汰新近就业家庭的福利。 美国运用的另一项政策是薪资收入租税抵减，当低收入家庭赚钱时，给其额外的收入， 以抵消政府撤回的其他福利。 避免贫穷陷阱的另一种方式是提供实物的帮助，意即以某种非现金的服务来支持，医疗补助保险与食物券都属此类。 信息不完全与保险:信息不完全造成了保险市场难以解决的失衡问题。 我们已知政府在市场经济中可能扮演多重角色，以公共权力改善社会福利:抑制垄断厂商、阻止公司的违法竞争行为、减少污染、扶持科技产业、提供公共物品、对抗贫穷和收入不均，以及处理信息不完全的问题。 市场是非常有用的制度，社会可以通过市场来分配其稀有资源。市场为有效率的生产、 创新、善用资源、满足消费者需求和欲望，以及逐渐提高生活水平提供动力。 市场有时可能会产生我们不想要的结果:垄断、不完全竞争、负外部性(例如污染、无法支持技术或无法生产公共物品)、贫穷、收入不均、信息不完全，以及管理不善的问题。 政府在处理市场问题时可以扮演有用的角色，但它的行动也是不完美的，在某些情况下，甚至会造成自身更大或另外的问题。 人均 GDP 较高的经济体，在很多方面都有较好的发展。 微观经济学关注商品、劳动力及资本的个别市场，以及垄断、竞争、污染、科技、贫穷、收入不均、保险和治理等议题 宏观经济政策的四个目标是:经济增长、充分就业、物价稳定和国际收支平衡。 宏观经济政策的两组主要工具，是财政政策和货币政策。 财政政策是政府税收和支出的政策，包括政府预算和预算赤字。 货币政策是指中央银行的政策，它会影响利率、信用以及社会上借款与放款的数量。 GDP 的定义是:一个经济体一年内所生产的最终商品和服务的总价值。GDP 可以根据 生产与销售的商品价值，或需求与购买的商品价值来衡量。 如果你问一个经济学家 GDP 是什么，有时他会回答 GDP=C+I+G+X-M，也就是:GDP= 消费+投资+政府支出+出口-进口。 GDP 呈现明显且持续的下滑，就叫作经济衰退(recession)。一些经济学家认为， GDP 持续下滑六个月(也就是两个季度)就是持续性衰退(lasting downturn)，但这 个时间范围并非官方定义。 预测一个经济体未来的价值(FV)，公式是拿它的现值(PV)乘以“1+经济体的增长 率”的 t 次方，t 是年期数[PV(1+r)t=FV]。 生产力增长的三大驱动因素是:实物资本增加(意即有更多的资本设备让员工使用)、 更多的人力资本(意即员工有更多的经验或更好的教育)以及更好的技术(意即更有 效率的生产方式)。 生产力的标准算法是先计算每位员工增加的教育和经验，以及每位员工增加的实物资本设备。 分析低收入国家的经济增长原因，你会发现其教育程度和实物资本呈现快速更新，即生产力的增长主要来自实物资本和人力资本的增加，较少来自新技术。 失业:劳动需求量下降，才会导致失业。 失业为什么不好?失业的代价是什么? 就个人角度来看，失业会伤害没工作的人。个人的损失不单是没有收入而已，远甚于此。失业会带来社会问题，从家庭的沉重压力到健康变差，甚至引起社会犯罪。 从社会层面来看，失业会缩减国家经济规模。 经济学家把失业分成两类:自然失业和周期性失业。自然失业来自动态衰退以及员工就业与产业的变动。 当一个国家有大量购买力却没有相对足够的商品时，通胀就会随之发生。 贸易差额:贸易顺差与逆差，谈的是金钱的流向，以及向哪边的流动比较大。 出口大于进口，该国就有贸易顺差(trade surplus)。进口大出口，该国则是贸易逆差(trade deficit)。 国民储蓄与投资恒等式始于一个基本概念:金融资本的总供给量必须等于金融资本的总需求量。 金融资本供给有两个主要来源:国内资金的储蓄加上国外资金的流入。金融资本需求也有两个主要来源:国内实物资本的投资需求和政府借款。 保护主义(限制从国外进口商品)也不能解决贸易逆差的问题。若流入美国的外资变少，则必须降低预算赤字(亦即要加税或降低政府支出)，或者要提高国内储蓄率(亦即要节制消费)，或者企业要自备扩张资金。这些选择都不吸引人，但如果美国保持目前的高额贸易逆差，这三个选项的其中之一(也许三者)势必将发生。 如果社会有能力生产的东西发生变化，总供给就会移动。总供给移动的两个主要原因是大量企业的技术发展以及生产条件发生剧烈改变。 在看重总供给的萨伊定律和看重总需求的凯恩斯法则之间，有一个看似可行的、务实的折中方案:凯恩斯理论强调总需求的重要性，它和短期政策更有关联;而新古典经济理论强调总供给的重要性，对长期经济更重要。这大概是当代经济学家的主流观点。 价格的确会反映需求和供给的力量，但根据宏观经济的观点，改变整个社会所有商品价格的过程(无论是向上还是向下)需要时间。如果某些市场的价格没有快速调整，就可能会出现生产过剩(商品堆积在货架上)或生产短缺(至少短期内商品会销售一空)的情况。 菲利普斯曲线反映通胀率与失业率之间的取舍关系 当政府的支出超过税收时，要去哪里筹钱?答案是发行债券。 反经济周期的财政政策:租税是自动的、反经济周期的财政政策。 使社会的总需求增加或购买力提高的政策，称作“扩张性”(expansionary)宏观经济政策，或称作“宽松”(loose)的财政政策。扩张性政策包括减税与增加支出，两者都会使更多的钱流入社会。 用来降低总需求的政策，称作“收缩性”(contractionary)政策或“紧缩”(tight)的财政政策。增税或减少支出的政策属于收缩性财政政策，会降低社会的购买力。这种财政政策的基本目的是平衡经济衰退和扩张。 反经济周期的财政政策可以用两种方式实施:自发性或权衡性。自发性稳定机制是指政府的财政政策在不需要动用法律的情况下，当经济衰退时自动刺激总需求，当经济扩张时自动抑制总需求。 预算赤字与国民储蓄:短期的预算赤字，在经济衰退期间不是一件坏事。 如果政府预算赤字增加，以下三件事的某些组合必定会发生:私人储蓄增加，私人投资下降，或外资流入增加。 嘉图等价定理认为，当人们注意到政府预算赤字偏高时，便预期在未来某个时间点会增税，因此必须增加储蓄。以此理论模型推导，个人储蓄增加可能是为了提供资金作为政府借款， 应对预算赤字增加的另外两种方式，就是减少私人的实物资本投资或扩大贸易失衡。经济理论的“挤出效应”(crowding out)认为，如果政府借越来越多的钱来管理它的赤 字，就会减少民间企业可取得的用于投资的资金。因此，政府借款增加意味着私人投资减少。相反，政府借款减少就表示企业可取得更多资金用于投资。 第三个理论称为“挤入效应”(crowding in)，意思是政府大量借款会带来贸易逆差。 货币银行学:银行实际上是通过放款的过程来创造货币。 经济学家不是用货币形式来定义货币，而是把社会上具备下列三个功能的任何物品定义为货币:交易媒介(medium of exchange)、价值储存(store of value)、计账单位 (unit of account)。 交易媒介是可以拿来交换任何待售商品的某样东西。 作为价值储存的工具，货币是可以暂时持有而不会失去有效购买力的物品。 货币的最后一个功能是作为计价单位，意思是大部分商品的价格是用货币来衡量的。 政府统计学家有其定义货币的方式，他们使用一系列的定义，我们称之为 M1 和 M2。 M1 货币包括通货(硬币与钞票)、旅行支票与个人支票账户。 M2 是更广义的货币，是由 M1 加上储蓄账户构成的。储蓄账户大致可定义为银行活期 存款，你无法用它直接开支票，但可以用其他方式(例如自动提款机或银行)轻易存 取这笔钱。M2 货币包括货币市场基金、某些极安全的投资以及小额(低于 10 万美元) 定期存款(CD)。 银行是通过放款的过程来创造货币。 中央银行有三个传统工具，可在银行与货币的架构内运作:法定准备金(reserve requirement)、贴现率(discount rate)、公开市场操作(open market operation)。还有一个因 2007~2009 年经济衰退而开发的工具，称作量化宽松(quantitative easing)。 法定准备金是银行不可贷放出去的存款比率。每家银行都被要求在中央银行储备一些存款，实际上，银行必须把这笔钱存入中央银行。 再贴现率是央行扩大或抑制放款的另一种方式。它就需要在很短的时间内(理论上是隔夜)借钱，来平衡放款和存款，以符合法定准备金率的要求。银行经常为此互相借钱，如果银行为此向中央银行借钱，所需支付的利率就是再贴现率。 2008 年以前，公开市场操作向来是货币政策的主要工具。所谓公开市场操作，是指中央银行购买或销售债券，以增加或减少货币供给。 债券不是货币，不是 M1 或 M2 的一部分。 货币政策工具的最新方法是量化宽松，过去只是理论，2008 年以前从未在美国使用。 它可以用两种方式来操作，其一是美联储可以把钱贷给金融市场的参与者。量化宽松的另一个做法，是由美联储购买较长期的证券。 美联储的工作之一，是为可能导致现金需求波动的情况做准备。 当通胀率出现负数时，称作通货紧缩(deflation)，意即货币的购买力不但没有随当通胀率出现负数时，称作通货紧缩(deflation)，意即货币的购买力不但没有随着 时间变低，反而随着时间变得更高。 实际利率(real interest rate)等于名义利率(nominal interest rate)减去通胀率。 国际贸易利益:相似商品的跨国界贸易会给国内生产者带来更激烈的竞争，而竞争有助于低价和创新。 国际贸易为什么能为所有参与的国家创造双赢?有几个理由。来自贸易的潜在利益可以分为三大类:绝对优势(absolute advantage)、比较优势(comparative advantage) 以及动态增益(dynamic gains)。 从贸易条件来看，如果一个国家可以用比另一个国家更高的生产力来制造某商品，无论是每小时有较高的产出，还是达到同样产出的投入要素较少，那么这个国家就具有经济学家所说的绝对优势。 这种相似产品的贸易，对两个国家的经济有什么好处呢? 第一个好处是使较小的国家善用规模经济。 这种贸易的第二个好处是多样性的利益。 相似商品贸易的第三个好处，是使产业的专业化程度更高。 保护主义论战:保护主义是指政府对国内产业提供间接补贴，由国内消费者用较高的价格埋单。 虽然大多数经济学家都支持自由贸易的力量，但他们也承认自由贸易有可能造成经济混乱或崩溃。 实施保护主义有几种方式。进口配额(import quota)是对进口采取数量限制，关税 (tariff)是提高进口成本的一种税。 保护主义，用经济学术语来说，是政府对国内产业提供间接补贴的一种方式，由国内消费者用较高的价格埋单。 关于产业补贴，或许最著名的论点是保护主义可以使国内工人受益。这个论点出于四种不同考虑(有些可能较其他更有说服力):进口可能影响国内工人可获得的工作总，进口可能影响平均薪资水平，进口可能造成产业崩溃、工人失业，进口可能导致整个社会的工资不均加剧(即使平均工资增加)。 对于国际贸易的另一个顾虑是掠夺式定价的问题，或称“倾销”(dumping)，即以低于 成本的价格销售商品，将竞争者赶走，取得垄断地位后，再提高价格。 经济全球化的趋势势必仍将持续，驱动因素有三个: 通信技术与交通的发展使全球的经济联结更容易;国际协议降低了贸易的法律障碍;中国、印度、巴西等出口导向经济体的崛起。 汇率:利用稳定或缓慢变动的汇率，可创造有利于贸易与投资的环境。 强势货币有助于外国资金的净流入，而弱势货币则会抑制外国资金的流入。强势货币往往会抑制出口、促进进口，并导致贸易逆差。就投资而言，强势货币有助于资金流入。 一般而言，外资可以分为两类: 一类是购买有形公司或工厂的直接投资(direct investment); 另一类是购买股票或债券等金融工具的证券投资(portfolio investment)。 宏观经济政策的四个目标是:经济增长、充分就业、物价稳定、国际收支平衡。 讨论宏观经济政策的架构称作总供给与总需求模型。 财政政策和货币政策是宏观经济政策的两组主要工具。前者是政府税收和支出的政策， 包括政府预算和预算赤字;后者是指中央银行的政策，它会影响利率、借款与放款。 出口大于进口，该国就有贸易顺差;进口大于出口，该国则有贸易逆差。顺差与逆差探讨的是金钱的流向，以及向哪边的流动比较大。 凯恩斯法则(需求创造其自身的供给)注重短期几年内的经济周期，萨伊定律(供给创造其自身的需求)倾向于更注重长期。 使社会的总需求增加或购买力提高的政策，称作扩张性或宽松的财政政策，包括减税与增加支出;反之则为收缩性或紧缩的财政政策，包括增税或减少支出。 未来的经济将不再是固定成长式的零和游戏，而像是一种合作创业，如果每个国家在遍布全球的贸易、生产、技术与知识的网络中合作，那么大家便都能更快速地成长。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>书摘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[山东大学机器学习课程复习提要(2016)]]></title>
    <url>%2F2016%2F12%2F30%2Fmachine-learning-2016-summary%2F</url>
    <content type="text"><![CDATA[本篇博客为我本人复习《机器学习》课程时所整理，该课程所用教材为周志华先生的《机器学习》一书，该书是一本质量极高的中文机器学习方向的教科书，希望对机器学习有兴趣的读者可以去花时间阅读一下。 简答部分1.应用贝叶斯决策需要满足的三个前提条件是什么？ 答：若要使用贝叶斯判定准则来最小化决策风险 R，首先要获得后验概率 P(c|x)，基于贝叶斯定理： $$P\left( { c }|{ x } \right) =\frac { P\left( c \right) \cdot P\left( { x }|{ c } \right) }{ P\left( x \right) }$$ 其中，P(c)是类先验概率，P(x|c)是样本 x 相对于类标记 c 的类条件概率（似然）。 2.试简述对先验概率和后验概率的理解 答：先验概率表达了样本空间中各类样本的比例，根据大数定律，当训练集包含充足的独立同分布样本时，先验概率就可以通过各类样本出现的频率来进行估计。 后验概率是通过贝叶斯公式对先验概率进行修正，计算而得出的概率。 3.试简述 Fisher 线性判别的基本思想 答：对于给定的训练样本，需要设法将这些样本投射到一条直线上，使得同一类样本在该直线上的投影点之间的距离尽可能的小，非同一类样本在该直线上的投影点之间的距离尽可能大；在对新样本进行分类时，将它同样投影到该直线上，根据其投影点的位置来判断它的类别。 4.试简述何为 K-近邻法 答：K-近邻学习是一种常用的监督学习方法，其工作机制非常简单：给定测试样本，基于某种距离度量（比如欧几里得距离）找出训练集中与其最靠近的 K 个训练样本，然后基于这 K 个『邻居』的信息来进行预测。 5.试简述对非线性支持向量机（SVM）的理解 答：对于线性支持向量机，选择一个合适的惩罚参数，并构造凸二次函数线性规划问题，求得原始问题的对偶问题的最优解 $ { \alpha }^{ \ast } $ ,由此可以求出原始问题的最优解；在处理非线性行问题时，通过选择合适的核函数来将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分。 6.试简述何为度量学习 答：在机器学习中，对高维数据进行降维的主要目的是希望找到一个合适的低维空间，在此空间中学习比原始空间更好。事实上，每个空间对应了在样本属性上定义的一个距离度量。度量学习就是通过『学习』来找出一个合适的距离度量。 7.简述何为半监督学习 答：半监督学习(Semi-Supervised Learning，SSL)是模式识别和机器学习领域研究的重点问题，是监督学习与无监督学习相结合的一种学习方法。它主要考虑如何利用少量的标注样本和大量的未标注样本进行训练和分类的问题。主要分为半监督分类，半监督回归，半监督聚类和半监督降维算法。 8.试简述何为聚类 答：聚类试图将数据集中的样本划分为若干个通常是不相交的子集称为一个『簇』，通过这样的划分，每个簇可能对应于一些潜在的概念（类别），并且这些概念对于聚类算法而言事先是未知的，聚类过程仅能自动地形成簇结构，簇所对应的概念语义需要使用者来把握和定义。 9.简述对稀疏表达的理解 答：假设一个样本数据 D，D 对应的矩阵中存在很多零元素，并且它们不是以整行整列的形式出现的，这样的稀疏表达形式对学习任务会有不少好处（例如，SVM 在文本上有很好的性能）；若给定数据集 D 是稠密的，即普通非稀疏数据，我们可以通过『字典学习』（『稀疏编码』）来将样本转化为合适的稀疏表示。 10.简述对流型学习的理解 答：流型学习是一类借鉴了拓扑流形概念的降维方法，它可以容易的在局部建立降维映射关系，然后再设法将局部关系拓广到全局；流型学习也通常被用于可视化，因为当维数被降至二维或三维时，能进行可视化。等度量映射和局部线性嵌入是两种著名的流型学习方法。 11.简述对同分布问题的理解 答：通常假设样本空间中的样本全部都服从一个未知的分布 D，我们获得的所有样本都是独立同分布的从这个分布上采样获得的，即『独立同分布』，一般而言，训练样本越多，我们得到的对于 D 的信息越多。 12.试简述对模型泛化能力的理解 答：机器学习的目标是使学得的模型能很好地应用于『新样本』，而不是仅仅在训练样本上工作得很好，学得模型适用于新样本的能力称为『模型泛化能力』。具有抢饭化能力的模型能很好地适用于整个样本空间。 13.为什么机器学习此时才热起来？ 答：两个基本原因：数据大了，计算能力强了。 数据小，样本少，容易产生过拟合问题，面对复杂模型，计算能力不够，则无法求解。 计算问题设在某个局部地区细胞识别中正常 w1 和异常 w2 两类的先验概率分别为： 正常状态：P(w1) = 0.9 异常状态：P(w2) = 0.1 现有一待识别的细胞，其观察值为 x，从类条件概率密度分布曲线上查得： P(x|w1) = 0.2, P(x|w2) = 0.4 试使用贝叶斯决策对该细胞 x 进行分类 答：根据贝叶斯公式： $$P\left( { \omega _{ 1 } }|{ x } \right) =\frac { P \left( { x }|{ \omega _{ 1 } } \right) \cdot P \left( \omega _{ 1 } \right) }{ P\left( { x }|{ \omega _{ 1 } } \right) \cdot P\left( \omega _{ 1 } \right) +P\left( { x }|{ \omega _{ 2 } } \right) \cdot P\left( \omega _{ 2 } \right) } \approx 0.818$$ 又有， $$P\left( { \omega _{ 2 } }|{ x } \right) =1-P\left( { \omega _{ 1 } }|{ x } \right) =0.182$$ 因为， $$ {P}\left( { { w }_{ 1 } }|{ x } \right) &gt; {P}\left( { { w }_{ 2 } }|{ x } \right) $$ 所以，x 归类于正常状态。 论述部分如果让您设计与实现一个模式识别系统，用于实现齐鲁软件学院男、女士的分类（二分类问题），您将如何考虑？其中有哪些需要注意的问题？请就您的理解，尽可能全面，深入地描述，以此展示您对《模式识别技术》这门课程的理解。如果您觉得必要，必要之处也可以画图辅助表达。 答：假设我们所拥有的训练样本有如下属性： 身高 是否喜欢网购 出行次数（月） 生活费（月） 性别 155 是 12 2500 女 159 是 11 2200 女 182 否 8 1800 男 …… …… …… …… …… 我们可以采用 ID3 决策树算法来用于对学生性别的分类。 在建立决策树的过程中，首先需要对属性进行划分，为了选择出最优划分属性，我们需要计算出用每个属性对样本集进行划分所获得的信息增益，选择信息增益大的属性划分，我们可以得到一棵决策树。 可能存在的问题： 过拟合：我们可以通过剪枝来解决过拟合的问题，使得决策树不会出现分支过多的问题。 连续值处理：对上述例子中的身高属性，即为连续值的属性，因为连续属性的可取值的数目不是无限的，所以不能根据属性值来划分，因此要计算，找出划分点。 缺失值处理：如果某些样本的某些属性缺失，我们也不能浪费这些样本，C4.5 算法提供了解决方案。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>笔记</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSAPP 实验I 数据操作（bits lab）（doing）]]></title>
    <url>%2F2016%2F12%2F15%2Fcsapp-labss-01%2F</url>
    <content type="text"><![CDATA[TODO]]></content>
      <tags>
        <tag>技术</tag>
        <tag>CSAPP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSAPP - 数据的表示和操作]]></title>
    <url>%2F2016%2F12%2F15%2Fcsapp-notes-02%2F</url>
    <content type="text"><![CDATA[这篇文章是 CSAPP 的第二章的学习笔记，内容为数据的表示和操作。计算机使用二进制来表示数据，1位的数据通常没有什么作用，因此我们需要把许多位组合起来进行表示，例如，对于数字我们有无符号整数表示、补码表示、浮点数表示方法，同时我们还要考虑溢出、符号等问题。 数据的存储计算机不是一位一位对数据进行操作的，一般都是以 byte (8 bits) 作为单位，这是内存最小的寻址单位。内存中的每个 byte 都有一个标识作为它的地址（虚拟地址空间） 进制表示二进制、十进制、十六进制之间的转换如下表所示： 十六进制 0 1 2 3 4 5 6 7 十进制 0 1 2 3 4 5 6 7 二进制 0000 0001 0010 0011 0100 0101 0110 0111 十六进制 8 9 A B C D E F 十进制 8 9 10 11 12 13 14 15 二进制 1000 1001 1010 1011 1100 1101 1110 1111 字长通常机器字长决定内存的寻址空间，我们所听到的32位计算机、64位计算机，指的就是机器字长（32位计算机可寻址的内存大小为4GB），另外通常机器字长就是 C 语言中指针的大小。 数据的大小在 C 语言中，不同的数据类型的大小是不同的，并且不同字长的机器相同的数据类型有可能大小也是不同的，例如： C 语言数据类型 32位机器 64位机器 char 1 1 short int 2 2 int 4 4 long int 4 8 long long int 8 8 char * 4 8 flout 4 4 double 8 8 寻址顺序和字节顺序大端和小端（Big endian &amp; Little endian）以存储『0x01234567』为例： 大端： 小端： 存在的问题大端、小端存储顺序的不同造成了不同计算机之间进行的网络传输存在问题，因此在网络传输的过程中需要双方计算机了解互相的数据是采用大端还是小端方式，然后将接收到的数据按照自己的数据字节顺序进行表示。 字符串的表示在 C 语言中，英文字符串的表示 通常是：ASCII 码 + ‘\0’，例如，字符串”12345”通常编码为：『31 32 33 34 35 00』 布尔代数非 ~ 0 1 1 0 与 &amp; 0 1 0 0 0 1 0 1 或 \ 0 1 0 0 1 1 1 1 异或 ^ 0 1 0 0 1 1 1 0 C 语言中的逻辑操作C语言中的逻辑操作包括：逻辑与（&amp;&amp;）、逻辑或（||）、逻辑非（！） 下面直接看一个例子： x = 0x66; y = 0x39 123456 表达式 | 值 | 表达式 | 值 |============================================= x &amp; y 0x20 x &amp;&amp; y 0x01 x | y 0x7F x || y 0x01 ~x | ~y 0xDF !x || !y 0x00 x &amp; !y 0x00 x &amp;&amp; ~y 0x01 C 语言中的移位操作对于移位操作，通常有两种：算数移位和逻辑移位，对于右移操作分为算术右移和逻辑右移；对于所有的左移操作我们都认为它是逻辑左移。 规则为： 左移操作：低位补0，高位移出。 逻辑右移：高位补0，低位移出。 算数右移：若高位为0，高位补0，低位移出；若高位为1，高位补1，低位移出。 我们来看一个例子： x x &lt;&lt; 3 x &gt;&gt; 2（逻辑） x &gt;&gt; 2（算数） 1100 0011 0001 1000 0011 0000 1111 0000 0111 0101 1010 1000 0001 1101 0001 1101 整数的表示无符号整数的表示无符号整数的表示在编码上就相当于从十进制直接转换为二进制。公式如下： 其中，B2U表示从二进制（Binary）转化为无符号整数（Unsigned interger），w 表示总共用多少位来表示。 补码表示补码表示法将最高位用作符号位，公式如下： 例： 类型转换中的扩展与截取 扩展（从 short 到 int） 无符号数：直接高位补0 有符号数：补符号位 截取（int 到 short）：对于小的数正常截取 无符号数：mode 操作 有符号数：近似 mode 操作 整数的运算无符号加法对于无符号加法，两个 w 位的数字相加，结果有可能是 w+1 位，对于这种情况，我们会舍弃最高位，也就是发生了溢出。 补码加法补码加法操作方式和无符号加法是一致的，只不过会发生两种溢出：正溢出和负溢出。 正溢出就是原来的符号位为0，但是由于相加的数字过大，导致了符号位变成了1，结果变成了负数； 负溢出就是原来符号位为1，但是由于相加的数字过大导致进位，和符号位相加后为0，原本的负数变为了正数。 浮点数的表示一般表示浮点数表示的公式为： 十进制 二进制 5+4/3 101.11 2+7/8 10.111 1+7/16 1.0111 我们发现，这种表示方法有限制：只有形如 $\frac { x }{ { 2 }^{ i } } $ 的小数部分可以精确表示。 IEEE 表示在 IEEE 的标准中，使用以下公式来表示浮点数：$$V={ \left( -1 \right) }^{ s }\times M\times { 2 }^{ E }$$其中，s 表示符号位，M 通常表示一个1.0~2.0的小数，E表示2的次方数。 具体编码形式如下： 示例在这个示例中我们采用 1 位符号位，4 位 exp，3 位 frac，对应的 bias 就是 2^(4-1)-1=7， 对于规范化数：e = Exp - bias; 对于非规范化数：e = 1 - bias; s exp frac e 值 备注 0 0000 000 -6 0 非规范化数值 0 0000 001 -6 (1/64)*(1/8)=1/512 非规范化数值 0 0000 010 -6 (1/64)*(2/8)=2/512 非规范化数值 0 0000 011 -6 (1/64)*(3/8)=3/512 非规范化数值 …… …… …… …… …… …… 0 0000 111 -6 (1/64)*(7/8)=7/512 能表示的最大非规范化数值 0 0001 000 -6 (1/64)*(8/8)=1/64 能表示的最小规范化数值 0 0001 001 -6 (1/64)*(9/8)=9/512 规范化数值 …… …… …… …… …… …… 0 0110 110 -1 (1/2)*(14/8)=7/8 规范化数值 0 0110 111 -1 (1/2)(15/8)=15/16 最接近1的值 0 0111 000 0 1*8/8=1 1 0 0111 001 0 1*9/8=9/8 大于1最接近1的值 …… …… …… …… …… …… 0 1110 111 7 128*15/8=240 能表示的最大的规范化数值 0 1111 000 - 正无穷 正无穷 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>读书笔记</tag>
        <tag>CSAPP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[变位词程序的实现]]></title>
    <url>%2F2016%2F12%2F15%2Fprogramming-pearls-thick-02%2F</url>
    <content type="text"><![CDATA[这篇文章是 读厚《编程珠玑》系列博客 的第 2 篇，主要的内容是《编程珠玑》第二章最后提出的变位词程序的实现。 问题简述问题来源于《编程珠玑》第二章中最后提出的变位词程序的实现。其中的变位词的概念，在第二章开篇的 C 问题中得到了阐释。 C. 给定一个英语词典，找出其中所有变位词的集合。例如，『pots』，『stop』，『tops』互为变位词，因为每一个单词都可以通过改变其他单词中字母的顺序来得到。 我们所实现的变位词程序需要做的就是：将字典读入，然后找出所有的变位词集合。 实现思路本文中的思路就按照文章中介绍的进行实现： 将程序分为三个部分： sign：读入字典，对单词进行『sign』（计算标识符）。计算标识符的过程就是对单词中的字母进行排序。例如：上述三个单词『pots』，『stop』，『tops』的标识符是相同的，都是『opst』 sort：将所有具有相同标识符的单词放到一起（这里我们直接使用系统的 sort 程序） squash：将具有相同标识符的单词放到一行打印出来 最后，通过管道将三个程序连接起来： 1sign &lt; words.txt | sort | squash &gt; gramlist.txt 最终gramlist.txt中就是我们需要的结果。 代码实现sign 程序1234567891011121314151617181920212223242526//// sign.c// somecode//// Created by 罗远航 on 16/12/2016.// Copyright © 2016 罗远航. All rights reserved.//#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#define WORDMAX 100int charcomp(const void *x, const void *y)&#123; return *(char *)x - *(char *)y;&#125;int main()&#123; char word[WORDMAX], sig[WORDMAX]; while(scanf("%s",word) != EOF)&#123; strcpy(sig, word); qsort(sig, strlen(sig), sizeof(char), charcomp); printf("%s %s\n",sig, word); &#125;&#125; squash 程序1234567891011121314151617181920212223242526272829//// squash.c// somecode//// Created by 罗远航 on 16/12/2016.// Copyright © 2016 罗远航. All rights reserved.//#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#define WORDMAX 100int main()&#123; char word[WORDMAX], sig[WORDMAX], oldsig[WORDMAX]; int linenum = 0; strcpy(oldsig, ""); while (scanf("%s %s", sig, word) != EOF) &#123; if (strcmp(oldsig, sig) != 0 &amp;&amp; linenum &gt; 0) printf("\n"); strcpy(oldsig, sig); linenum++; printf("%s ", word); &#125; printf("\n"); return 0;&#125; 运行结果运行程序之后，我找到了几个比较长的变位词： 1234algorithm&apos;s logarithm&apos;sanatomicopathological pathologicoanatomicalparadisaically paradisiacally…… 注：单词表我是在这里下载到的，大概有35万英文单词。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【读薄《编程珠玑》】贰 啊哈！算法]]></title>
    <url>%2F2016%2F12%2F11%2Fprogramming-pearls-thin-2%2F</url>
    <content type="text"><![CDATA[这篇文章是[《读薄&lt;编程珠玑&gt;》系列博客][1]的第 贰 篇，在这篇文章中，作者提出了三个问题，并且给出了相应的解决方案，本文阐述了这三个问题以及解决方案，并且对课后习题进行了分析。 问题集合 0x00: 给定一个最多包含40亿个随机排列的32位整数的顺序文件，找出一个不在文件中的32位整数（在文件中至少缺失一个这样的数）。在具有足够内存的情况下，如何解决该问题？如果有几个外部的『临时』文件可用，但是仅有几百字节的内存，又该如何解决该问题？ 0x01: 将一个 n 元一维向量向左旋转 i 个位置。例如，当 n=8, i=3 时，向量 abcdefg 旋转为 defgabc。简单的代码使用一个 n 元的中间向量在 n 步内完成该工作。你能否仅适用数十个额外字节的存储空间，在正比于 n 的时间内完成向量的旋转？ 0x02: 给定一个英语字典，找出其中的所有变位词的集合。例如，『pots』、『stop』、『tops』互为变位词，因为每个单词都能通过改变其他单词中的字母顺序来获得。 0x03：考虑查找给定输入单词的所有变位词问题。仅给定单词和词典的情况下，如何解决该问题？如果有一些时间和空间可以在响应任何查询之前预先处理字典，又会如何？ 0x04：给定包含 4,300,000,000 个 32 位证书的顺序文件，如何找出一个至少出现两次的整数？ 0x05：前面涉及了两个需要经敲代码来实现的向量旋转算法。将其分别作为独立的程序实现。在每个程序中，i 和 n 的最大公约数如何出现？ 0x06：几位读者指出，既然所有的三个旋转算法需要执行的运行时间都正比于 n，杂技算法的运行速度显然是求逆算法的两倍。杂技算法对数组中的每个元素仅存储和读取一次，而求逆算法需要两次。在实际的计算机上实验以比较两者的速度差异，特别注意内存引用位置附近的问题。 0x07：向量旋转算法将向量 ab 变为 ba。如何将向量 abc 变为 cba？（这对交换非相邻内存块的问题进行了建模） 0x08：20世纪70年代末期，贝尔实验室开发出了『用户操作的电话号码簿辅助程序』，该程序允许雇员使用标准的按键电话在公司电话号码簿中查找号码。 要查找该系统设计者的名字 Mike Lesk，可以按『LESK*M*』(也就是『5375*6*』)，随后，系统会输出他的电话号码。这样的服务现在随处可见。该系统中出现的一个问题是，不同的名字有可能具有相同的按键编码。在 Lesk 的系统中发生这种情况时，系统会询问用户更多的信息。给定一个大的名字文件时（例如标准的大城市电话号码簿），如何定位这些『错误匹配』呢？（当 LESK 在这种规模的电话号码簿上做实验时，他发现错误匹配的概率仅仅是0.2%）如何实现一个以名字的按键编码为参数，并返回所有可能的匹配名字的函数？ 0x09：在20世纪60年代早期，Vic Vyssotsky 与一个程序员一起工作，该程序员需要转置一个存储在磁带上的4000*4000的矩阵（每条记录的格式相同，为数十个字节）。他的同事最初提出的程序需要运行50个小时。Vyssotsky 如何将运行时间减少到半小时呢？ 0x10：给定一个 n 元实数集合、一个实数 t 和一个整数 k，如何快速确定是否存在一个 k 元子集，其元素之和不超过 k ？ 0x11：顺序搜索和二分搜索代表了搜索时间和预处理时间之间的折中。处理一个 n 元表格时，需要执行多少次二分搜索才能弥补对表进行排序所消耗的预处理时间？ 方案集合0x00该问题的解思想在于：二分法。 首先，将40亿个数字遍历一遍，分为 2 组，第一位为 1 的一组，为 0 的一组（假设只缺少一个数字），则数量少的一组必定有缺少的数，然后对该组再次进行分组，如此进行下去直到找到该缺少的数字。 如果有足够的空间使用第一章中介绍的位向量也是可以的。 0x01解法1： 思想在于向量中的元素移动后的最终位置其实是确定的，我们需要的是一个临时变量，存放着该元素移动后的位置，然后把对应的元素放到相应位置即可 解法2： 思想在于旋转向量的问题其实就是将该向量分为了两部分 ab，然后变成 ba 的过程。其中 a 为向量的前 i 个元素，将 ab 变为 ba 过程是这样的：首先对 a 求逆得到 a’，然后对 b 求逆得到 b’，最后对 (a’b’) 求逆，所得到的结果就是 ba，过程如下： 123reverse(0, i-1); /* cbadefgh */reverse(i, n-1); /* cbahgfed */reverse(0, n-1); /* defghabc */ 0x02对于该问题，我们可以标识字典中的每一个词，使用基于排序的标识，按照字母表的顺序来对出现的字母进行排序，例如，”deposit” 的标识为 “deiopst”。改进后的标识，我们可以使用类似 “e1h1l1o2” 来标识 “hello”。 0x03如果仅给单词和词典，我们需要对字典中的单词进行依次算标识，然后进行比较； 如果有一些时间和空间可以预先处理字典，我们可以先计算出每个单词的标识然后建立(标识, 单词)对然后方便查找（或者直接排序） 0x04思路同 0x00，先扫描一遍，把第一位是 「0」和「1」的数字放到两个文件中，数量多的一个对第二位数字再分组，以此类推，最后一定能找出一个数字。 0x05第一个算法的实现（杂耍算法） 1234567891011121314151617181920/* 求最大公约数 */int gcd(int a, int b)&#123; return b==0?a:gcd(b, a%b);&#125;/* 第一个算法 */int a1(int *start, int *end, int i)&#123; int len = end - start; int g = gcd(len, i); for(int index = 0; index &lt; g; index++)&#123; int t = *(start+index); int next = index; while((next+i)%len != index)&#123; *(start+next) = *(start+(next+i)%len); next = (next+i)%len; &#125; *(start+next) = t; &#125; return 0;&#125; 第二个算法的实现（交换算法） 12345678910111213141516171819202122232425262728/* 第二个算法 */void rangeswap( int *a, int i, int j, int m)&#123; //交换 a[i...i+m] 和 a[j...j+m] for(int index = 0; index &lt; m; index++)&#123; int temp = a[i + index]; a[i + index] = a[j + index]; a[j + index] = temp; &#125;&#125;void a2( int *a, int shift )&#123; if(shift == 0 || shift == num) return; int n = shift; int j = num - shift; int i = shift; while(i != j )&#123; if(i &gt; j)&#123; rangeswap(a, n-i, n, j); i -= j; &#125; else&#123; rangeswap(a, n-i, n+j-i, i); j -= i; &#125; &#125; rangeswap(a, n-i, n, i);&#125; 第三个算法的实现（求逆算法） 12345678910111213141516/* 第三个算法 */void reverse(int m, int n)&#123; int mid = (m+n)/2; int temp; for(int i = m, j=n; i &lt;= mid; i++, j--)&#123; temp = a[i]; a[i] = a[j]; a[j] = temp; &#125;&#125;void a3(int* a, int i)&#123; reverse(0, i-1); reverse(i, num-1); reverse(0, num-1);&#125; 0x06把上述三种算法分别运行，向量长度为1,000,000，旋转长度为 1 - 50，作图如下：（横坐标为旋转长度，纵坐标为运行时间，单位为毫秒） 测试代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354int main(int argc, const char * argv[]) &#123; ofstream oFile; oFile.open("/Users/jason/data.csv", ios::out | ios::trunc); for(int i = 1; i &lt;= 50; i++)&#123; oFile &lt;&lt; i &lt;&lt; ','; &#125; oFile &lt;&lt; endl; /*算法一运行时间统计（向量长度1000000，旋转距离1-50）*/ for(int i = 1; i &lt;=50; i++)&#123; init(); clock_t start, finish; double totaltime; start = clock(); a1(a, a+num, i); finish = clock(); totaltime = (double)(finish-start)/CLOCKS_PER_SEC; oFile &lt;&lt; totaltime*1000 &lt;&lt; ','; &#125; oFile &lt;&lt; endl; /*算法二运行时间统计（向量长度1000000，旋转距离1-50）*/ for(int i = 1; i &lt;= 50; i++)&#123; init(); clock_t start, finish; double totaltime; start = clock(); a2(a, i); finish = clock(); totaltime = (double)(finish-start)/CLOCKS_PER_SEC; oFile &lt;&lt; totaltime*1000 &lt;&lt; ','; &#125; oFile &lt;&lt; endl; /*算法三运行时间统计（向量长度1000000，旋转距离1-50）*/ for(int i = 1; i &lt;= 50; i++)&#123; init(); clock_t start, finish; double totaltime; start = clock(); a3(a, i); finish = clock(); totaltime = (double)(finish-start)/CLOCKS_PER_SEC; oFile &lt;&lt; totaltime*1000 &lt;&lt; ','; &#125; oFile &lt;&lt; endl; oFile.close(); return 0;&#125; 0x07分别对 a, b, c 求逆，得到 a’, b’, c’，再对 (a’b’c’) 求逆，得到 cba 0x08首先计算出所有名字的标识，例（『LESK*M*』的标识是『5375*6*』），然后对所有标识进行排序，查找时使用二分搜索2（答案中说实际中往往使用散列表或数据库系统） 0x09（作者给的答案） 为了转置矩阵，Vyssotsky 为每条记录插入列号和行号，然后调用系统的磁带排序程序先按列排序，再按行排序，最后使用另一个程序删除列号和行号 0x10我能想到的方法是：对这个集合进行排序，然后算出前 k 位的和与 t 进行比较 0x11TODO 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读薄《Linux 内核设计与实现》(6) - 虚拟文件系统]]></title>
    <url>%2F2016%2F11%2F07%2Flkd-thin-06%2F</url>
    <content type="text"><![CDATA[这篇文章是《读薄「Linux 内核设计与实现」》系列文章的第 VI 篇，本文主要讲了以下问题：Linux 虚拟文件系统的概念、相关接口等内容。 0x00 虚拟文件系统概念 虚拟文件系统（VFS）为用户空间提供了文件系统接口 VFS 协同不同文件系统的工作 0x01 通用文件接口 VFS 使得用户可以直接使用 open(), read(), write()这样的系统调用而无需考虑具体文件系统和实际物理介质 0x02 文件系统的抽象层 VFS 提供了一个通用的文件系统模型，该模型囊括了任何文件系统的常用功能集合和行为 它定义了所有文件系统都支持的、基本的、概念上的接口和数据结构 对一个具体实现的文件系统，在处理时需要概念上的转换，例如将目录看为文件 0x03 VFS 中的对象I 超级块对象它代表一个具体的已安装文件系统，各种文件系统都必须实现超级块对象，用于存放特定文件系统的信息 它由super_block结构体表示，定义于&lt;linux/fs.h&gt;中 II 索引节点对象它代表一个具体文件，包含了内核在操作文件或目录时需要的全部信息，索引节点对象由 inode 结构体表示，她定义在 &lt;linux/fs.h&gt; 中 III 目录项对象VFS 把目录项当做文件对待，为了方便查找操作，引入目录项概念，每个 dentry 代表路径中的一个特定部分，目录项由 dentry 结构体表示，定义在文件 &lt;linux/dcache.h&gt; 中 目录项对象有 3 种状态： 被使用：该目录项对用一个有效的索引节点（d_inode 所指的），且存在一个或多个使用者 未被使用：该目录项对应一个有效的索引节点，但 VFS 当前未使用它（d_count = 0） 负状态：该目录项没有对应的有效索引节点（d_inode 为 NULL） 目录项缓存主要包括 3 个部分： 『被使用的』目录项链表：一个给定的索引节点可能有多个链接，可能有多个目录项对象，用链表连接 『最近被使用的目录项的』双向链表：该链表含有被使用的和负状态的目录项对象 散列表和散列函数用来快速地将给定路径解析为相关目录项对象 IV 文件对象文件对象表示进程已打开的文件，是已打开的文件在内存中的表示，由 file 结构体表示，定义在文件 &lt;linux/fs.h&gt;中。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读薄《Linux 内核设计与实现》(5) - 定时器、时间管理和内存管理]]></title>
    <url>%2F2016%2F10%2F23%2Flkd-thin-05%2F</url>
    <content type="text"><![CDATA[这篇文章是《读薄「Linux 内核设计与实现」》系列文章的第 V 篇，本文主要讲了以下问题：Linux 内核中的时间概念和时间表示，硬件时钟和定时器以及时间中断和内存管理的相关知识。 0x00 内核中的时间概念 内核需要管理相对时间和绝对时间 硬件为内核提供了一个系统定时器用以计算流逝的时间，它以某种频率自行触发时间中断，该频率可以通过编程预定，称作节拍率 时间的作用： 更新系统时间 更新实际时间 定期均衡运行队列（SMP） 时间片 定期统计处理器时间 0x01 Linux 中的时间表示I 节拍率（Hz）在 &lt;asm/param.h&gt; 中定义，不同体系结构不同。 理想的Hz 值应该是多少？ 高 Hz 的优势： 提高定时器频度和精度 依赖定时值值省得系统调用能够以更高精度运行 提高进程抢占的精准度 高 Hz 的劣势： 提高时钟中断频率，加重系统负担 提高中断处理程序占CPU时间 更频繁的打乱处理器高速缓存并增加能耗 II jiffies全局变量 jiffies 用来记录自系统启动以来产生的节拍的总数，定义于 &lt;linux/jiffies.h&gt; 中 extern unsigned long volatile jiffies; jiffies 的回绕问题 jiffies 的值超过它的最大存放范围后就会发生溢出，溢出后它的值会回绕到0 解决方案 宏 time_after(unknown, known): 当时间 unknown 超过指定的 known 时，返回真，否则返回假； 宏 time_before(unknown, known): 当时间 unknown 没超过指定的 known 时，返回真，否则返回假； unknown 通常是 jiffies，unknown是需要对比的值； 宏 time_before_eq 和 time_after_eq:当 unknown 和 known 相等时，返回真 1234567unsigned long timeout = jiffies + HZ / 2; /*0.5秒后超时*/if(time_before(jiffies, timeout))&#123; /*没有超时,很好*/&#125;else&#123; /*超时，发生错误*/&#125; 0x02 硬件时钟和定时器体系结构中提供了两种设备进行计时： 系统定时器：提供了一种周期性触发中断机制 实时时钟：用来持久存放系统时间的设备 0x03 Linux 下的时钟中断I 时钟中断处理程序做的工作 获得 xtime_lock 锁，对 jiffies_64 和 xtime 进行保护 应答或重新设置系统时钟 周期性使用墙上时间更新实时时钟 调用体系结构无关的时钟例程：do_timer() ​ II do_timer() jiffies + 1 更新资源消耗的统计值 执行到期的动态定时器 执行 scheduler_tick() 更新墙上时间并存到 xtime 变量中 计算平均负载值 III 从用户空间获取时间gettimeofday(): 对应系统调用 sys_gettimeofday() 0x04 Linux 内存页I 内核分配内存特点 内核使用的内存空间有限 内核不支持便捷的内存分配方式 处理内存分配错误难度大 内核分配机制不能太复杂 II 页 内核以物理页为单位分配内存 物理页的大小取决于体系结构 page 结构体（定义于 &lt;linux/mm_types.h&gt;） 12345678910struct page&#123; unsigned long flags; //存放页的状态 atomic_t _count; //存放页的引用计数 atomic_t _mapcount; unsigned long private; struct address_space *mapping; pgoff_t index; struct list_head lru; void *virtual; //页的虚拟地址&#125; 0x05 Linux 内存区由于硬件的限制，内核并不能对所有的页一样看待，内核需要对页进行分类，分不同区域 Linux 必需处理 2 种由于硬件存在缺陷而引起的内存寻址问题： 一些硬件只能用某些特定的内存地址来执行DMA（Direct Memory Access） 一些体系结构的内存的物理寻址范围比虚拟内存大得多，导致一些内存不能总是映射到内核空间 Linux 主要使用了 4 种区： ZONE_DMA： 该区页面用来执行 DMA ZONE_DMA32： 用于 32 位设备执行 DMA ZONE_NORMAL：该区页面都能正常映射 ZONE_HIGHEM：该区包含“高端内存”，这里的页不能永久映射到内核空间 0x06 内存管理提供的服务I 获得页 alloc_pages() page_address(struct page* page) __get_free_pages() alloc_page() __get_free_page() II 获得填充为 0 的页 get_zeroed_page() III 释放页 __free_pages() free_pages() free_page() IV kmalloc()用于获得以字节为单位的一块连续内存空间： 1void *kmalloc (size_t size, gfp_t flags) V kfree()该函数用于释放 kmalloc() 分配出的内存块： 1void kfree(const void *ptr) VI vmalloc()类似 kmalloc(), 但分配的内存空间不连续，释放使用 vfree() VII slab 层即 slab 分配器，它扮演了通用数据结构缓存层的角色，是一种缓存机制 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读薄《Linux 内核设计与实现》(4) - 中断与同步]]></title>
    <url>%2F2016%2F06%2F30%2Flkd-thin-04%2F</url>
    <content type="text"><![CDATA[这篇文章是《读薄「Linux 内核设计与实现」》系列文章的第 IV 篇，本文主要讲了以下问题：中断和中断处理程序的概念与实现原理、Linux 中的下半部以及内核同步方法。 0x00 中断和中断处理程序I 中断 中断是一种特殊的电信号，由硬件发向处理器，处理器接收到中断时，会马上箱操作系统反映，由操作系统进行处理。中断随时可以产生，因此，内核随时可能因为新到来的中断而被打断。 不同的设备对应的中断不同，每个中断通过一个唯一的数字标识，这些中断值通常被称为中断请求（IRQ）线。 II 中断处理程序 中断处理程序又成为中断处理例程（ISR），是内核在响应中断时执行的一个函数 一个中断处理程序对应一个中断，一个设备可能发出多种中断 对于外部设备，中断处理程序是设备驱动程序的一部分 在 Linux 中，中断处理程序和 C 函数区别不大，但有自己的规范，主要是运行时需要在中断上下文中 0x01 中断处理机制I 注册中断处理程序驱动程序可以通过request_irq()函数注册一个中断处理程序(linux/interrupt.h) 12345int request_irq(unsigned int irq, irqhandler_t handler, unsigined long falgs, const char *name, void *dev) irq:表示要分配的中断号 handler:一个指针，指向处理这个中断的实际中断处理函数 1typedef irqhandler_t(*irq_handler_t)(int, void*); II 释放中断处理程序卸载驱动程序时，需要注销响应中断处理程序，并释放中断线。 1void free_irq(unsigned int irq, void *dev); 如果指定的中断线不是共享的，那么该函数删除处理程序的同时将禁用这条中断线；中断线是共享的，则仅仅删除 dev 对应的处理程序，而这条中断线本身只有在删除了最后一个处理程序时才会被禁用 III 中断的禁止与激活12local_irq_disable();local_irq_enable(); IV 上半部与下半部又想中断处理程序运行的快，又想中断处理程序完成的工作多，这两个目的显然有所抵触，所以把中断处理分为两个部分： 中断处理程序是上半部，接收到一个中断，它就立刻开始执行，但只做有严格时限的工作，例如一些只有在中断被禁止的状态下才能完成的工作 能够被允许稍后完成的工作会推迟2到下半部去，此后，在合适的时机，下半部会被开中断执行 Q1：为什么要分上半部和下半部？ 中断程序以异步方式执行，可能打断重要操作的执行，越快越好 中断处理程序会屏蔽其他同级中断，所以执行越快越好 中断处理程序往往需要对硬件操作，通常有很高的时限要求 中断处理程序不在进程的上下文中运行，所以不能阻塞 Q2：上半部和下半部如何分开？ 如果一个任务对时间非常敏感，将其放到上半部； 如果一个任务和硬件相关，将其放到上半部； 如果一个任务要保证不被其它中断打断，将其放到上半部； 其他的所有任务考虑放到下半部 0x02 下半部下半部的任务就是执行与终端处理密切相关但中断处理程序本身不执行的工作。我们期望中断处理程序将尽量多的工作放到下半部执行，以快速从中断返回。 I 下半部实现机制a.软中断此处的软中断和系统调用使用的 int 80H 不同，是操作系统支持的一种，在编译期间静态分配 软中断的实现 定义于 linux/interrupt.h 中： 1234struct softirq_action&#123; void (*action)(struct sfotirq_action*); //待执行的函数 void *data; //传递的参数&#125; 最多可能32个软中断，定义于 kernel/softirq.c 1static struct softirq_action softirq_vec[NR_SOFTIRQS]; 软中断处理程序1void softirq_handler(struct softirq_action*); //传递整个结构体 执行软中断一个注册的软中断必须在被标记后才会执行下列地方，待处理的软中断会被检查和执行： 在 ksoftirqd 内核线程中 在那些显式检查和和执行待处理的软中断的代码中（如网络子系统） 不管执行的时机，软中断都要在do_softirq 中执行 使用软中断 分配索引： 通过 linux/interrupt.h 中的一个枚举类型中声明一个新的软中断 注册处理程序：在运行时通过调用open_softirq()注册软中断处理程序，有两个参数，软中断和处理函数 触发软中断：raise_softirq()函数可以将一个软中断设置为挂起状态，让它在下次调用do_softirq()函数时投入运行 b.tasklet基于软中断的实现，但它的接口更简单，锁保护要求更低 tasklet 的实现 tasklet 结构体（linux/interrupt.h） 1234567struct tasklet_struct&#123; struct tasklet_struct *next; //链表 unsigned long state; //tasklet 状态 atomic_t count; //引用计数器 void (*funx)(unsigned long); //taklet 处理函数 unsigned long data; //给处理器函数传递的参数&#125; 调度 tasklet被触发的软中断存放在2个数据结构：tasklet_vec,task_hi_vec,这两个数据结构都是由task_struct构成的链表，由tasklet_schedule()和task_hi_schedule()进行调度，调度步骤如下： （1）检查 tasklet 状态，如果为TASK_STATE_SCHED则返回（2）调用_tasklet_schedule()（3）保存中断状态，禁止本地中断（4）把需要调度的 tasklet 加到 tasklet_vec或tasklet_hi_vec链表头（5）唤起TASKLET_SOFTIRQ或HI_SOFTIRQ软中断，下一次调用do_softirq()时会执行该 tasklet（6）恢复中断 软中断处理程序：tasklet_action()或task_hi_action()[tasklet 处理的核心]： （1）禁止中断 （2）将当前处理器上的该链表头设为 NULL （3）允许中断 （4）循环遍历链表上所有待处理的 tasklet （5）如果是多个处理器，检查TASKLET_STATE_RUN判断这个 tasklet 是否在其他处理器上运行，如果是，跳到笑一个 tasklet （6）如果否，设置TASKLET_STATE_RUN （7）检查 count 是否为0，确保 tasklet 没有被禁止；如果被禁止，跳到下一个 tasklet （8）执行 tasklet 处理程序 （9）执行完毕，清除TASKLET_STATE_RUN （10）重复执行下一个 tasklet 使用 tasklet声明自己的 tasklet： 静态：linux/interrupt.h 中的2个宏： 12DECLARE_TASKLET(name,func,data);DECLARE_TASKLET_DIASBLED(name,func,data); 动态：通过一个指针赋给一个动态创建的 tasklet_struct: 1tasklet_init(t, takslet_handler, dev); #####编写自己的 tasklet 处理程序 1void tasklet_handler(unsigned long data) 注意：不能再 tasklet 中使用信号量或者其他阻塞式函数 #####调度自己的 tasklet 123tasklet_schedule(&amp;my_tasklet);tasklet_enable(&amp;my_tasklet);tasklet_disable(&amp;my_tasklet); #####ksoftirqd ksoftirqd 是内核线程，每个处理器都有一个，用于在空闲处理器处理软中断 1234567891011for(;;)&#123; if(!softirq_pending(cpu)) schedule(); set_current_state(TASK_RUNNING); while(softirq_pending(cpu))&#123; do_softirq(); if(need_resched()) schedule(); &#125; set_current_sdtate(TASK_INTERRUPTIBLE);&#125; 只要有待处理的软中断，该线程就会处理 c.工作队列工作队列机制将下半部功能交给内核县城去执行，有线程上下文，可以睡眠 工作队列的实现 提供创建工作者线程的接口 提供默认的工作者线程处理排到队列里的下半部工作 提供吧需要推后执行的任务排到队列里的接口 处理机制 线程将自己休眠，并加到等待队列（TASK_INTERRUPTIBLE） 如果工作链表为空，线程调用schedule()，休眠 如果不为空，将自己设为TASK_RUNNING 调用run_workqueue()执行被推后的工作 该函数循环遍历链表上每个待处理的工作： 当链表非空，选取下一个节点对象 获取要执行的函数和参数 从链表上解下该节点，将 pending 位清零 调用函数 重复执行 工作队列的使用 创建推后的工作： 静态： 1DECLARE_WORK(name, void(*func)(void*), void *data); 动态： 1INIT_WORK(struct work_struct *work, void(*func)(void*), void *data); 工作队列处理函数 1void work_handler(void *data) 对工作的调度 12schedule_work(&amp;work);schedule_delayed_work(&amp;work, delay); 刷新操作 1void flush_scheduled_work(void); 3种下半部机制的比较 机制 上下文 顺序执行保障 软中断 中断 没有 tasklet 中断 同类型不能同时执行 工作队列 进程 没有（和进程上下文一样被调度） Q：我们要选择哪种机制？ 如果有休眠的要求，选择工作队列；否则，最好使用 tasklet；要是必须专注性能的提高，选择软中断 II 在下半部之间加锁 如果进程上下文和一个下半部共享数据，在访问这些数据之前，你需要禁止下半部的处理并得到锁的使用权 如果中断上下文和一个下半部共享数据，在访问数据之前，需要禁止中断并得到锁的使用权 0x03 内核同步I 临界区临界区就是访问和操作共享资源的代码段，必须保证原子地执行才能保证安全 II 加锁保证在临界区执行的县城只有一个 III 造成并发的原因 中断 软中断和 tasklet 内核抢占 睡眠及用户空间的同步 对称多处理 IV 死锁产生条件 要有一个或多个执行线程和一个或多个资源 每一个线程都在等待其中一个资源 所有的资源都被占用 所有县城都在互相等待，但他们永远不会释放已经占有的资源 V 内核同步方法原子操作 原子整数操作（asm/atomic.h） 1atomic_dec_and_test(atmoic_t, *v) 原子位操作（asm/bitops.h） 1set_bit(0, &amp;word) 自旋锁 自旋锁只能被一个可执行进程持有 若争用一个被占用的锁则进程忙等（旋转） 自旋锁不能长期被占用，否则效率低 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读薄《Linux 内核设计与实现》(3) - 系统调用]]></title>
    <url>%2F2016%2F06%2F25%2Flkd-thin-03%2F</url>
    <content type="text"><![CDATA[这篇文章是《读薄「Linux 内核设计与实现」》系列文章的第 III 篇，本文主要讲了以下问题：系统调用的概念、系统调用的实现原理与过程以及如何在 Linux 中增加一个系统调用。 0x00 系统调用的概念系统调用是为了和用户空间上的进程进行交互，内核提供的一组界面。 应用程序通过这组界面访问硬件和其他操作系统资源 完成对硬件和资源的访问控制 硬件设备的抽象（提供设备的独立性） 0x01 系统调用简介I 常用系统调用 fork(), exec(), open(), read(), write(), close(),…… 目前 Linux 系统调用 300 多个 II 应用程序及系统调用的层次关系应用程序通过在用户空间实现的 API 而不是直接通过系统调用来编程 例：调用 printf() 函数时，应用程序、C 库和内核的关系：应用程序调用 printf() -&gt; C 库中的 printf() -&gt; C 库中的 write() -&gt; 内核中的 write() 系统调用 0x02 Linux 系统调用实现原理I 相关概念 int 80H：软中断，通知内核的机制是靠软中断实现的，第128号中断处理程序 IVT（Interrupt Vector Table）：中断向量表，包括所有中断程序入口地址，它固定存放于内存中（实模式下应用） IDT（Interrupt Descriptor Table）：中断描述符表，不固定内存位置，通过 IDTR 寄存器定位该表（保护模式下应用，int 80H 占据其中一项） syscall table：系统调用表 系统调用号： 在 Linux 中，每个系统调用被赋予一个系统调用号，表示它在表中的编号 II 系统调用的加载操作系统在加载时做的有关系统调用的加载： int 80H 处理程序地址的加载：start_kernel()中的 trap_init()和 set_system_gate() 各系统调用处理程序的加载（entry.s） III 系统调用过程(以 x86 为例)首先，通过软中断陷入到 int 80h 中断中，促使系统切换到内核态去执行异常处理程序（系统调用处理程序）；之后，系统通过读取 eax 寄存器的值来获取系统调用号；之后，系统通过读取寄存器来获取传递的参数（ebx, ecx, edx, esi, edi）按照顺序存放前五个参数，如果参数为6个或以上，则将其中一个寄存器的值指向内存空间；最后，执行相应系统调用代码，完成系统调用 IV 系统调用的参数验证系统调用必须仔细检查他们所有参数是否合法有效，如果用户将不合法的参数传递给内核，那么系统的安全和稳定将面临极大考验。 权限验证：系统调用的调用者可以使用 capable() 函数来检查是否有权能对制定的资源进行操作 指针合法性验证：在接受一个用户空间的指针之前，内核需要验证： 指针指向的内存区域属于用户空间 指针指向的内存区域在进程的地址空间里 如果是读，该内存应被标记为可读；如果是写，该内存应被标记为可写；如果是可执行，进程决不能绕过内存访问限制 0x03 如何增加一个系统调用 增加系统调用函数（/kernel/sys.c） 把系统调用函数入口添加到 sys_call_table(entry.s) 添加系统调用号 0x04 系统调用的意义 它为用户提供了一种硬件的抽象接口 在保证系统稳定和安全的前提下提供服务，避免应用程序恣意横行 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读薄「Linux 内核设计与实现」(2) - 进程管理和调度]]></title>
    <url>%2F2016%2F06%2F23%2Flkd-thin-02%2F</url>
    <content type="text"><![CDATA[这篇文章是《读薄「Linux 内核设计与实现」》系列文章的第 II 篇，本文主要讲了以下问题：进程管理的任务、进程管理与其他模块的依赖关系、进程描述符和任务队列、进程的创建、线程的实现、进程的终止、进程调度。 #0x00 进程管理的任务 进程能创建新的进程（通过复制现有进程） 确定哪个进程能拥有 CPU 接受中断并将中断导向相应的内核子系统 管理时钟硬件 当一个进程结束时释放其资源 动态装载执行模块 #0x01 进程管理与其他模块的依赖关系 I 进程模块的内外界面 对用户进程提供了一组简单的系统调用接口 对内核的其他模块提供了丰富的接口功能 II 进程模块与其他模块的依赖关系 内存管理模块：当一个进程被调度时，为它建立内存映射 IPC 模块：bottom-half 处理使用了其中的信号量队列 文件系统模块：在装载 module 时为进程调度提供实际设备的访问途径 所有其他模块都依赖于进程调度模块，因为当要进行硬件访问时，它们需要 CPU 挂起用户进程，切换到系统态进行处理 #0x02 进程描述符和任务队列 I 进程描述符 task_struct （进程描述符）定义于&lt;linux/sched.h&gt;，其中包含：它打开的文件、进程的地址空间、挂起的信号、进程的状态…… 任务队列(task_list)是一个双向循环链表，每一项都是 task_struct II 分配进程描述符 Linux 通过 slab 分配 task_struct 可以达到对象复用和缓存着色的目的，不需要频繁调用内存管理相应功能，相当于一种高级缓存 III 进程描述符的存放 通过 PID 标识进程，最大值默认为32768 如何获得当前运行的进程？ 通过 current 宏（体系结构相关），current_thread_info()-&gt;task; #0x03 进程的创建 I 进程创建过程描述 Linux 中，进程的创建是通过拷贝已存在的进程来实现的 内核启动的时候，start_kernel() 初始化各系统数据结构，同时生成了与系统共存亡的后台进程：init 这些子进程通过 fork() 系统调用生成他们的子进程 进程的终止是通过系统调用 _exit() 实现的 II 进程创建函数 fork(): 进程复制自身产生子进程 exec(): 加载可执行代码模块覆盖自身代码 III 写时拷贝(copy-on-write)使地址空间上的页的拷贝被推迟到实际发生写入的时候才进行 #0x04 线程的实现 Linux 没有真正的线程，线程当做进程来实现（仅仅是进程间资源直接共享的一种机制） 通过 clone 时传递一些参数标志来实现： 1clone(CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND, 0); 这些标志定义于 &lt;linux/sched.h&gt; 内核线程：独立运行在内核的标准进程 #0x05 进程的终止 删除进程描述符 父进程得知进程终止的消息后才能删除子进程的描述符 父进程 WAIT() （通过系统调用 wait4()实现），挂起父进程，直到其中一个子进程退出 之后，真正释放描述符（release_task()）: 调用 _unhash_process()从 pidhash 上删除该进程 _exit_signal() 释放目前僵死进程所使用剩余资源 调用 put_task_struct 释放描述符（内核栈、thread_info 所占的页、slab 高速缓存） 若父进程异常终止，将发生什么情况？ 如果父进程在子进程之前推出，这些成为孤儿的进程会处于僵死状态，解决方案是给子线程在当前进程中找一个父亲，如果不行，则以 init 进程为父亲，过程： do_exit() -&gt; exit_notify() -&gt; forget_original_parent() -&gt; find_new_reaper() 开始寻父。 #0x06 进程调度 I 多任务系统分类 抢占式：由调度程序决定一个进程的运行与挂起，挂起的动作就叫做抢占（Linux 为抢占式内核），进程在被抢占之前的运行时间是预先设置好的，叫做时间片 非抢占式：除非进程自己停止，否则它会一直运行，它主动挂起自己的动作叫让步（yielding） II 调度策略I/O 消耗型和 CPU 消耗型进程 I/O 消耗型：进程大部分时间用来提交 I/O 请求或是等待 I/O 请求 CPU 消耗型：进程把时间大多用在执行代码上 UNIX 系列倾向于 I/O 消耗型 进程优先级(Linux 采用2种不同的优先级范围) nice 值：从 -20~+19，默认为0，nice 越大，优先级越低 实时优先级：从 0~99，越高的实时优先级越高，它的值可以配置 时间片 时间片分配多大？：时间片过长使得系统交互性不好；时间片过短会导致大部分 CPU 时间浪费在进程的切换上。 Linux 采用可变长的时间片 III Linux 调度算法O(1) 调度优先级数组O(1)调度算法中的一个核心数据结构即为prio_array结构体，该结构体中有一个用来表示进程动态优先级的 queue，它其中的每一项都是一种优先级形成的进程的链表，即每一条链表中的进程都有相同优先级 12345struct prio_array&#123; unsigned int nr_active; unsigned long bitmap[BITMAP_SIZE]; struct list_head queue[MAX_PRIO];&#125; 另外，该结构体中还包含一个优先级位图 bitmap，该位图使用1位来表示1种优先级，开始时，所有位置都置0，一旦有进程处于可运行状态时，该进程所在优先级对应位图中的相应位被置1. 因此，在 O(1)调度中查找最高的优先级就转化为查找优先级位图中第一个被置1的位 确定了最高优先级之后，选取下一个进程就是在 queue 对应的链表中取一个进程即可 活动进程和过期进程在 O(1)调度中，对可运行态的进程分了两类：一类为活动进程，即时间片还未用完的进程；另一类为过期进程，即时间片已经用完的进程，但进程还未结束，它们没有机会得到执行。 在可运行队列结构中（runqueue）的 arrays 的两个元素分别来表示上述两个集合，active 和 expire 两个指针分别指向这2个集合 时间片的计算active中的进程一旦时间片使用完毕就会放入expire中，并设置好新的时间片；当active为空时，说明所有进程时间片已耗尽，此时，将active和expire对调，重新开始下一轮时间片的递减过程。 O(1)算法中的两个核心 选择下一个进程 时间片的重新分配 CFS 调度（公平调度）O(1)算法是根据进程的优先级进行调度的；CFS 是根据进程的虚拟进程运行时间来进行调度的 如何选择进程?CFS 提出了虚拟运行时间的概念（vruntime），vruntime 记录了一个可执行进程到当前时刻为止执行的总时间，vruntime 越大，它被调度的可能性越小，因此每次选择 vruntime 越小的进程进行调度（在 Linux 中使用红黑树来找出 vruntime 最小的进程） 调度进程的运行时间现在已经知道了进程是如何调度的，那么当进程运行时，它的运行时间是多少呢？ CFS 的运行时间是由当前所有可调度进程优先级比重来确定的 例：3个进程优先级为5，15，20，它们时间片大小分配为：5/40, 15/40, 20/40 IV 抢占和上下文切换上下文切换表示从一个可执行进程切换到另一个可执行进程（定义在 sched.h 中的 context_switch()） 调用 switch_mm()：把虚拟进程从一个进程切换到新进程 调用 switch_to()：保存和恢复栈信息、寄存器信息 need_resched 标志：每个进程都包含该标志，为了让内核知道在什么时候调用schedule().当某进程应该被抢占时，设置该标志；当一个优先级高的进程进入可执行态时，也会设置该标志。 用户抢占的发生 从系统调用返回用户空间时 从中断处理程序返回用户空间时 当内核返回用户空间时，如果 need_resched 被设置，会导致 schedule() 被调用，此时发生用户抢占 内核抢占的发生 从中断程序返回内核空间时 内核代码再一次具有可抢占性时 如果内核中的任务显示调用 schedule() 如果内核中的任务阻塞（同样也会调用schedule()） 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读薄「Linux 内核设计与实现」]]></title>
    <url>%2F2016%2F06%2F07%2Flkd-thin-00%2F</url>
    <content type="text"><![CDATA[本学期的课程中有一门课程叫做《操作系统开发技术》，课程中所选用的教材即《Linux 内核设计与实现》，这个系列的博客是我整理的读书笔记和上课的部分内容，主要有以下几个部分： 读薄「Linux 内核设计与实现」(1) - 从内核出发 读薄「Linux 内核设计与实现」(2) - 进程管理和调度 读薄《Linux 内核设计与实现》(3) - 系统调用 读薄《Linux 内核设计与实现》(4) - 中断与同步 读薄《Linux 内核设计与实现》(5) - 定时器、时间管理和内存管理 读薄《Linux 内核设计与实现》(6) - 虚拟文件系统 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读薄「Linux 内核设计与实现」(1) - 从内核出发]]></title>
    <url>%2F2016%2F06%2F07%2Flkd-thin-01%2F</url>
    <content type="text"><![CDATA[这篇文章是《读薄「Linux 内核设计与实现」》系列文章的第一篇，本文主要讲了两个问题：内核编程的特点以及 GNU C 在内核开发中的特点。 0x00 内核编程特点 无 libc 库，不能访问标准 C 文件 使用 GNU C 无内存保护机制 慎用浮点数计算 注意同步和并发 可移植性考虑：保持字节顺序、64位对齐、不假定字长和页面长度 0x01 GNU C 内联函数：将函数展开至调用位置，省却函数调用代价 内联汇编：在确定体系结构的情况下，在 C 代码中直接嵌入汇编代码 分支声明：分支时可根据预知条件发生的概率进行优化 例： 123if(error)&#123;/* do something */&#125; 优化后： 123if(unlikely(error))&#123; //error为0的概率大/* do something */&#125; 或： 123if(likely(success))&#123; //success为0的概率大/* do something */&#125; 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【读薄《编程珠玑》】壹 开篇]]></title>
    <url>%2F2016%2F05%2F19%2Fprogramming-pearls-thin-1%2F</url>
    <content type="text"><![CDATA[这篇文章是《读薄&lt;编程珠玑&gt;》系列博客的第一篇，在这篇文章中，我总结了在书中出现的一些问题以及一些解决方案。 问题集合 0x01：一个最多包含n个正整数的文件，每个数都小于n，其中n=107，并且没有重复。最多有1MB内存可用。要求用最快方式将它们排序并按升序输出 0x02：使用位逻辑运算来实现位向量 0x03：尽可能快的生成位于 0~n-1 之间的 k 个随机不同顺序的整数 0x04：如果在问题0x01中需要1.25MB 的内存空间来进行排序，而我们只有1MB 空间该如何处理？ 0x05：如果在问题0x01中，每个数字出现的次数不是1次，而是不多于10次，该如何处理？ 0x06：如果说我们的位向量非常的稀疏，可能10000位里只有100位得到了使用，这样的话大量的时间都会浪费在初始化空间上，该如何解决这个问题？ 0x07：如何组织电话号码的存储，来能够支持高效的插入和检索操作？ 方案集合 0x01：把文件一次读入，出现的数字在位向量对应索引处中标注为1，读取完文件之后，将位向量从低位向高位依次将为1的索引输出即可。(具体实现详见：http://blog.luoyuanhang.com/2016/05/15/I-%E4%BD%8D%E5%90%91%E9%87%8F%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%8E%E5%BA%94%E7%94%A8/) 0x02： 12345678910#define BITSPERWORD 32#define SHIFT 5#define MASK 0x1F#define N 10000000int a[1 + N/BITSPERWORD];void set(int i)&#123; a[i&gt;&gt;SHIFT] |= (1&lt;&lt;(i &amp; MASK)); &#125;void clr(int i)&#123; a[i&gt;&gt;SHIFT] &amp;= ~(1&lt;&lt;(i &amp; MASK)); &#125;void set(int i)&#123; a[i&gt;&gt;SHIFT] &amp;= (1&lt;&lt;(i &amp; MASK)); &#125; (详细分析请见：位向量的实现与应用) 0x03： 首先，生成一个大小为 N 的数组，每个值都等于它的索引值。 然后，遍历该数组 0~K-1 的位置，将遍历的第 i 个位置的值与随机的 第 K~N-1 的数字进行交换。 代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;time.h&gt;#define N 100#define K 80void swap(int *i, int *j);int randint(int m, int n);int main(void)&#123; srand((unsigned)time(NULL)); int x[N]; int i; for(i = 0; i &lt; N; i++) &#123; x[i] = i; &#125; for(i = 0; i &lt; K; i++) &#123; swap(&amp;x[i], &amp;x[randint(i+1,N-1)]); &#125; for(i = 0; i &lt; K; i++) &#123; printf("%d ", x[i]); &#125;&#125;int randint(int m, int n)&#123; return (rand()%(n-m+1) + m);&#125;void swap(int *i, int *j)&#123; *j = *j ^ *i; *i = *i ^ *j; *j = *j ^ *i;&#125; 0x04：我们可以使用2趟排序，第一次排序前一半，然后把前一半的位图结果存到硬盘，然后再处理后一半。这种方法需要读两遍文件。 0x05：我们可以在位图中使用4位来表示该数字出现的次数，例：0000表示没有出现，1010表示出现10次。 0x06：我们可以对位向量已经使用的位进行标注，只有将要使用的位才进行初始化。 我们借助两个 n 元向量和一个变量 top（初始为0） 来标识初始化向量，下面的代码实现了对数组元素 i 的首次访问： 1234from[i] = top;to[top] = i;data[i] = 1;top++; from[i] = top;表示将 i 在 to 中的索引值存放到 from 的第 i 位中to[top] = i;表示 to 的第 top 位存放的是 i 的值，即 data 中的第 i 位被标注 判断第 i 位是否被初始化的方法： 1(from[i] &lt; top) &amp;&amp; (to[from[i]] == i) 单凭第一个条件并不能确定第 i 位已被初始化因为 from 中的第 i 位有可能没被初始化，是一个随机的值。如果 to 中的第 from[i] 位等于 i 就能够说明 data[i] 已经被初始化。 0x07：使用电话号码的后两位来组织一个散列表，因为电话号码的后两位随机性比较强适合作为散列函数。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【读厚《编程珠玑》】I 位向量的实现与应用]]></title>
    <url>%2F2016%2F05%2F15%2FI-%E4%BD%8D%E5%90%91%E9%87%8F%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%8E%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[这篇文章是《读厚&lt;编程珠玑&gt;》系列博客的第一篇，我们在《编程珠玑》的第一章 - 开篇中就了解了位向量是什么，《编程珠玑》的作者使用位向量来解决了一个海量数据排序问题，这篇文章我们来深入的了解一下位向量的实现与应用。 0x00 位向量是什么？位向量，也叫位图，是一个我们经常可以用到的数据结构，在使用小空间来处理大量数据方面有着得天独厚的优势。位向量，顾名思义就是「位构成的向量」，我们通常使用0来表示 false，1来表示 true，例：[010111] 我们就可以说它是一个位向量，它表示 [false true false true true true]。在位向量这个数据结构中，我们常常把它的索引和它的值对应起来使用。 0x01 位向量的实现通常我们实现位向量的思路是：使用基本数据类型来表示多个位，使用多个基本数据类型来构成数组。例如：我们使用「int」类型来实现位向量，一个「int」类型有32位，我们使用 int 数组来存放整个位向量。 下面根据这个思路我们来写一下代码： 1234567891011121314#ifndef bitvector_h#define bitvector_h#include &lt;stdio.h&gt;#define N 1000000 //表示位向量元素个数#define BITPERINT 32 //int 有32位#define NUM (N-1)/BITPERINT+1#define SHIFT 5 //2^5=32,表示移位#define MASK 0x1F //二进制11111#define SET(i)&#123;vector[i &gt;&gt; SHIFT] |= (1 &lt;&lt; (i &amp; MASK));&#125; //第i位 置为1#define CLR(i)&#123;vector[i &gt;&gt; SHIFT] &amp;= ~(1 &lt;&lt; (i &amp; MASK));&#125; //第i位 置为0#endif /* bitvector_h */ 下面我们来分析一下这段代码，关键的部分就是 SET 和 CLR 这两个宏函数，我们来分解看一下代码： i &gt;&gt; SHIFT表示算数右移5位，即i / 32，该操作的作用是将数组的索引定位到需要操作的那个 int 的位置上，因为我们的位向量结构是由许多个 int 组成的，例如：如果i = 50,i &gt;&gt; SHIFT等于1，首先将第50位定位到了第2个 int 中。 i &amp; MASK表示取 i 的最后5位，例：50 &amp; MASK 等于10010,然后把1左移这么多位，即第18位为1 SET操作是取或运算，即把定位到的 int 中的某位设置为1，例：i = 50即把第二个 int 的第18位置1。CLR操作也是同样的道理。 使用位向量： 12345678int vector[NUM];int i;for(i = 0; i &lt; N; i++)&#123; CLR(i);&#125;SET(1);SET(20); 0x02 位向量的应用《编程珠玑》中的问题问题重述：一个最多包含n个正整数的文件，每个数都小于n，其中n=107，并且没有重复。最多有1MB内存可用。要求用最快方式将它们排序并按升序输出。 解决方案就是：把文件一次读入，出现的数字在位向量对应索引处中标注为1，读取完文件之后，将位向量从低位向高位依次将为1的索引输出即可。 Linux进程 pid 的分配算法我们知道：在 Linux 中，进程当中的 pid 号的分配是在 0~32767 之间的，其中 0~299 的进程号是分配给守护进程的，剩下的 pid 号是分配给普通进程的。在进程号(pid)的分配中就使用到了位向量。 (以下Linux 内核代码版本为：3.8) Linux 中用来存放 pid 的位向量结构体叫做 pidmap，具体代码如下(/include/linux/pid_namespace.h)： 1234struct pidmap &#123; atomic_t nr_free; //表示未分配的 pid 的个数 void *page; //用数组来表示位向量，每一位表示该同该索引号的 pid 是否被分配（1表示被分配，0表示未分配）&#125;; 下面我们来分析一下有关 pidmap 的操作： 置位为1 (/include/asm-generic/bitops/atomic.h)1234567891011121314static inline int test_and_set_bit(int nr, volatile unsigned long *addr)&#123; unsigned long mask = BIT_MASK(nr); unsigned long *p = ((unsigned long *)addr) + BIT_WORD(nr); unsigned long old; unsigned long flags; _atomic_spin_lock_irqsave(p, flags); old = *p; *p = old | mask; _atomic_spin_unlock_irqrestore(p, flags); return (old &amp; mask) != 0;&#125; 这个函数的作用是：当为一个进程申请到 pid 之后，将对应的pidmap中的 nr 位置位为1的函数，并返回置位之前该位的值。\*addr表示的是 pidmap 的地址 下面我们来分析一下具体代码： 在 /include/linux/bitops.h 中我们可以找到 BIT_MASK 的宏定义：1#define BIT_MASK(nr) (1UL &lt;&lt; ((nr) % BITS_PER_LONG)) 我们同样可以在 include/asm-generic/bitsperlong.h 找到 BITS_PER_LONG 的定义：12345#ifdef CONFIG_64BIT#define BITS_PER_LONG 64#else#define BITS_PER_LONG 32#endif /* CONFIG_64BIT */ 我们可以知道 BITS_PER_LONG 是和机器相关的，为32或64. 1UL &lt;&lt; (nr) % BITS_PER_LONG)表示取 nr 的第0~BITS_PER_LONG位，然后把1左移这么多位 我们同样可以在include/asm-generic/bitsperlong.h 找到 BIT_WORD 的定义：1#define BIT_WORD(nr) ((nr) / BITS_PER_LONG) 它用于定位想要操作的 nr 位在数组中的第几个单位中，因此 unsigned long *p = ((unsigned long *)addr) + BIT_WORD(nr); 这条语句就是将 *p 指向想要操作的位 *p = old | mask; 将第 nr 位置 1 return (old &amp; mask) != 0; 返回置位之前 nr 位的值 置位为0 (/include/asm-generic/bitops/atomic.h)1234567891011121314static inline int test_and_clear_bit(int nr, volatile unsigned long *addr)&#123; unsigned long mask = BIT_MASK(nr); unsigned long *p = ((unsigned long *)addr) + BIT_WORD(nr); unsigned long old; unsigned long flags; _atomic_spin_lock_irqsave(p, flags); old = *p; *p = old &amp; ~mask; _atomic_spin_unlock_irqrestore(p, flags); return (old &amp; mask) != 0;&#125; 与上面不同的操作就是 *p = old &amp; ~mask; 将第 nr 位置 0 寻找一下个为0的位置 1234567891011121314151617181920212223242526272829303132333435363738unsigned long find_next_zero_bit(const unsigned long *addr, unsigned long size, unsigned long offset)&#123;//addr 表示 pidmap 的地址，size = PAGE_SIZE*8，offset 一开始为0 unsigned long *p = addr + BITOP_WORD(offset); unsigned long result = offset &amp; ~(BITS_PER_LONG-1);//如果BITS_PER_LONG为32，则取 offset 后5位 unsigned long tmp; if (offset &gt;= size) return size; size -= result; offset %= BITS_PER_LONG;//offset位于32位的第几位 if (offset) &#123;//如果 offset 不在数组单位中的第一位 tmp = *(p++); tmp |= ~0UL &gt;&gt; (BITS_PER_LONG - offset);//将0~offset 位置1 if (size &lt; BITS_PER_LONG)//不足32位 goto found_first; if (~tmp)//存在0 goto found_middle; //说明 tmp 为全1： size -= BITS_PER_LONG;//到下一个单位空间 result += BITS_PER_LONG;//数据减少一个单位大小 &#125; while (size &amp; ~(BITS_PER_LONG-1)) &#123; if (~(tmp = *(p++))) goto found_middle; result += BITS_PER_LONG;//到下一个单位空间 size -= BITS_PER_LONG;//数据减少一个单位大小 &#125; if (!size)//size = 0 说明已经全部查完，result = size 返回 return result; tmp = *p;//size 不是32的整数倍，说明有额外几个 bit，继续查found_first: tmp |= ~0UL &lt;&lt; size; if (tmp == ~0UL) return result + size;found_middle: return result + ffz(tmp);&#125; 分配 pid 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static int alloc_pidmap(struct pid_namespace *pid_ns)&#123; int i, offset, max_scan, pid, last = pid_ns-&gt;last_pid; struct pidmap *map; pid = last + 1; if (pid &gt;= pid_max) pid = RESERVED_PIDS;//RESERVED_PIDS=300,前300为守护进程 offset = pid &amp; BITS_PER_PAGE_MASK;//pid 在一个单位中的偏移量 map = &amp;pid_ns-&gt;pidmap[pid/BITS_PER_PAGE]; max_scan = DIV_ROUND_UP(pid_max, BITS_PER_PAGE) - !offset; for (i = 0; i &lt;= max_scan; ++i) &#123; if (unlikely(!map-&gt;page)) &#123; //分配空间 void *page = kzalloc(PAGE_SIZE, GFP_KERNEL); spin_lock_irq(&amp;pidmap_lock); if (!map-&gt;page) &#123; map-&gt;page = page; page = NULL; &#125; spin_unlock_irq(&amp;pidmap_lock); kfree(page); if (unlikely(!map-&gt;page)) break; &#125; if (likely(atomic_read(&amp;map-&gt;nr_free))) &#123; do &#123; if (!test_and_set_bit(offset, map-&gt;page)) &#123;//offset 位置的 pid 是否被分配 atomic_dec(&amp;map-&gt;nr_free);//原子操作，将空闲数量减一 set_last_pid(pid_ns, last, pid); return pid;//分配该 pid &#125; offset = find_next_offset(map, offset); pid = mk_pid(pid_ns, map, offset); &#125; while (offset &lt; BITS_PER_PAGE &amp;&amp; pid &lt; pid_max); &#125; if (map &lt; &amp;pid_ns-&gt;pidmap[(pid_max-1)/BITS_PER_PAGE]) &#123; ++map; offset = 0; &#125; else &#123; map = &amp;pid_ns-&gt;pidmap[0]; offset = RESERVED_PIDS; if (unlikely(last == offset)) break; &#125; pid = mk_pid(pid_ns, map, offset); &#125; return -1;&#125; 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《编程珠玑》读书笔记]]></title>
    <url>%2F2016%2F05%2F15%2Fprogramming-pearls-directory%2F</url>
    <content type="text"><![CDATA[这系列博客是我读《编程珠玑》所做的笔记，主要分为两部分，一部分是『读薄』部分，另一部分是『读厚』部分。在『读薄』部分主要记录了书中的一些问题以及解决方案，在『读厚』部分是我的一些理解和总结，以及书中一些问题的延伸。 『读薄』部分： 壹 开篇 『读厚』部分： I 位向量的实现与应用 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PART 2: 使 Shell 能读取命令]]></title>
    <url>%2F2016%2F04%2F23%2FPART-2-%E4%BD%BF-Shell-%E8%83%BD%E8%AF%BB%E5%8F%96%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[这篇文章是《动手写 Shell》系列文章的第 篇。上篇文章中，我们已经完成了我们动手 Shell 的第一步：Shell 的提示符。在这篇文章中，我们开始使得我们的 Shell 能够开始读取命令，并且做简单的分词，将命令与参数分开。 读取命令0x00 readline 库的使用在实现读取命令的方法中我们所使用到的库是 readline，其实我们使用 fgets() 方法也能达到目的，但是如果使用 fgets() 的话如果我们在使用 Shell 时输入错了命令不能通过退格键来撤销，因为 fgets() 是按字符进行读取的。 0x01 安装 readline 库1sudo apt-get install libreadline-dev 0x02 使用 readline 库如果我们的程序中使用到了该库，需要在编译代码时需要链接到 libreadline 例： 1gcc -o test test.o -I /usr/include -lreadline 处理命令0x00 实现思路对于一条命令 1cmd para1 para2 […… paraN] 我们希望它能被识别成为： 命令: cmd参数0: cmd参数1: para1参数2: para2……参数N: paraN 其实思路也是很简单： 我们需要一个command指针来存储命令，一个数组来存储命令。 需要两个指针来顺着我们的整条指令来移动，来获取到每一个命令或者参数。 一开始时： 两个指针 *start, *end都指向指令的开头 如果 *start, *end 指向空格，自动向后移动 定义一个计数器 count，然后 *end 指针开始向后移动，直到碰到空格或者换行符或者结束符 如果 count 为0，说明当前处理的是命令，定一个临时指针 *p,沿着 *end 向 *start 移动，将其赋给 *command 和 parameter[0]，count + 2. 如果 *end 为换行符或终止符则停止，否则，将 *end 赋给 *start,然后 *end 按上述方式继续向后移动，直到遇到空格，将 *start 赋给 parameters[count-1]， count + 1. 重复以上工作，直到 *end 遇到终止符 \0 或者换行符 \n 0x01 实现代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697#include "lshell.h"#include &lt;readline/readline.h&gt;#include &lt;readline/history.h&gt;int read_command(char **command, char **parameters, char *prompt)&#123; free(buffer); buffer = readline(prompt); if(feof(stdin)) &#123; printf("\n"); exit(0); &#125; if(buffer[0] == '\0') &#123; return -1; &#125; int count = 0; char *start, *end; int isFinished = 0; start = end = buffer; while(isFinished == 0) &#123; while((*start == ' ' &amp;&amp; *end == ' ') || (*start == '\t' &amp;&amp; *end == '\t')) &#123; start++; end++; &#125; if(*end == '\0' || *end == '\n') &#123; if(count == 0) &#123; return -1; &#125; break; &#125; while(*end != '\0' &amp;&amp; *end != '\n' &amp;&amp; *end != ' ') &#123; end++; &#125; if(count == 0)&#123; char *p = end; *command = start; while(p != start &amp;&amp; *p != '/')&#123; p--; &#125; if(*p == '/')&#123; p++; &#125; parameters[0] = p; count += 2;#ifdef DEBUG printf("\ncommand:%s\n", *command);#endif // DEBUG &#125; else if(count &lt;= MAX_ARGS)&#123; parameters[count-1] = start; count++; &#125; else&#123; break; &#125; if(*end = '\0' || *end == '\n')&#123; *end = '\0'; isFinished = 1; &#125; else&#123; *end = '\0'; end++; start = end; &#125; &#125; parameters[count-1] = NULL;#ifdef DEBUG printf("input analysis:\n"); printf("command:[%s]\ncommand:[%s]\nparameters:\n",*command,parameters[0]); int i; for(i=0;i&lt;count-1;i++) printf("[%s]\n",parameters[i]);#endif return count;&#125; 完整代码详见：https://github.com/luoyhang003/linux_kernel_expriment/tree/master/exp2 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>C</tag>
        <tag>Shell</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PART 1: Shell 提示符的实现]]></title>
    <url>%2F2016%2F04%2F10%2FPART-1-Shell-%E6%8F%90%E7%A4%BA%E7%AC%A6%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[这篇文章是《动手写 Shell》系列文章的第 篇，在这篇文章中，我们先完成一个 Shell 中最基本的功能 - Shell 提示符的实现。在这篇文章中，我会介绍一下实现的思路，以及介绍下用到的系统 API 和一些 C 语言中的库函数。 Shell 提示符用过 Linux 的人都知道当我们打开终端时，在命令行中会出现一行字，后边会有光标在一直删，那一行字就是 Shell 的提示符。 提示符格式我们通常看到的 Shell 提示符的格式如下所示： 1username@hostname:~/path$ 我们要写的 Shell 的第一步就是来实现这个东西。 实现思路从提示符的格式中我们就知道我们首先需要得到： 用户名 主机名 当前路径 我们主要通过调用 Linux 系统 API 的方式来完成上述功能。 所需要的功能0x00 得到当前用户名passwd 结构体在 Linux 中定义了一个 passwd 结构体，该结构体定义了与用户有关的信息，在 /usr/include/pwd.h 中 该结构体定义如下：1234567891011/* The passwd structure. */struct passwd&#123; char *pw_name; /* Username. */ char *pw_passwd; /* Password. */ __uid_t pw_uid; /* User ID. */ __gid_t pw_gid; /* Group ID. */ char *pw_gecos; /* Real name. */ char *pw_dir; /* Home directory. */ char *pw_shell; /* Shell program. */&#125;; getpwuid() 与 getuid() 函数 getuid(): 用来获取当前用户的 ID getpwuid(uid_t uid): 根据用户 ID 来获取 passwd 结构体 用法： 1234567891011121314151617#include &lt;pwd.h&gt;#include &lt;sys/types.h&gt;#include &lt;stdio.h&gt;int main()&#123; uid_t my_uid; structpasswd *my_info; my_info =getpwuid(getuid()); printf( "my name = [%s]\n", my_info-&gt;pw_name ); printf( "my passwd = [%s]\n", my_info-&gt;pw_passwd ); printf( "my uid = [%d]\n", my_info-&gt;pw_uid ); printf( "my gid = [%d]\n", my_info-&gt;pw_gid ); printf( "my gecos = [%s]\n", my_info-&gt;pw_gecos ); printf( "my dir = [%s]\n", my_info-&gt;pw_dir ); printf( "my shell = [%s]\n", my_info-&gt;pw_shell ); return0;&#125; 0x02 得到当前主机名通过 gethostname() 函数我们可以获得当前主机名 123int max_name_len = 256;char hostname[max_name_len];gethostname(hostname, max_path_len); 0x03 获取当前路径通过 getced() 函数我们可以获得当前路径 123int max_path_len = 1024;char pathname[max_path_len];getcwd(pathname, max_path_len); 0x04 需要处理的其它问题当前用户目录下的显示对于在当前目录下的提示符我们采用将用户主目录用 ~ 来代替，对于不在当前目录下的提示符我们再使用完整的目录来进行显示，这也是目前 Ubuntu 中的默认终端所采取的提示符显示格式。 实现策略： 如果当前目录前面一部分同用户主目录路径不相符，则显示完整目录 如果当前目录的长度小于用户主目录路径，则显示完整目录 其他情况，将当前目录与用户主目录相同部分用 ~ 代替 实现方法： 获取用户主目录： 我们通过访问 passwd 结构体的方式来获取用户主目录路径： 123char home_dir[1024];pwd = getpwuid(getuid());home_dir = pwd-&gt;pw_dir; 是否是 root 用户对于是 root 用户的提示符我们将使用 # 来进行表示，对于其他用户使用 $ 来表示。 实现方法： 我们使用 getuid() 函数来判断当前用户是否是 root 用户， 如果返回值为 0，则是 root 用户。 用到的C库函数sprintf()功能它的功能是把格式化的数据写入某个字符串缓冲区。 头文件stdio.h 原型int sprintf( char *buffer, const char *format, [ argument] … ); 参数列表 buffer： char型指针，指向将要写入的字符串的缓冲区。 format： 格式化字符串。 [argument]…： 可选参数，可以是任何类型的数据。 strncmp()功能这个函数用来比较 s1 和 s2 字符串的前 num 个字符。如果两个字符串相等的话，strncmp 将返回0。 头文件string.h 原型int strncmp ( const char * str1, const char * str2, size_t num ); 参数列表 str1: 待比较字符串 1 str2: 待比较字符串 2 num: 比较的位数 参考代码下面贴上实现 Shell 提示符的代码： 详见：https://github.com/luoyhang003/linux_kernel_expriment/tree/master/exp2 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/* * prompt.c ---- Description *------------------------------------------------------------ * Date: April 8th, 2016 * Copyright: Written by Jason Luo - luoyhang003@hotmail.com * Function: Promption of the Shell *------------------------------------------------------------ */#include"lshell.h"const int max_name_len = 256;const int max_path_len = 1024;void get_prompt(char *prompt)&#123; extern struct passwd *pwd; char hostname[max_name_len]; char pathname[max_path_len]; int prompt_length; pwd = getpwuid(getuid()); getcwd(pathname, max_path_len); if(gethostname(hostname, max_path_len) == 0) &#123; sprintf(prompt, "lshell&gt;%s@%s:", pwd-&gt;pw_name, hostname); &#125; else &#123; sprintf(prompt, "lshell&gt;%s@unknown:", pwd-&gt;pw_name); &#125; prompt_length = strlen(prompt); if(strlen(pathname) &lt; strlen(pwd-&gt;pw_dir) || (strncmp(pathname, pwd-&gt;pw_dir, strlen(pwd-&gt;pw_dir))) != 0) &#123; sprintf(prompt + prompt_length, "%s", pathname); &#125; else &#123; sprintf(prompt + prompt_length, "~%s", pathname + strlen(pwd-&gt;pw_dir)); &#125; prompt_length = strlen(prompt); if(geteuid() != 0) &#123; sprintf(prompt + prompt_length, "$"); &#125; else &#123; sprintf(prompt + prompt_length, "#"); &#125; return;&#125; 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>C</tag>
        <tag>Shell</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 Mac 上打包 PyQT 程序]]></title>
    <url>%2F2016%2F04%2F07%2F%E5%9C%A8-Mac-%E4%B8%8A%E6%89%93%E5%8C%85-PyQT-%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[有许多人使用 Python 来写图形化界面时选择了 PyQT，但是有许多人不知道如何将开发好的程序打包成为安装包，这篇文章我就来介绍一种非常简单的也是非常基础的在 MAC 下打包 PyQT 程序的方法。 安装 PyQT安装 QT我们首先要安装 QT，我这里安装的是， QT 5.5，对于 MAC 上 QT 的安装直接到官方网站上去找到对应的安装包下载安装即可。 http://www.qt.io/ 安装 SIP对于 SIP，我们也需要到官方网站去下载对应的 MAC 的源码包，安装过程如下： 123python configure.pysudo makesudo make install 如果该过程中出现了 Operation not permitted 的报错信息，解决方案详见：解决 Mac OS X 10.11 安装 sip 没有权限的问题 安装 PyQT我们需要到官方网站上去下载 PyQT5 的源码包，编译安装： 123python configure.pysudo makesudo make install 需要注意的是，在 make 的过程中可能需要我们在参数中加入 QT5 的 bin 目录和 SIP 的安装目录。 安装 PyInstaller在终端中执行： 1sudo pip install pyinstaller 这样就安装完成了打包所需要的工具 写一个 PyQT 程序下面我们来写一个简单的 PyQT 程序： 123456789101112131415mport sysfrom PyQt5.QtWidgets import QApplication, QWidgetif __name__ == '__main__': app = QApplication(sys.argv) w = QWidget() w.resize(250, 150) w.move(300, 300) w.setWindowTitle('Simple') w.show() sys.exit(app.exec_()) 执行之后： 1python testqt.py 我们会看到一个 QT 程序： 将 PyQT 程序 打包下面我们就将上面写的程序进行打包，成为 .app 文件 我们需要先对程序的入口文件运行一次打包程序（对于我的Demo就是 testqt.py）： 1pyinstaller --windowed --onefile --clean --noconfirm testqt.py 我们查看下目录有什么变化： 1234567891011121314151617181920212223242526$ tree.├── build│ └── testqt│ ├── out00-Analysis.toc│ ├── out00-BUNDLE.toc│ ├── out00-EXE.toc│ ├── out00-PKG.pkg│ ├── out00-PKG.toc│ ├── out00-PYZ.pyz│ ├── out00-PYZ.toc│ └── warntestqt.txt├── dist│ ├── testqt│ └── testqt.app│ └── Contents│ ├── Frameworks│ ├── Info.plist│ ├── MacOS│ │ └── testqt│ └── Resources│ └── icon-windowed.icns├── testqt.py└── testqt.spec8 directories, 14 files 打开自动生成的 testqt.spec,这就是一个配置文件： 1234567891011121314151617181920212223242526272829303132# -*- mode: python -*-block_cipher = Nonea = Analysis(['testqt.py'], pathex=['/Users/jason/Project/Python/PyQt'], binaries=None, datas=None, hiddenimports=[], hookspath=[], runtime_hooks=[], excludes=[], win_no_prefer_redirects=False, win_private_assemblies=False, cipher=block_cipher)pyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)exe = EXE(pyz, a.scripts, a.binaries, a.zipfiles, a.datas, name='testqt', debug=False, strip=False, upx=True, console=False )app = BUNDLE(exe, name='testqt.app', icon=None, bundle_identifier=None) 我们可以修改它来打包更复杂的程序，具体参考 PyInstaller 官方文档 下面就剩下最后一步我们就能将其打包成为 .app 文件了： 1pyinstaller --clean --noconfirm --windowed --onefile testqt.spec 我们可以看到在 dist 目录下多了一个 testqt.app，这就是我们打包完成的程序包，双击，可以正常运行。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Python</tag>
        <tag>QT</tag>
        <tag>PyQT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决 Mac OS X 10.11 安装 sip 没有权限的问题]]></title>
    <url>%2F2016%2F04%2F06%2F%E8%A7%A3%E5%86%B3-Mac-OS-X-10-11-%E5%AE%89%E8%A3%85-sip-%E6%B2%A1%E6%9C%89%E6%9D%83%E9%99%90%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在搭建 PyQT 的过程中我遇上了一个非常恶心的问题，在安装 sip 的时候编译源码之后的安装过程中一直提示我：Operation not permitted ，我甚至重装了系统也无济于事，最终通过查资料解决了问题。 安装 sip下载 sip 源码包解压之后进入它的目录下： 123python configure.pysudo makesudo make install 这时出现了一个很恶心的报错提示： 1234cp -f sip /System/Library/Frameworks/Python.framework/Versions/2.7/bin/sipcp: /System/Library/Frameworks/Python.framework/Versions/2.7/bin/sip: Operation not permittedmake[1]: *** [install] Error 1make: *** [install] Error 2 于是乎，我用 su 登录 Shell，在重复以上过程，无果。 之后，我又使用 brew install sip，报同样的错误。 然后我又进入 /System/Library/Frameworks/Python.framework 目录打算一探究竟： 试图修改它的权限，结果： 原因经历了XCode编译器代码被注入的事件后，这次 Mac OS X El Capitan系统的升级，启用了更高的安全性保护机制：系统完整性保护System Integrity Protection (SIP)。简单来讲就是更加强制性的保护系统相关的文件夹。开发者不能直接操作相关的文件内容。 苹果官方给出的解释： System Integrity Protection is a security technology in OS X El Capitan that’s designed to help prevent potentially malicious software from modifying protected files and folders on your Mac.In OS X, the “root” user account previously had no permission restrictions and could access any system folder or application on your Mac. Software gained root-level access when you entered your administrator name and password to install it and could then modify or overwrite any system file or application.System Integrity Protection restricts the root account and limits the actions that the root user can perform on protected parts of OS X.Paths and applications protected by System Integrity Protection include:/System/usr/bin/sbinApps that are pre-installed with OS XPaths and applications that third-party apps and installers can write to include:/Applications/Library/usr/localSystem Integrity Protection is designed to allow modifications of these protected parts only by processes that are signed by Apple and have special entitlements to write to system files, like Apple software updates and Apple installers.Apps that you download from the Mac App Store already work with System Integrity Protection. Other third-party software that conflicts with System Integrity Protection might be set aside when you upgrade to OS X El Capitan.System Integrity Protection also helps prevent software from changing your startup volume. To boot your Mac from a different volume, you can use the Startup Disk pane in System Preferences or you can hold down the Option key while you reboot, and select a volume from the list.Information about products not manufactured by Apple, or independent websites not controlled or tested by Apple, is provided without recommendation or endorsement. Apple assumes no responsibility with regard to the selection, performance, or use of third-party websites or products. Apple makes no representations regarding third-party website accuracy or reliability. Risks are inherent in the use of the Internet. Contact the vendor for additional information. Other company and product names may be trademarks of their respective owners.https://support.apple.com/en-us/HT204899 解决方案其实解决方案就已经很简单了，既然是系统中有 SIP 的问题，那么我们把它关闭就好了： 重启系统 按住 Command + R 进入 Recoverary 模式 点击 实用工具 &gt; 终端 输入 csrutil disable 重启系统 这时我们再重新编译安装 sip 就没有任何问题了。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Python</tag>
        <tag>PyQT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术干货分享]]></title>
    <url>%2F2016%2F03%2F27%2F%E6%8A%80%E6%9C%AF%E5%B9%B2%E8%B4%A7%E5%88%86%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[这篇文章中的大部分书籍、网站、博客等曾经在我的学习中给了我很大的帮助，因此把他们分享出来，希望能给更多的人以帮助，也希望大家能够继续补充，可以在后边的评论区进行补充，我会时刻进行更新。 0x00 关于 C++书籍（难度递增） 《C++ primer plus》 《C++程序设计原理与实践 》 《Effective C++ 》 《C++编程规范》 《C++模板元编程》 《Advanced C++ Metaprogramming》 网站 C++入门教程（英文） http://www.tutorialspoint.com/cplusplus/index.htm C++程序代码片 http://www.planetsourcecode.com/vb/default.asp?lngWId=3 一些C++项目 http://www.codeproject.com/?cat=2 C++标准库教程和参考资料 http://www.josuttis.com/libbook/examples.html 一些用C++写的程序 http://people.sc.fsu.edu/~jburkardt/cpp_src/cpp_src.html 0x01 关于 Python书籍（最好结合网上资源进行入门） 《Expert Python Programming》（英文） 《Python 高级编程》 《Python 源码分析》 网站 廖雪峰大神的 Python 入门教程 http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000 Python2 入门教程（英文） http://www.tutorialspoint.com/python/index.htm 南京大学公开课 https://www.coursera.org/learn/hipython/ Python练手小项目 https://www.zhihu.com/question/29372574 Python与机器学习数据处理 https://www.dataquest.io/ Python Guide http://docs.python-guide.org/en/latest/ Python3 Cookbookhttp://python3-cookbook.readthedocs.org/zh_CN/latest/c01/p07_keep_dict_in_order.html CSDN专栏：Python也可以 http://blog.csdn.net/column/details/python-can.html 微信公众号： 编程派 Python开发者 0x02 关于 QT书籍 《Qt 5编程入门》 《Qt+Creator快速入门》 《C++ GUI Qt 4 编程（第二版）》 《Qt5开发及实例》 《C++ Qt5 范例开发大全》 网站 官方文档 http://doc.qt.io/ QT 学习之路http://www.devbean.net/category/qt-study-road-2/ 为知笔记QT开源项目 https://github.com/WizTeam/WizQTClient 0x03 关于 Git书籍 《Git 权威指南》 《Pro Git》 《Git版本控制管理》 网站 廖雪峰大神的Git教程 http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000 0x04 算法与数据结构书籍 《算法》 《数据结构与算法分析——C语言描述》 《编程珠玑》 《算法设计与分析基础》 《算法引论》 《Advanced Data Structures》 网站 我的算法学习之路 http://lucida.me/blog/on-learning-algorithms/ 算法学习笔记 https://github.com/nonstriater/Learn-Algorithms LeetCode http://leetcode.com/ 麻省理工公开课 http://www.class.cn/course/course_detail/?course_id=100103 可视化的数据结构和算法 http://www.csdn.net/article/2011-05-06/297285 一些算法 http://top.jobbole.com/tag/algorithm/?utm_source=jobboleblog-sidebar-topic 0x05 机器学习书籍 《机器学习》周志华 《机器学习实战》 《图解机器学习》 网站 Stanford 公开课（万分推荐） https://www.coursera.org/learn/machine-learning 机器学习基础 https://www.coursera.org/course/ntumlone 机器学习与统计 http://pan.baidu.com/s/1gd5hNdL CSDN寒小阳博客 http://blog.csdn.net/han_xiaoyang/article/details/49123419 人工智能和机器学习领域有哪些有趣的开源项目 http://code.csdn.net/news/2822818 近200篇机器学习&amp;深度学习资料分享 http://developer.51cto.com/art/201501/464174.htm 机器学习路线图 http://blog.csdn.net/han_xiaoyang/article/details/50759472 0x06 Linux 内核书籍 《Linux 内核设计与实现》 《深入理解Linux内核》 《Linux内核完全剖析》 《Linux内核设计的艺术》 《Linux内核源代码情景分析》 《Linux内核探秘》 《Linux内核完全注释》 网站 庖丁解牛Linux内核 http://mooc.study.163.com/course/USTC-1000072000?tid=1000096000#/learn/announce Linux内核之旅 http://www.kerneltravel.net/ LXR http://lxr.oss.org.cn/ Linux内核探秘（提取密码：4fbr） http://pan.baidu.com/s/1hsEWo9e Linux从入门到内核驱动编译（提取密码：3cmw） http://pan.baidu.com/s/1eSi6syY Linux Inside https://0xax.gitbooks.io/linux-insides/content/ 0x07 Android 开发书籍 《Android 第一行代码》 网站 CSDN专栏：Android基础开发笔记 http://blog.csdn.net/column/details/android-gu.html?&amp;page=2 Mars Android开发视频教程 http://mars.apkbus.com/ CodePath http://guides.codepath.com/android 0x08 学习 Arduino书籍 《Arduino程序设计基础》 《Arduino权威指南》 《Arduino开发实战指南》 网站 发现有趣的项目 http://www.seeedstudio.com/recipe/ Arduino中文社区 http://www.arduino.cn/ 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>分享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 分发工具初探之 setuptools 进阶]]></title>
    <url>%2F2016%2F03%2F25%2FPython-%E5%88%86%E5%8F%91%E5%B7%A5%E5%85%B7%E5%88%9D%E6%8E%A2%E4%B9%8B-setuptools-%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[在上篇文章中我们知道了 setuptools 是什么，以及它基本的功能和用法。在这篇文章中，我们会介绍如何讲setuptools应用于稍大的项目中，通过 setuptools 控制包中的文件。 0x03 使用 find_packages()在之前的例子中，我们使用的都是 setup() 的默认参数，使用默认参数只能打包一些简单的、不复杂的工程，如果我们的工程中的文件越来越多，就不能使用它的默认参数了。 现在我们来建这样一个工程： 12345678910111213141516.├── setup.py└── src ├── demo.egg-info │ ├── PKG-INFO │ ├── SOURCES.txt │ ├── dependency_links.txt │ └── top_level.txt └── test ├── __init__.py ├── a.txt └── data ├── data1.dat └── data2.dat4 directories, 9 files 如果像之前那样使用 setup() 的默认参数来进行打包，我们会看到的 egg 如下： 123456789101112Archive: demo1-0.1-py2.7.egg Length Date Time Name -------- ---- ---- ---- 1 03-25-16 20:27 EGG-INFO/dependency_links.txt 177 03-25-16 20:27 EGG-INFO/PKG-INFO 141 03-25-16 20:27 EGG-INFO/SOURCES.txt 5 03-25-16 20:27 EGG-INFO/top_level.txt 1 03-25-16 20:27 EGG-INFO/zip-safe 102 03-22-16 23:48 test/__init__.py 354 03-25-16 20:27 test/__init__.pyc -------- ------- 781 7 files 依然是只有 __init__.py ，如果我们要想把上边目录中的 .txt 文件和 /data 下的 .dat 文件也包含到我们的egg包中，我们需要修改 setup.py ： 12345678910111213141516171819#-*- coding:utf-8 -*-from setuptools import setup, find_packagessetup( name = "demo", version = "0.1", # 包含所有src目录下的包 packages = find_packages('src'), package_dir = &#123;'':'src'&#125;, package_data = &#123; # 包含所有.txt文件 '':['*.txt'], # 包含data目录下所有的.dat文件 'test':['data/*.dat'], &#125; ) 这时我们再看一下 egg 包中的内容： 123456789101112131415Archive: demo-0.1-py2.7.egg Length Date Time Name -------- ---- ---- ---- 1 03-25-16 20:47 EGG-INFO/dependency_links.txt 176 03-25-16 20:47 EGG-INFO/PKG-INFO 220 03-25-16 20:47 EGG-INFO/SOURCES.txt 5 03-25-16 20:47 EGG-INFO/top_level.txt 1 03-25-16 20:47 EGG-INFO/zip-safe 102 03-22-16 23:48 test/__init__.py 354 03-25-16 20:47 test/__init__.pyc 0 03-25-16 17:24 test/a.txt 0 03-25-16 17:24 test/data/data1.dat 0 03-25-16 17:24 test/data/data2.dat -------- ------- 859 10 files 我们也可以排除掉某些文件： 1find_packages(exclude=[&quot;*.tests&quot;, &quot;*.tests.*&quot;, &quot;tests.*&quot;, &quot;tests&quot;]) 0x04 使用 entry_pointsentry_points 是一个字典，从entry point组名映射道一个表示entry point的字符串或字符串列表。Entry points是用来支持动态发现服务和插件的，也用来支持自动生成脚本。 比如说： 1234567891011121314151617setup( entry_points = &#123; 'console_scripts': [ 'foo = demo:test', 'bar = demo:test', ], 'gui_scripts': [ 'baz = demo:test', ] &#125;)我们再安装这个 egg，会发现在安装过程中会出现：```bashInstalling foo script to /usr/local/binInstalling bar script to /usr/local/bin 查看 /usr/local/bin/foo 内容： 12345678910#!/usr/bin/python# EASY-INSTALL-ENTRY-SCRIPT: 'demo==0.1','console_scripts','foo'__requires__ = 'demo==0.1'import sysfrom pkg_resources import load_entry_pointif __name__ == '__main__': sys.exit( load_entry_point('demo==0.1', 'console_scripts', 'foo')() ) 这个内容其实显示的意思是，foo将执行 console_scripts 中定义的foo所代表的函数。执行foo，发现打出了 hello world!，和预期结果一样。 0x05 总结这篇文章介绍了一些 setuptools 比较进阶的使用方法，对于更详细的其他用法，详见官方文档 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 分发工具初探之 setuptools]]></title>
    <url>%2F2016%2F03%2F23%2FPython-%E5%88%86%E5%8F%91%E5%B7%A5%E5%85%B7%E5%88%9D%E6%8E%A2%E4%B9%8B-setuptools%2F</url>
    <content type="text"><![CDATA[这篇文章主要介绍了一下 setuptools 是什么，以及它的功能和特点，并且介绍了如何使用它来创建和安装使用自己的包，这篇文章仅仅讲了最基本的功能和用法，一些对于进阶的用法会在下篇文章中进行介绍。 0x00 setuptools 是什么setuptools 与 disutils我们通常所知道的 Python 分发工具是 Python distutils， setuptools 可以说是它的增强版，它能帮助我们更好的创建和分发 Python 的包，尤其是具有复杂依赖关系的包。对于开发者来说，能够更好的组织自己项目的分发和发布；对于用户来说，不需要安装 setuptools 也可以使用由它创建的包，只需要一个启动模块即可。 实现这样的的包管理机制主要由两部分构成： 一个存储在 Python 官方网站的集中式仓库，名叫 Python Package Index（PyPI） 另外就是基于 distutils 开发的 setuptools 包管理系统 它提供的内容包括： 用来提供标准元数据字段：诸如作者名、版权类型等信息的骨架 一组用来将包中的代码来构建软件安装包的辅助工具 distutils 仅仅适用于包，它无法定义包之间的依赖关系。但是 setuptools 通过添加一个基本的依赖系统以及许多相关功能，弥补了该缺陷。他还提供了自动包查询程序，用来自动获取包之间的依赖关系，并完成这些包的安装，大大降低了安装各种包的难度，使之更加方便。 ##相关功能 利用 EasyInstall 自动查找、下载、安装升级依赖包 能够创建 Python Eggs、 包含目录中的数据文件和包，不需要在 setup() 函数中一一列举出来 自动包含包内和发布有关的所有相关文件，而不用创建一个 MANIFEST.in文件 自动生成经过包装的脚本 支持Pyrex，即在可以 setup.py 中列出 .pyx 文件，而最终用户无须安装Pyrex 支持上传到 PyPI 可以部署开发模式，使项目在sys.path中 用新命令或 setup() 参数扩展distutils，为多个项目发布/重用扩展 在项目的 setup()中简单声明 entry points，创建可以自动发现扩展的应用和框架 0x01 安装 setuptools##**Ubuntu： 1sudo apt-get install python-setuptools ##Mac： 安装 wget： 123456curl -O http://ftp.gnu.org/gnu/wget/wget-1.13.4.tar.gztar -xzvf wget-1.13.4.tar.gzcd wget-1.13.4./configuremakesudo make install 安装 setuputils： 12wget http://peak.telecommunity.com/dist/ez_setup.pysudo python ez_setup.py 0x02 创建一个简单的包创建一个空的包新建一个 demo 目录 12mkdir demo1cd demo1 在目录下新建 setup.py 文件 1234567from setuptools import setup, find_packagessetup(name = 'demo1',version = '0.1',packages = find_packages(),) 将该项目打包 1python setup.py bdist_egg 这时我们查看该项目目录： 1234567891011demo1|--build| `--bdist.macosx-10.11-intel|--demo1.egg-info| |--dependency_links.txt| |--PKG-INFO| |--SOURCES.txt| `--top_level.txt|--dist| `--demo1-0.1-py2.7.egg`--setup.py 我们看到在 dist 目录中的就是生成的 egg 包，将其解压： 123456789101112unzip -l demo1-0.1-py2.7.eggArchive: demo1-0.1-py2.7.eggLength Date Time Name-------- ---- ---- ----1 03-22-16 23:29 EGG-INFO/dependency_links.txt177 03-22-16 23:29 EGG-INFO/PKG-INFO124 03-22-16 23:29 EGG-INFO/SOURCES.txt1 03-22-16 23:29 EGG-INFO/top_level.txt1 03-22-16 23:29 EGG-INFO/zip-safe-------- -------304 5 files 以上的程序是最简单的一个 setup.py 程序，如果想要发布到 PyPI 就需要参考官方给出的示例： 12345678910111213141516171819202122232425262728from setuptools import setup, find_packagessetup(name = "HelloWorld",version = "0.1",packages = find_packages(),scripts = ['say_hello.py'],# Project uses reStructuredText, so ensure that the docutils get# installed or upgraded on the target machineinstall_requires = ['docutils&gt;=0.3'],package_data = &#123;# If any package contains *.txt or *.rst files, include them:'': ['*.txt', '*.rst'],# And include any *.msg files found in the 'hello' package, too:'hello': ['*.msg'],&#125;,# metadata for upload to PyPIauthor = "Me",author_email = "me@example.com",description = "This is an Example Package",license = "PSF",keywords = "hello world example examples",url = "http://example.com/HelloWorld/", # project home page, if any# could also include long_description, download_url, classifiers, etc.) 给包中添加内容我们上边生成的 egg 是一个空的，没有实际的内容，现在我们来添加一些内容： 在项目目录新建一个目录： 12mkdir testcd test 新建 __init__.py,加入如下代码： 1234567#-*- coding:utf-8 -*-def test():print "hello world!" if __name__ == '__main__':test() 再次生成 egg 包： 1python setup.py bdist_egg 查看 egg 包内容： 12345678910111213unzip -l demo1-0.1-py2.7.eggArchive: demo1-0.1-py2.7.eggLength Date Time Name-------- ---- ---- ----1 03-22-16 23:51 EGG-INFO/dependency_links.txt177 03-22-16 23:51 EGG-INFO/PKG-INFO141 03-22-16 23:51 EGG-INFO/SOURCES.txt5 03-22-16 23:51 EGG-INFO/top_level.txt1 03-22-16 23:51 EGG-INFO/zip-safe102 03-22-16 23:48 test/__init__.py354 03-22-16 23:51 test/__init__.pyc-------- -------781 7 files 我们看到其中已经多了 test 目录和 __init__.py,然后我们就可以尝试安装一下我们自己的包： 1sudo python setup.py install 然后该包就会安装到 Python 的 site-packages 目录下，在我的电脑上为 /Library/Python/2.7/site-packages/demo1-0.1-py2.7.egg 这时我们可以在 Python 终端测试我们的包： 123456Python 2.7.10 (default, Oct 23 2015, 18:05:06)[GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.5)] on darwinType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; import test&gt;&gt;&gt; test.test()hello world! 我们看到我们编写的包已经成功运行！ 0x02 总结这篇文章主要介绍了一下 setuptools 是什么，以及它的功能和特点，并且介绍了如何使用它来创建和安装使用自己的包，这篇文章仅仅讲了最基本的功能和用法，一些对于进阶的用法会在下篇文章中进行介绍。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 QT5 中使用 SQLITE]]></title>
    <url>%2F2016%2F03%2F14%2F%E5%9C%A8-QT5-%E4%B8%AD%E4%BD%BF%E7%94%A8-SQLITE%2F</url>
    <content type="text"><![CDATA[在我最近一直在做的有关 Kindle 批注管理软件的项目中，对于数据库我是用的是 SQLITE，在这篇文章中我会介绍一下 SQLITE 数据库，以及如何在 QT5 中使用它。 SQLITE 简介WHAT IS SQLITE？SQLite，是一款轻型的数据库，是遵守ACID的关系型数据库管理系统，它包含在一个相对小的C库中。它是D.RichardHipp建立的公有领域项目。它的设计目标是嵌入式的，而且目前已经在很多嵌入式产品中使用了它，它占用资源非常的低，在嵌入式设备中，可能只需要几百K的内存就够了。它能够支持Windows/Linux/Unix等等主流的操作系统，同时能够跟很多程序语言相结合，比如 Tcl、C#、PHP、Java等，还有ODBC接口，同样比起Mysql、PostgreSQL这两款开源的世界著名数据库管理系统来讲，它的处理速度比他们都快。 不像常见的客户-服务器范例，SQLite引擎不是个程序与之通信的独立进程，而是连接到程序中成为它的一个主要部分。所以主要的通信协议是在编程语言内的直接API调用。这在消耗总量、延迟时间和整体简单性上有积极的作用。整个数据库(定义、表、索引和数据本身)都在宿主主机上存储在一个单一的文件中。它的简单的设计是通过在开始一个事务的时候锁定整个数据文件而完成的。 （来自百度百科） WHY SQLITE？从 SQLITE 的用途来看，它是一款轻量级的数据库，并且一开始是设计给嵌入式设备的，我们知道 QT 其实现在也是在嵌入式方向应用的比较广泛，因此 QT 内置有 SQLITE 数据库的模块，因此我们能够比较容易上手。并且对于该项目使用文件形式的数据库更加灵活和轻便，更加符合这个项目的需求。 在 QT 中使用 SQLITE0x00 修改 .pro 文件为了能使用 SQLITE 我们必须在 QT 工程中的 .pro 文件中加入： 1QT += core gui sql 0x01 查看 QT 支持哪些数据库我们可以通过 QSqlDatabase::drivers() 方法来获取当前的 sql 模快中支持哪些数据库，以我的 QT5 为例： 1qDebug() &lt;&lt; QSqlDatabase::drivers(); 执行结果为： 1("QSQLITE", "QMYSQL", "QMYSQL3", "QODBC", "QODBC3", "QPSQL", "QPSQL7") 我们可以看到当前的 QT 是包含有 SQLITE 驱动的。 0x02 创建一个数据库连接我们来编写一个 connect() 函数： 12345678910bool connect(const QString &amp;dbName)&#123;QSqlDatabase db = QSqlDatabase::addDatabase("QSQLITE");db.setDatabaseName(dbName);if (!db.open()) &#123;qDebug() &lt;&lt; "Database Error!";return false;&#125;return true;&#125; 使用这个函数我们可以创建一个名称为 dbName 的 SQLITE 数据库。我们在 main 函数中测试一下： 1234567if(connect("test.db"))&#123;qDebug() &lt;&lt; "Database Create Sucessfully!";&#125;else&#123;qDebug() &lt;&lt; "Database Create Failed!";&#125; 我们会看到在工程编译后的目录中生成了一个 test.db 文件，并且控制台输出了： 1Database Create Sucessfully! 0x03 使用 SQL 语句在 QT 中我们通过一个QSqlQuery实例执行 SQL 语句： 1QSqlQuery query; 创建表我们创建一个名叫 student 的表，包含三列id, name, age: 123456if (!query.exec("CREATE TABLE student (""id INTEGER PRIMARY KEY AUTOINCREMENT,""name VARCHAR,""age INT)")) &#123;qDebug() &lt;&lt; "Create Table Failed!";&#125; 插入条目我们可以直接使用 query.exec() 来执行 INSERT 语句： 123if(!query.exec("INSERT INTO student (name, age) VALUES (\"TOM\", 10)"))&#123;qDebug() &lt;&lt; "INSERT Failed!";&#125; 也可以使用下面的形式来一次添加多个条目： 1234567891011query.prepare("INSERT INTO student (name, age) VALUES (?, ?)");QVariantList names;names &lt;&lt; "Tom" &lt;&lt; "Jack" &lt;&lt; "Jane" &lt;&lt; "Jerry";query.addBindValue(names);QVariantList ages;ages &lt;&lt; 20 &lt;&lt; 23 &lt;&lt; 22 &lt;&lt; 25;query.addBindValue(ages);if (!query.execBatch()) &#123;qDebug() &lt;&lt; "INSERT Failed!";&#125;query.finish(); 其它的语句都可以采用上面类似的方法进行实现，这里不再赘述。 这次我们使用 SQL 语句完成了对数据库的常规操作，包括简单的 CREATE、INSERT 等语句的使用。其实，Qt 不仅提供了这种使用 SQL 语句的方式，还提供了一种基于模型的更高级的处理方式。这种基于QSqlTableModel 的模型处理更为高级，如果对 SQL 语句不熟悉，并且不需要很多复杂的查询，这种QSqlTableModel模型基本可以满足一般的需求，以后我会介绍QSqlTableModel的一般使用。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>QT</tag>
        <tag>SQLITE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 字符串 String 内建函数大全(2)]]></title>
    <url>%2F2016%2F03%2F07%2FPython-%E5%AD%97%E7%AC%A6%E4%B8%B2-String-%E5%86%85%E5%BB%BA%E5%87%BD%E6%95%B0%E5%A4%A7%E5%85%A8-2%2F</url>
    <content type="text"><![CDATA[在上一篇文章中，我们提到了部分 Python 中字符串 string 的内建函数，这篇文章我们将继续介绍其他函数。 lower() 函数功能将字符串中的字母转换为小写 用法str.lower() 参数无 返回值字符串 示例代码123str = "HELLO WORLD!"print str.lower() 运行结果1hello world! lstrip() 函数功能把字符串左边的特定字符全部截取掉，默认字符为空格 用法str.lstrip([char]) 参数 chars: 被截取掉的字符 返回值返回截取后的字符串 示例代码12345str = " HELLO WORLD!"print str.lstrip()str = "!!!!!!Hello world!"print str.lstrip('!') 运行结果12HELLO WORLD!Hello world! maketrans() 函数功能将字符串中的一部分字符替换成另一部分 用法str.maketrans(intab, outtab) 参数 intab: 被替换的字符 outtab: 替换的字符 返回值返回替换规则 示例代码12345678from string import maketransstr = "abcdefghijk"intab = "acrgik"outtab = "123456"trans = maketrans(intab, outtab)print str.translate(trans) 运行结果11b2def4h5j6 max(str) 函数功能返回字符串中最大的字符 用法max(str) 参数无 返回值返回字符串中最大的字符 示例代码12345str = "abcdefghijk"print "MAX character: " + max(str)str = "123abc"print "MAX character: " + max(str) 运行结果12MAX character: kMAX character: c min 函数功能返回字符串中最小的字符 用法min(str) 参数无 返回值返回字符串中最大的字符 示例代码12345str = "abcdefghijk"print "MIN character: " + min(str)str = "123abc"print "MIN character: " + min(str) 运行结果12MIN character: aMIN character: 1 replace() 函数功能将字符串中的子字符串用某字符串来代替 用法str.replace(old, new[, max]) 参数 old: 被替换的子字符串 new: 替换后的字符串 max: 需要替换的个数 返回值返回替换后的字符串 示例代码1234str = "this is a string, this is a string"print str.replace("is", "was")print str.replace("is", "was", 2) 运行结果12hwas was a string, thwas was a stringthwas was a string, this is a string split() 函数功能分割字符串 用法str.split(str=&quot; &quot;, num=string.cout(str)) 参数 str: 分隔符，默认是空格 num: 分割的次数，默认为按照分隔符分割整个字符串 返回值返回分割后的 list 示例代码12345str = "word1 word2 word3 word4"print str.split();print str.split('r')print str.split(' ', 2) 运行结果123['word1', 'word2', 'word3', 'word4']['wo', 'd1 wo', 'd2 wo', 'd3 wo', 'd4']['word1', 'word2', 'word3 word4'] splitlines() 函数功能将字符串按行分割 用法str.splitlines(num=string.count(&#39;\n&#39;)) 参数 num: 该数值如果不为0，表示分割后的字符串中保留\n 返回值返回分割后的 list 示例代码12345str = "line1\nline2\nline3\nline4"print str.splitlines();print str.splitlines(0);print str.splitlines(2) 运行结果123['line1', 'line2', 'line3', 'line4']['line1', 'line2', 'line3', 'line4']['line1\n', 'line2\n', 'line3\n', 'line4'] startswith() 函数功能判断字符串是否是以某子字符串开头 用法str.stratswith(str, start=0, end=len(str)) 参数 str: 被检查的子字符串 start: 检查的字符串的起始 index，默认为 str 的开始位置 end: 检查的字符串的结束 index，默认为 str 的终止位置 返回值如果字符串是否是以某子字符串开头，返回True；否则返回False 示例代码1234str = "hello world!"print str.startswith('hel')print str.startswith('hel',2,8) 运行结果12TrueFalse strip() 函数功能去除字符串两边的某字符 用法str.strip([char]) 参数 char: 需要去除的字符 返回值返回去除之后的字符串 示例代码123str = "!hello!!world!"print str.strip('!') 运行结果1hello!!world swapcase() 函数功能将字符串中的大小写字母转换 用法str.swapcase() 参数无 返回值返回转换后的字符串 示例代码123str = "Hello World!"print str.swapcase() 运行结果1hELLO wORLD! upper() 函数功能将字符串中的字母都转换成大写 用法str.upper() 参数无 返回值返回转换后的字符串 示例代码123str = "Hello World!"print str.upper() 运行结果1HELLO WORLD! 至此，我们在 Python 中常见的、常用的字符串内建函数就大概都介绍过了，如果以后我又想起来一些会继续往上边添加的~ 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 字符串 String 内建函数大全(1)]]></title>
    <url>%2F2016%2F03%2F02%2FPython-%E5%AD%97%E7%AC%A6%E4%B8%B2-String-%E5%86%85%E5%BB%BA%E5%87%BD%E6%95%B0%E5%A4%A7%E5%85%A8-1%2F</url>
    <content type="text"><![CDATA[关于 Python 的字符串处理相关的方法还是非常多的，由于我正在学习 Python，于是就把 Python 中这些混杂的用于 string 的函数总结出来，在自己忘记的时候便于查找，希望对于有类似需求的人有所帮助。 captalize() 函数功能将一个字符串的第一个字母大写 用法str.captalize() 参数无 返回值string 示例代码123str = "hello world!"print "str.capitalize(): ", str.capitalize() 运行结果1tr.capitalize(): Hello world! center(width, fillchar) 函数将字符串居中，居中后的长度为 width 功能将字符串居中，居中后的长度为 width 用法str.center(width[, fillchar]) 参数 width: 表示字符串总长度 fillchar: 使字符串居中所填充的字符，默认为空格 返回值返回填充字符后的字符串 示例代码1234str = "hello world!"print "str.center(20): ", str.center(20)print "str.center(20,'-'): ", str.center(20,'-') 运行结果12tr.center(20): hello world!str.center(20,'-'): ----hello world!---- count(str, start=0, end=len(string)) 函数功能返回该字符串中出现某字符串序列（或字符）的次数 用法str.count(sub, start=0, end=len(string)) 参数 sub: 被查找的字符串序列 start: 开始查找的索引位置，默认为字符串开始 end: 结束查找的索引位置，默认为字符串结束 返回值被查找的序列在字符串的查找位置中出现的次数 示例代码1234567str = "hello world! hello world!"sub = "o"print "str.count(sub): ", str.count(sub)sub = "hello"print "str.count(sub, 5) ", str.count(sub, 5) 运行结果12str.count(sub): 4str.count(sub, 5) 1 decode(encoding=’UTF-8’,errors=’strict’) 函数 &amp; encode(encoding=’UTF-8’,errors=’strict’)功能使用特定编码将字符串解码(decode)/编码(encode) 用法str.decode(encoding=&#39;UTF-8&#39;,errors=&#39;strict&#39;) str.encode(encoding=&#39;UTF-8&#39;,errors=&#39;strict&#39;) 参数 encoding: 使用的编码格式 errors: 设置不同的错误处理方法，其他选项有 ignore, replace, xmlcharrefreplace, backslashreplace 返回值编码/解码后的字符串 示例代码12345str = "hello world!"str = str.encode('base64', 'strict')print "Encoded str: ", strprint "Decoded str: ", str.decode('base64') 运行结果123Encoded str: aGVsbG8gd29ybGQhDecoded str: hello world! endswith(suffix, start=0, end=len(string)) 函数功能判断字符串是否是以某字符串结尾的 用法str.endswith(suffix, start=0, end=len(string)) 参数 suffix: 被查找的字符串 start: 字符串查找的起始位置，默认为字符串起始位置 end: 字符串查找的结束位置，默认为字符串结束位置 返回值如果字符串是以 suffix 结尾的返回 True, 否则返回 False 示例代码12345678str = "hello world!"suffix = "world!"print str.endswith(suffix)suffix = "llo"print str.endswith(suffix,0,4)print str.endswith(suffix,0,5) 运行结果123TrueFalseTrue expandstabs(tabsize=8) 函数功能提供自定义 tab(/t) 长度的方法，默认为8 用法str.expandtabs(tabsize=8) 参数 tabsize: 表示自定义 tab 的长度 返回值string 示例代码12345str = "hello\tworld!"print "Original str: " + strprint "Defalut expanded tab: " + str.expandtabs();print "Double expanded tab: " + str.expandtabs(16) 运行结果123Original str: hello world!Defalut expanded tab: hello world!Double expanded tab: hello world! find(str, start=0, end=len(string)) 函数功能在字符串的某指定位置查找某字符串 用法str.find(str, start=0, end=len(string)) 参数 str: 被查找的子字符串 start: 查找的起始位置，默认为字符串起始位置 end: 查找的结束位置，默认为字符串结束位置 返回值如果查找到，返回该子字符串的索引；未查找到，返回-1 示例代码123456str = "hello world!"str1 = "wo"print str.find(str1)print str.find(str1, 8) 运行结果126-1 index(str, start=0, end=len(string)) 函数功能功能上与 find() 相同，只是在未找到子字符串是抛出异常 用法str.index(str, start=0, end=len(string)) 参数同 find() 返回值如果查找到，返回该子字符串的索引；未查找到，抛出异常 示例代码123456str = "hello world!"str1 = "wo"print str.index(str1)print str.index(str1, 8) 运行结果123456Traceback (most recent call last): File "teststrmethods.py", line 6, in &lt;module&gt; print str.index(str1, 8)ValueError: substring not found isalnum() 函数功能判断该字符串是否只是字母数字组合 用法str.isalnum() 参数无 返回值如果该字符串是字母数字组合，返回 True,否则返回 False 示例代码1234567891011str = "helloworld"print str.isalnum()str = "hello world"print str.isalnum()str = "hello123"print str.isalnum()str = "hello123!"print str.isalnum() 运行结果1234TrueFalseTrueFalse isalpha() 函数功能判断该字符串是否是字母组合 用法str.isalpha() 参数无 返回值如果该字符串是字母组合，返回 True,否则返回 False 示例代码1234567891011str = "helloworld"print str.isalpha()str = "hello world"print str.isalpha()str = "hello123"print str.isalpha()str = "hello123!"print str.isalpha() 运行结果1234TrueFalseFalseFalse isdigit() 函数功能判断该字符串是否只包含数字 用法str.isdigit() 参数无 返回值如果该字符串只包含数字，则返回 True,否则返回 False 示例代码12345str = "hello123"print str.isdigit()str = "123456"print str.isdigit() 运行结果12FalseTrue islower() 函数功能判断该字符串中是否只是小写字母 用法str.islower() 参数无 返回值如果该字符串中只是小写字母，返回True,否则返回False 示例代码12345str = "hello wolrd!"print str.islower()str = "Hello Wolrd!"print str.islower() 运行结果12TrueFalse isspace() 函数功能判断该字符串是否只包含空格 用法str.isspace() 参数无 返回值如果该字符串只包含空格，返回True,否则返回False 示例代码12345str = " "print str.isspace()str = "Hello Wolrd!"print str.isspace() 运行结果12TrueFalse istitle() 函数功能检查该字符串中的单词是否首字母都大写 用法str.istitle() 参数无 返回值如果该字符串中的单词首字母都大写了，返回True,否则返回False 示例代码12345str = "Hello world!"print str.istitle()str = "Hello Wolrd!"print str.istitle() 运行结果12FalseTrue isupper() 函数功能判断该字符串中的字母是否都是大写 用法str.isupper() 参数无 返回值如果该字符串中的字母都是大写，返回True,否则返回False 示例代码12345str = "Hello world!"print str.isupper()str = "HELLO WORLD!"print str.isupper() 运行结果12FalseTrue join(seq) 函数功能用该字符串连接某字符序列(seq) 用法str.join(sequence) 参数 sequence: 被连接的字符序列 返回值返回连接之后的字符串 示例代码1234str = "-"sequence = ("hello", "world", "everyone", "!")print str.join(sequence) 运行结果1hello-world-everyone-! len(string) 函数功能得到该字符串的长度 用法len(str) 参数无 返回值返回该字符串长度 示例代码123str = "Hello world!"print "the length of str: ", len(str) 运行结果1the length of str: 12 ljust(width, fillchar=’ ‘)函数功能在字符串的右边填充字符使得字符串达到指定长度 用法str.ljust(width, fillchar=&#39; &#39;) 参数 width: 填充后的目标长度 fillchar: 用于填充的字符，默认为空格 返回值返回填充后的字符串 示例代码1234str = "Hello world"print str.ljust(15)print str.ljust(15,'!') 运行结果12Hello worldHello world!!!! 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编写带命令行参数的 Python 程序]]></title>
    <url>%2F2016%2F02%2F27%2F%E7%BC%96%E5%86%99%E5%B8%A6%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0%E7%9A%84-Python-%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[我们在安装一些 Python 程序的时候经常会输入这样的命令行语句 python setup.py install，从这条语句中我们可以看到 setup.py 是一个 Python 程序，但是其中的 install 又是什么呢？其实它就是这个 Python 程序的命令行参数。在这篇文章中我会和大家探讨 Python 程序中命令行参数的工作机制和如何去编写一个带命令行参数的 Python 程序。 Python 是如何识别出命令行参数的sys 模块在 Python 中，sys 模块是一个非常常用且十分重要的模块，通过模块中的 sys.argv 就可以访问到所有的命令行参数，它的返回值是包含所有命令行参数的列表(list)，下面我们通过程序来说明它的用法： 123456import sysprint 'Number of arguments:', len(sys.argv)print 'They are:', str(sys.argv) 运行以及结果： 123python ./test_argv.py arg0 arg1 arg2Number of arguments: 4They are: [&apos;./test_argv.py&apos;, &apos;arg0&apos;, &apos;arg1&apos;, &apos;arg2&apos;] 我们看到通过 sys.argv 我们可以获得运行 Python 程序中所有的命令行参数。 getopt 模块谈到 Python 的命令行参数，有一个模块是不得不提的，那就是 getopt,我们先来看一下这个函数： getopt.getopt(args, options[, long_options]) 我们先来看一下里面参数的含义： args: 表示的是要被处理的命令行参数列表（通常是通过上述的 sys.argv 获得的结果） options: 它表示的是命令行参数中的选项，通常是一个字母，就像我们在 Linux 中对于某个命令不熟悉时所使用的帮助选项-h一样。如果说该选项需要一个参数的话，需要在该字母后边加上一个冒号:,表示该选项需要一个参数（如果这句不明白可以看下边的示例程序） long_options: 它是一个可选的参数，表示的是选项的长格式，上边的options是短格式，长格式的选项的参数格式示例为--input=input.txt,具体如何使用，详见下边的示例程序。 编写一个带命令行的 Python 程序了解了 sys 模块和 getopt 模块，我们就可以来自己编写一个带有命令行的程序并且在该程序中，我们还使用了 getopt.GetoptError 来进行异常处理。代码如下： 1234567891011121314151617181920212223242526272829303132# -*- coding:utf-8 -*- import sys, getoptdef main(argv): inputfile = "" outputfile = "" try: # 这里的 h 就表示该选项无参数，i:表示 i 选项后需要有参数 opts, args = getopt.getopt(argv, "hi:o:",["infile=", "outfile="]) except getopt.GetoptError: print 'Error: test_arg.py -i &lt;inputfile&gt; -o &lt;outputfile&gt;' print ' or: test_arg.py --infile=&lt;inputfile&gt; --outfile=&lt;outputfile&gt;' sys.exit(2) for opt, arg in opts: if opt == "-h": print 'test_arg.py -i &lt;inputfile&gt; -o &lt;outputfile&gt;' print 'or: test_arg.py --infile=&lt;inputfile&gt; --outfile=&lt;outputfile&gt;' sys.exit() elif opt in ("-i", "--infile"): inputfile = arg elif opt in ("-o", "--outfile"): outputfile = arg print 'Input file : ', inputfile print 'Output file: ', outputfileif __name__ == "__main__": main(sys.argv[1:]) 运行结果： 123./test_arg.pyInput file :Output file: 123python ./test_arg.py -htest_arg.py -i &lt;inputfile&gt; -o &lt;outputfile&gt;or: test_arg.py --infile=&lt;inputfile&gt; --outfile=&lt;outputfile&gt; 123python ./test_arg.py -aError: test_arg.py -i &lt;inputfile&gt; -o &lt;outputfile&gt; or: test_arg.py --infile=&lt;inputfile&gt; --outfile=&lt;outputfile&gt; 123python ./test_arg.py -i in.txt -o out.txtInput file : in.txtOutput file: out.txt 123Cookies python ./test_arg.py --infile=in.txtInput file : in.txtOutput file: 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记 2016 MCM/ICM 难忘参赛经历]]></title>
    <url>%2F2016%2F02%2F07%2F%E8%AE%B0-2016-MCM-ICM-%E9%9A%BE%E5%BF%98%E5%8F%82%E8%B5%9B%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[『扬哥哥，要不要参加今年的数学建模美赛？』 『老罗，你要参加吗？』 『是啊，打算娱乐一下。』 就这样，我参加了今年的数学建模美赛。从决定参加到组队，一个月的时间，三个人，4 * 24 小时。 同学，你好这次在软件园见到老扬的时候，不同以往。黑直短发，围着围巾，一袭黑衣，只有身高如故。身旁一小伙伴，是我们另外的队友，拉着老扬的拉杆箱，就先姑且叫他老唐吧。 『 同学，你好。』 『嗯。』 老唐话不多，人很帅，个子也高，是我们这次建模队伍中的中流砥柱。他总让我想起一个小学时的好哥们，同样也是话不多，却对一切都”门儿清”。 老扬和老唐在路上唏嘘了一阵软件园的环境之后，就随我进了宿舍。每天看看论文，喝喝咖啡，有条不紊的准备着建模。快要过年的气氛被将要到来的数学建模比赛压得无影无踪。 选 E 题！比赛第一天早上，建模题目出来了。 一直话不多的老唐突然发话，『A、B 题需要比较专业的数学物理知识，MCM 里 C 题可以做做看』 于是我们就开始了在 CDEF 中进行审题，读题、讲解、分析，一番争论之后，最终确定了题目。 就选 E 题吧？ 恩，E 题。 好，E 题！ 就这样，四天时间我们开始了和各种国家统计局，各地水利局，以及官方给的 www.fao.org/nr/water/aquastat/data 打起了各种交道。 MATLAB、EXCEL、Python 都成了这次建模的主角。为了这一题，这 E 题我们不知道干了多少杯咖啡，搜了多少篇论文。 嗯，就是 E 题。 看我屌不？ 『看我屌不？』 『不看！』 我和老扬的这段对话就这样被玩了四天。 四天建模，有过欢笑，有过分歧，有过惊喜，有过意外。 但不论如何也是不看屌的。 也算是端过屎的交情了说起这次建模，最悲剧的人物算是老扬了。 其次悲剧的应该算是我了吧，可能不仅仅因为我端了老扬的屎。 建模第三天早上，老扬泡了一杯咖啡，加了点牛奶，遂一饮而尽。不料，牛奶过期，胃不适，吐之。扬痛不能忍，往医院，吾欲与其同往，遂去之。 到了医院之后，挂号排队，一个小时，医生说要化验，验屎验血。老扬取了血，又去厕所取了屎。 医生要从化验钵中取屎，老扬行动不便，吾遂端之。 扬曰： 『你和我也算是端过屎的交情了，以后你若是有端屎的需求，当万死不辞。』 哦，愿我被老扬温柔相待，安静端屎。 兄弟，再见最后一天，凌晨四点，论文发送至比赛举办方，上床睡了不到两个小时，宿管就开始在宿舍吹哨、敲门，催促我们快走。 睁着朦胧睡眼，收拾着行李，除了宿舍楼，回望我们住了这么多天的宿舍，让我们糟蹋得已不成样子。 拖着各自的行李箱，各回各家，各找各妈。 兄弟，再见。 再见，兄弟。 嗯。 ###附：2016 MCM/ICM E 题渣渣论文一篇]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 QT 中使用 libusb 检测 MAC 上的 USB 设备]]></title>
    <url>%2F2016%2F01%2F27%2F%E5%9C%A8-QT-%E4%B8%AD%E4%BD%BF%E7%94%A8-libusb-%E6%A3%80%E6%B5%8B-MAC-%E4%B8%8A%E7%9A%84-USB-%E8%AE%BE%E5%A4%87%2F</url>
    <content type="text"><![CDATA[最近在用 QT 做一个 MAC 上的 Kindle 批注管理软件，遇到的第一个问题就是检测 MAC 上连接的 USB 设备的状态。如果是在 Cocoa 进行开发，会有对应的系统 API 可供使用，但是由于我是在 QT 平台进行的开发，所以无形中加大了一点难度。就在这时，我发现了一个库：libusb libusb 介绍libusb 设计了一系列的外部API 为应用程序所调用，通过这些API应用程序可以操作硬件，从libusb的源代码可以看出，这些API 调用了内核的底层接口，和kernel driver中所用到的函数所实现的功能差不多，只是libusb更加接近USB 规范。使得libusb的使用也比开发内核驱动相对容易的多。（From: 百度百科） 0x00 下载 libusb在 libusb 项目主页（http://libusb.info）我们可以找到最新的源码，下载下来，并且解压。这里我下载的是 libusb-1.0.20.tar.bz2，把它解压出来。 0x01 安装 libusb1234cd libusb-1.0.20/./configuremakemake install 这时就已经在机器上编译安装完成了 libusb 0x02 运行示例程序12cd examples/make 然后我们看到在 examples/ 目录下多了几个可执行程序： listdevs：列出当前所有的 USB 设备 hotplugtest：USB 热插拔测试 dpfp_threaded：操作 U.are.U 4000b 指纹采集仪的 Demo dpfp：初始化 U.are.U 4000b 指纹采集仪 sam3u_benchmark：测试 Atmel SAM3U USB 主控的同步传输的性能的 Demo fxload：USB 固件操作 12345678910Usage: fxload [-v] [-V] [-t type] [-d vid:pid] [-p bus,addr] [-s loader] -i firmware -i &lt;path&gt; -- Firmware to upload -s &lt;path&gt; -- Second stage loader -t &lt;type&gt; -- Target type: an21, fx, fx2, fx2lp, fx3 -d &lt;vid:pid&gt; -- Target device, as an USB VID:PID -p &lt;bus,addr&gt; -- Target device, as a libusb bus number and device address path -v -- Increase verbosity -q -- Decrease verbosity (silent mode) -V -- Print program version xusb：USB 测试程序 123456789101112131415usage: /Users/jason/Downloads/libusb-1.0.20/examples/.libs/xusb [-h] [-d] [-i] [-k] [-b file] [-l lang] [-j] [-x] [-s] [-p] [-w] [vid:pid] -h : display usage -d : enable debug output -i : print topology and speed info -j : test composite FTDI based JTAG device -k : test Mass Storage device -b file : dump Mass Storage data to file 'file' -p : test Sony PS3 SixAxis controller -s : test Microsoft Sidewinder Precision Pro (HID) -x : test Microsoft XBox Controller Type S -l lang : language to report errors in (ISO 639-1) -w : force the use of device requests when querying WCID descriptors If only the vid:pid is provided, xusb attempts to run the most appropriate test 我们以 listdevs 为例，执行测试程序： 1./listdevs 执行结果： 123405ac:8406 (bus 20, device 3) path: 705ac:828f (bus 20, device 20) path: 3.30a5c:4500 (bus 20, device 27) path: 305ac:8005 (bus 20, device 0) 链接库在Windows平台、MAC 平台和Linux平台下都大量存在着库。本质上来说库是一种可执行代码的二进制形式，可以被操作系统载入内存执行。由于Windows、MAC和Linux的平台不同（主要是编译器、汇编器和连接器的不同），因此二者库的二进制是不兼容的。 Linux下的库有两种：静态库和共享库（动态库）。二者的不同点在于代码被载入的时刻不同。 静态库的代码在编译过程中已经被载入可执行程序，因此体积较大。 共享库的代码是在可执行程序运行时才载入内存的，在编译过程中仅简单的引用，因此代码体积较小。 创建静态链接库0x00 写一个静态链接库 hello.h 123456#ifndef HELLO_H #define HELLO_H void hello(const char *name); #endif hello.c 1234#include &lt;stdio.h&gt; void hello(const char *name) &#123; printf("Hello %s!\n", name); &#125; main.c 123456#include "hello.h" int main() &#123; hello("world"); return 0; &#125; 0x01 创建目标代码1gcc -c hello.c gcc 中 -c 的编译选项的意思是使用GNU汇编器将源文件转化为目标代码之后就结束，在这种情况下,只调用了C编译器（ccl）和汇编器（as），而连接器(ld)并没有被执行，所以输出的目标文件不会包含作为程序在被装载和执行时所必须的包含信息，但它可以在以后被连接到一个程序。 我们执行 ls 命令会看到目录下多了一个 hello.o 文件，它就是 hello.c 编译的目标代码 0x02 创建静态链接库1ar rcs libhello.a hello.o 创建静态库用ar命令。 静态库文件名的命名规范是以lib为前缀，紧接着跟静态库名，扩展名为.a。 例如：我们将创建的静态库名为hello，则静态库文件名就是libhello.a。在创建和使用静态库时，需要注意这点。 我们执行 ls 命令,可以看到目录下多了一个静态链接库 libhello.a 0x03 链接静态链接库静态库制作完了，如何使用它内部的函数呢？ 只需要在使用到这些公用函数的源程序中包含这些公用函数的原型声明，然后在用gcc命令生成目标文件时指明静态库名，gcc将会从静态库中将公用函数连接到目标文件中。 注意，gcc会在静态库名前加上前缀lib，然后追加扩展名.a得到的静态库文件名来查找静态库文件,因此，我们在写需要连接的库时，只写名字就可以，如libhello.a的库，只写: -lhello 1gcc -o main main.c -L. -lhello 执行程序 12./mainHello world! 创建动态链接库0x00 创建动态链接库1gcc -dynamiclib -o hello.dylib hello.o 我们使用 ls 命令可以看到目录下多了 hello.dylib,它就是创建的动态链接库（.dylib是 MAC 系统下的，Windows 下是.dll, Linux 下是.so） 0x00 链接动态链接库1gcc -o main1 main.c -L. -lhello 执行程序 12./main1Hello world! 在 QT 中使用 libusb0x00 将 libusb 动态链接库加入 QT 项目我们首先在 QT5 中新建一个项目 Testlibusb,然后在项目目录下新建一个目录 lib 用来存放 libusb 的库文件。 将 libusb 对应的库文件复制到该目录下，因为我所使用的平台是 MAC OS X，所对应的库文件应当是以 .dylib 为扩展名的，我们在 libusb 源码文件夹下的 /libusb/.libs/ 目录下找到 libusb-1.0.0.dylib 然后复制到刚刚创建的目录下 并且将 libusb 的头文件 libusb.h 加入到项目中 0x01 修改 QT 项目编译选项修改 QT 项目中的 .pro 文件，加入下面几行： 12345macx: LIBS += -L$$PWD/lib/ -lusb-1.0.0INCLUDEPATH += $$PWD/.DEPENDPATH += $$PWD/. 0x02 编写 libusb 测试程序 getusbinfo.h 1234567891011121314151617181920212223242526272829303132#ifndef GETUSBINFO#define GETUSBINFO#include &lt;QString&gt;#include &lt;QObject&gt;#include &lt;QList&gt;#include &lt;QThread&gt;#include &lt;libusb.h&gt;struct STUUSBDevices&#123; QString idProduct; QString idVendor; QString iManufacturer; QString iSerialNumber;&#125;;class GetUsbInfo : QThread&#123;public: GetUsbInfo(QObject *parent); ~GetUsbInfo(); int initUsbDevices(); QString getVidPid(libusb_device **devs); void showAllUsbDevices(QList&lt;STUUSBDevices&gt; lst); void setRunStatus(); void run(); bool isStop;&#125;;#endif // GETUSBINFO getusbinfo.cpp 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#include "getusbinfo.h"#include &lt;QThread&gt;#include &lt;QDebug&gt;#include &lt;QString&gt;GetUsbInfo::GetUsbInfo(QObject *parent) : QThread(parent),isStop(false)&#123;&#125;GetUsbInfo::~GetUsbInfo()&#123; qDebug()&lt;&lt;"GetUsbInfo::~GetUsbInfo "&lt;&lt;endl;&#125;int GetUsbInfo::initUsbDevices()&#123; libusb_device **devs; int r; ssize_t cnt; r = libusb_init(NULL); if (r &lt; 0) return r; cnt = libusb_get_device_list(NULL, &amp;devs); if (cnt &lt; 0) return (int) cnt; getVidPid(devs); libusb_free_device_list(devs, 1); libusb_exit(NULL); return 0;&#125;QString GetUsbInfo::getVidPid(libusb_device **devs)&#123; libusb_device *dev; int i = 0; QList&lt;STUUSBDevices&gt; lstUsb; while ((dev = devs[i++]) != NULL) &#123; struct libusb_device_descriptor desc; int r = libusb_get_device_descriptor(dev, &amp;desc); if (r &lt; 0) &#123; qDebug()&lt;&lt;"failed to get device descriptor"&lt;&lt;stderr; return ""; &#125; printf("%04x:%04x (bus %d, device %d)\n", desc.idVendor, desc.idProduct, libusb_get_bus_number(dev), libusb_get_device_address(dev)); STUUSBDevices stu; stu.idProduct = QString::number(desc.idProduct); stu.idVendor = QString::number(desc.idVendor); stu.iManufacturer = QString::number(desc.iManufacturer); stu.iSerialNumber = QString::number(desc.iSerialNumber); lstUsb.append(stu); &#125; showAllUsbDevices(lstUsb); return QString(lstUsb[0].idProduct);&#125;void GetUsbInfo::showAllUsbDevices(QList&lt;STUUSBDevices&gt; lst)&#123; for(int i=0;i&lt;lst.count();i++) &#123; qDebug()&lt;&lt;"vid: "&lt;&lt;lst.at(i).idVendor&lt;&lt;"\n" &lt;&lt;"pid:"&lt;&lt;lst.at(i).idProduct&lt;&lt;"\n" &lt;&lt;"serNumber:"&lt;&lt;lst.at(i).iSerialNumber&lt;&lt;"\n" &lt;&lt;"Manufacturer:"&lt;&lt;lst.at(i).iManufacturer&lt;&lt;"\n"; &#125;&#125;void GetUsbInfo::setRunStatus()&#123; isStop = true;&#125;void GetUsbInfo::run()&#123; qDebug()&lt;&lt;"GetUsbInfo::run() "&lt;&lt;endl; while (!isStop) &#123; initUsbDevices(); sleep(10); &#125;&#125; main.cpp 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include "mainwindow.h"#include &lt;QApplication&gt;#include "getusbinfo.h"#include &lt;QLibrary&gt;int main(int argc, char *argv[])&#123; QApplication a(argc, argv); MainWindow w; w.show(); QThread t; GetUsbInfo info(&amp;t); info.initUsbDevices(); return a.exec();&#125;``` ## 0x03 执行 libusb 测试程序```bashStarting /Users/jason/Project/QTDemos/build-Testlibusb-Desktop_Qt_5_5_1_clang_64bit-Debug/Testlibusb.app/Contents/MacOS/Testlibusb...vid: "1452" pid: "33798" serNumber: "5" Manufacturer: "3" vid: "1452" pid: "33423" serNumber: "0" Manufacturer: "1" vid: "2652" pid: "17664" serNumber: "0" Manufacturer: "1" vid: "1452" pid: "32773" serNumber: "0" Manufacturer: "0" 最终我们获得了当前 MAC 上的 USB 设备列表 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>QT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序的语法]]></title>
    <url>%2F2016%2F01%2F17%2F%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[『我不生产代码，我只是代码的搬运工。』当然了，这是一个玩笑。说到代码，我们要学习各种编程语言，学习如何让编译器能懂我们编写的代码。但是，编译器是如何做到能听懂我们的话的呢？按照我们既定的语句一行行的去执行，最终达到我们的目的。这篇文章，我会讲一个很简单的四则运算解释器，通过使用 Python 实现它来一步步了解一个解释器是如何工作的，它们又是怎么得到我们想要的结果的。 #语法 计算机语言同样也是一种语言，是一种计算机能够理解的语言，我们想要和计算机对话，就要去学习这种语言。和我们人类的语言一样，计算机语言也是有语法的。以汉语为例，我说『我是中国人』，因为汉语的语法，你听到这句话之后会知道『我』是主语，『是』是谓语，『中国人』是宾语，同时你又很清楚每一个成分的含义，最终理解了整句话的意思。 同样，对于计算机语言也是一样，有着程序的语法，一个解释器知道哪个词是操作数，哪个是操作符，哪个是关键字，它们都有着怎样的含义和功能，通过解释器的解释，计算机明白了某行语句的意义，然后进行运算，得到最后的执行结果。 #语法图 语法图就是用来表示一种编程语言语法规则设计的示意图，它很直观的显示出了在一种编程语言中，允许使用的语句和不支持的语句。语法图十分易于阅读：只需跟随箭头指示的路径。一些路径表示选择。另一些路径表示循环。 ##一个简单的语法图 这里我们举一个语法图的例子： 这个语法图就是一个描述了简单的加减运算的语法图，term 在其中的意思就是一个操作数，一开始输入一个操作数，有三条路径可以选择『+』，『-』和退出，如果进入了『+』、『-』路径，则需要再输入一个操作数，之后的路径包括『+』、『-』和退出，如此循环，就能解释一个简单的加减法解释器。 根据上边的语法图，下面的表达式都是合法的： 4 1 + 1 1 + 4 - 3 下面的表达式不合法： - + - 2 + + 3 - 3 语法图可以帮助我们： 用图的方式表示出一种计算机语言的设计规范 可以帮助理解解释器，将图表表示成代码 ##代码实现（Python） 学习一样东西最简单的就是阅读代码（Read the Fucking Code！），因此我们先来看完整代码然后再来分析一下，完整代码在：https://github.com/luoyhang003/Pascal-Interpreter/blob/master/calc3.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159# Token Types:# EOF: End-Of-FileINTEGER, PLUS, MINUS, EOF = 'INTEGER', 'PLUS', 'MINUS', 'EOF'class Token(object): def __init__(self, type, value): # Token types: INTEGER, PLUS, MINUS, EOF self.type = type # Token value: 0,1,2,3,4,5,6,7,8,9,+,None self.value = value def __str__(self): """ The format of the print infomation For examle: Token(INTEGER, 3) Token(PLUS, '+') Token(MINUS, '-') """ return 'Token(&#123;type&#125;,&#123;value&#125;)'.format( type = self.type, value = repr(self.value) ) def __repr__(self): return self.__str__() class Interpreter(object): def __init__(self, text): # Process the whole input # e.g. 3+5 self.text = text self.pos = 0 self.current_token = None self.current_char = self.text[self.pos] def error(self): raise Exception('Error Parsing Error!') def advance(self): # Advance the pos and set current_char self.pos += 1 if self.pos &gt; len(self.text)-1: self.current_char = None else: self.current_char = self.text[self.pos] def skip_whitespace(self): # Skip space while self.current_char is not None and self.current_char.isspace(): self.advance() def integer(self): # Support mutidigit integer result = '' while self.current_char is not None and self.current_char.isdigit(): result += self.current_char self.advance() return int(result) def get_next_token(self): """ Lexical Analyzer: Parsing the input into tokens. Strategy: 1. is pos past the end of the text? 2. if so, return EOF 3. get a character at pos, and decide its type depends on the single char 4. if it is a space, advance the pos 5. if it is a digit, then convert it to integer and return INTEGER token 6. if it is a '+', then return PLUS token 7. if it is a '-', then return MINUS token """ while self.current_char is not None: if self.pos &gt; len(self.text) - 1: return Token(EOF, None) current_char = self.text[self.pos] if current_char.isspace(): self.skip_whitespace() continue if current_char.isdigit(): return Token(INTEGER, self.integer()) if current_char == '+': self.advance() return Token(PLUS, '+') if current_char == '-': self.advance() return Token(MINUS, '-') self.error() return Token(EOF, None) def eat(self, token_type): # compare the current token with the passed token type # if they match then eat the current token and assign next token to the self.current_token # otherwise raise an Exception if self.current_token.type == token_type: self.current_token = self.get_next_token() else: self.error() def term(self): # return an Integer Token's value token = self.current_token self.eat(INTEGER) return token.value def expr(self): # expr -&gt; INTEGER PLUS INTEGER # expr -&gt; INTEGER MINUS INTEGER self.current_token = self.get_next_token() result = self.term() while self.current_token.type in (PLUS, MINUS): token = self.current_token if token.type == PLUS: self.eat(PLUS) result += self.term() if token.type == MINUS: self.eat(MINUS) result -= self.term() return result def main(): while True: try: text = raw_input('cal&gt; ') except EOFError: break if not text: continue interpreter = Interpreter(text) result = interpreter.expr() print(result)if __name__ == '__main__': main() 在代码中，我们首先定义了四种 Token：整数（Integer）、加法（+）、减法（-）、终止符（EOF） 代码中主要分为几个主要部分： term 方法，在表达式中解析出一个整数 12345def term(self): # return an Integer Token's value token = self.current_token self.eat(INTEGER) return token.value expr 方法，根据语法图的流程来解析语句 123456789101112131415161718def expr(self): # expr -&gt; INTEGER PLUS INTEGER # expr -&gt; INTEGER MINUS INTEGER self.current_token = self.get_next_token() result = self.term() while self.current_token.type in (PLUS, MINUS): token = self.current_token if token.type == PLUS: self.eat(PLUS) result += self.term() if token.type == MINUS: self.eat(MINUS) result -= self.term() return result expr 方法，首先调用 term 方法获取一个整数，然后判断后边的 Token 是加法还是减法，之后再获取一个整数，然后进行运算，然后判断之后还有没有运算符，如果没有就返回结果，如果还有就重复以上步骤。我们看到 expr 方法是严格按照语法图进行解释的。 ##执行结果 123456789101112131415161718192021cal&gt; 1+23cal&gt; 1+4-32cal&gt; 1+ 5 -60cal&gt; 1 +Traceback (most recent call last): File &quot;calc3.py&quot;, line 176, in &lt;module&gt; main() File &quot;calc3.py&quot;, line 172, in main result = interpreter.expr() File &quot;calc3.py&quot;, line 155, in expr result += self.term() File &quot;calc3.py&quot;, line 136, in term self.eat(INTEGER) File &quot;calc3.py&quot;, line 131, in eat self.error() File &quot;calc3.py&quot;, line 54, in error raise Exception(&apos;Error Parsing Error!&apos;)Exception: Error Parsing Error! #文法 文法是另一种被广泛使用的、用于指定一种程序设计语言语法的表示法，它叫做『上下文无关文法』，简称文法。 为什么要使用文法？ 文法以更简明的方式说明一种程序设计语言的语法。比起来语法图，文法十分简洁。 文法可以用作很好的文档 文法可以非常方便的转换成代码（非常方便~） ##文法原理 我们以『3 4 / 5 2』这样的算数乘除表达式为例，它对应的文法表达式为： expr: factor ((MUL | DIV) factor)* factor: INTEGER 一段文法由一系列的规则（rule）组成，在上述文法中，我们有两条规则：expr: factor ((MUL | DIV) factor)* 和factor: INTEGER 一条规则由由一个非终结符（称规则的头或者左边）、一个冒号：、一系列终结符非终结符（称规则的主体或者右边）组成 分析以上文法： expr、factor这样的变量叫做非终结符 MUL、DIV、Integer这样的标记称为终结符 | 表示『或』，多选一。(MUL | DIV)表示要么 MUL（乘）要么 DIV（除） ( ) 一对圆括号表示把终结符非终结符组合起来，就像 (MUL | DIV) 一样 ( )* 表示匹配组合里面的内容 0 次或者多次，就像 while 循环 解释一下 expr 规则：expr 可以是一个 factor 可选地接着一个乘法或者除法运算符，再接着另一个 factor，依次可选地接着一个乘法或者除法运算符，再接着另一个 factor…… 现在我们以解释『3 4 / 5 2』这样的算数乘除表达式为例： 1234567exprfactor ((MUL | DIV) factor)*factor MUL factor ((MUL | DIV) factor)*factor MUL factor DIV factor ((MUL | DIV) factor)*factor MUL factor DIV factor MUL factorINTEGER MUL INTEGER DIV INTEGER MUL INTEGER 3 * 4 / 5 * 2 ##将文法映射称为为代码 对于文法中定义的每一条规则 R，都可以在代码中变成同名的方法 R() 对于多个可选项 ( | ) 可以编程为 if-else 语句 可选的 ( )* 集合编程称为 while 语句，表示可以循环 0~n 次 因此，上述文法用代码表示出来就是： factor 方法 123456def factor(self): # return an Integer Token's value # factor: Integer token = self.current_token self.eat(INTEGER) return token.value expr 方法 123456789101112131415161718def expr(self): # Arithmetic expression parser # expr: factor( (MUL | DIV) factor)* # factor: Integer result = self.factor() while self.current_token.type in (MUL, DIV): token = self.current_token if token.type == MUL: self.eat(MUL) result = result * self.factor() elif token.type == DIV: self.eat(DIV) result = result / self.factor() return result ##扩充我们的文法 ###加入加减运算 因为，我们加入了加减运算，因此现在存在运算优先级问题，很显然乘除运算优先级要高于加减运算 我们得到以下的优先级表格： 操作符 优先级 结合性 + - 2 左结合 * / 1 左结合 根据优先级表格构建文法： 为每个优先级定义一个非终结符。非终结符所在产生式的主体应该包含同等级的算术运算符和优先级高一级的非终结符 为表达式创建一个额外的非终结符 factor 作为基本单位，在我们的例子中该基本单位是整数。通用的规则是如果你有 N 层优先级，那么你总共需要 N + 1 个非终结符：每层优先级需要一个非终结符，加上一个用作表达式基本单位的非终结符。 更新我们的文法： expr: term ((PLUS | MINUS) term)* term: factor ((MUL | DIV) factor)* factor: INTEGER ###加入括号表达式 在之前，我们的基本单位只有 INTEGER，这次我们加入括号表达式。 更新后的文法为： expr: term ((PLUS | MINUS) term)* term: factor ((MUL | DIV) factor)* factor: INTEGER | LPAREN expr RPAREN LPAREN 表示左括号，RPAREN 表示右括号 括号表达式内的非终结符 expr 表示 expr 规则 下面我们以『 3 * （1 + 5）』为例，来说明该文法是如何工作的： ##最终的四则运算解释器 完整代码见：https://github.com/luoyhang003/Pascal-Interpreter/blob/master/calc6.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201# Token Types:# EOF: End-Of-FileINTEGER, PLUS, MINUS, MUL, DIV, LPAREN, RPAREN, EOF = ( 'INTEGER', 'PLUS', 'MINUS', 'MUL', 'DIV', '(', ')', 'EOF')class Token(object): def __init__(self, type, value): # Token types: INTEGER, PLUS, MINUS, MUL, DIV, EOF self.type = type # Token value: 0,1,2,3,4,5,6,7,8,9,,+,-,*,/,None self.value = value def __str__(self): """ The format of the print infomation For examle: Token(INTEGER, 3) Token(PLUS, '+') Token(MINUS, '-') TOKEN(MUL, '*') TOEKN(LPAREN, ')') """ return 'Token(&#123;type&#125;,&#123;value&#125;)'.format( type = self.type, value = repr(self.value) ) def __repr__(self): return self.__str__() class Lexer(object): def __init__(self, text): # Process the whole input # e.g. 3+ 5 * 2 - 4/2 self.text = text self.pos = 0 self.current_char = self.text[self.pos] def error(self): raise Exception('Invalid character!') def advance(self): # Advance the pos and set current_char self.pos += 1 if self.pos &gt; len(self.text)-1: self.current_char = None else: self.current_char = self.text[self.pos] def skip_whitespace(self): # Skip space while self.current_char is not None and self.current_char.isspace(): self.advance() def integer(self): # Support mutidigit integer result = '' while self.current_char is not None and self.current_char.isdigit(): result += self.current_char self.advance() return int(result) def get_next_token(self): """ Lexical Analyzer: Parsing the input into tokens. Strategy: 1. dictate current char 2. if it is a space, advance the pos 3. if it is a digit, then convert it to integer and return INTEGER token 4. if it is a '+', then return PLUS token 5. if it is a '-', then return MINUS token 6. if it is a '*', then return MUL token 7. if it is a '/', then return DIV token 8. if it is a '(', then return LPAREN token 9. if it is a ')', then return RPAREN token """ while self.current_char is not None: if self.current_char.isspace(): self.skip_whitespace() continue if self.current_char.isdigit(): return Token(INTEGER, self.integer()) if self.current_char == '+': self.advance() return Token(PLUS, '+') if self.current_char == '-': self.advance() return Token(MINUS, '-') if self.current_char == '*': self.advance() return Token(MUL, '*') if self.current_char == '/': self.advance() return Token(DIV, '/') if self.current_char == '(': self.advance() return Token(LPAREN, '(') if self.current_char == ')': self.advance() return Token(RPAREN, ')') self.error() return Token(EOF, None)class Interpreter(object): def __init__(self, lexer): self.lexer = lexer self.current_token = self.lexer.get_next_token() def error(self): raise Exception('Invalid Syntax') def eat(self, token_type): # compare the current token with the passed token type # if they match then eat the current token and assign next token to the self.current_token # otherwise raise an Exception if self.current_token.type == token_type: self.current_token = self.lexer.get_next_token() else: self.error() def factor(self): # factor: Integer | LPAREN expr RPAREN token = self.current_token if token.type == INTEGER: self.eat(INTEGER) return token.value if token.type == LPAREN: self.eat(LPAREN) result = self.expr() self.eat(RPAREN) return result def term(self): # term: factor( (MUL | DIV) factor)* # factor: Integer result = self.factor() while self.current_token.type in (MUL, DIV): token = self.current_token if token.type == MUL: self.eat(MUL) result = result * self.factor() elif token.type == DIV: self.eat(DIV) result = result / self.factor() return result def expr(self): # expr: term( (PLUS | MINUS) term)* # term: factor( (MUL | DIV) factor)* # factor: Integer result = self.term() while self.current_token.type in (PLUS, MINUS): token = self.current_token if token.type == PLUS: self.eat(PLUS) result = result + self.term() elif token.type == MINUS: self.eat(MINUS) result = result - self.term() return resultdef main(): while True: try: text = raw_input('cal&gt; ') except EOFError: break if not text: continue lexer = Lexer(text) interpreter = Interpreter(lexer) result = interpreter.expr() print(result)if __name__ == '__main__': main() ##运行结果 12345678910cal&gt; 1+12cal&gt; 1*33cal&gt; 1+3*310cal&gt; 5*(1+5)30cal&gt; (5+6)/(3-1)*210 #参考资料 Python Cookbook(第3版) Ruslan’s Blog 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【数学模型】商人们怎样过河？]]></title>
    <url>%2F2016%2F01%2F06%2F%E3%80%90%E6%95%B0%E5%AD%A6%E6%A8%A1%E5%9E%8B%E3%80%91%E5%95%86%E4%BA%BA%E4%BB%AC%E6%80%8E%E6%A0%B7%E8%BF%87%E6%B2%B3%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[这篇博文中，同样是一个很简单的数学问题，但是解决起来比上一个的问题要复杂一些。在这次模型求解中，我会使用两种方法，一种是纯粹的数学方法，另一种是通过计算机程序来计算，通过计算机求解我们可以求解一些规模更大的问题。由于这篇文章篇幅我预计会比较长，为了不混淆，上一篇文章《椅子能在不平的地面上放平吗？》中的延伸问题我会再写一篇文章单独解答。 #问题引出 问题： 三名商人各带一个随从过河，一只小船只能容纳两个人，随从们约定，只要在河的任何一岸，一旦随从人数多于商人人数就杀人越货，但是商人们知道了他们的约定，并且如何过河的大权掌握在商人们手中，商人们该采取怎样的策略才能安全过河呢？ 这次的问题是一个很经常遇到的过河问题，其实对于该类问题，我们经过逻辑思考就可以得到答案。但是通过数学模型的建立，我们可以得到一个通用的解答，并且通过计算机的计算我们可以大大扩大问题的规模。 #问题分析 因为这个问题已经理想化了，所以我们无需对模型进行假设，该问题可以看作一个多步决策问题。 每一步，船由此岸划到彼岸或者由彼岸划回此岸，都要对船上的人员进行决策（此次渡河船上可以有几名商人和几名随从），在保证安全（两岸的随从都不比商人多）的前提下，在有限次的决策中使得所有人都到对岸去。 因此，我们要做的就是要确定每一步的决策，达到渡河的目标。 #建立模型 记第 k 次过河前此岸的商人数为 xk , 随从数为 yk , k = 1, 2, 3…, xk ,yk = 0, 1, 2, 3 定义状态： 将二维向量 sk = ( xk , yk ) 定义为状态 将安全渡河状态下的状态集合定义为允许状态集合， 记为 S = {(x,y) | x=0,y=0,1,2,3; x=y=1; x=y=2; x=3,y=0,1,2,3} 记第 k 次渡河船上的商人数为 uk ， 随从数为 vk 定义决策： 将二维向量 dk = (uk , vk) 定义为决策 允许决策集合 记作 D = {(u,v) | 1 &le; u+v &le; 2, u,v = 0,1,2} 因为小船容量为2，所以船上人员不能超过2，而且至少要有一个人划船，由此得到上式。 由我们定义的状态 sk 和决策 dk ，我们可以发现它们之间是存在联系的： k 为奇数是表示船由此岸划向彼岸，k 为偶数时表示船由彼岸划回此岸 状态 sk 是随着决策 dk 变化的，规律为： sk+1 = sk + (-1)kdk 我们把上式称为状态转移律，因此渡河方案可以抽象为如下的多步决策模型： 求决策 dk &isin; D(k = 1,2,…,n) , 使状态 sk &isin; S 按照转移率，初始状态 s1 = (3,3) 经有限步 n 到达状态 sn+1 = (0,0) 到这里，整个数学模型就已经非常清晰了，接下来要做的就是求解模型得出结果。 #求解模型 在这个模型的求解中，我将会使用两种方法，一种是数学图解法，用于解决和当前题目一样的规模比较小的问题，优点是比较简便，但是对于规模比较大的问题就无能为力了，比如说有50个商人携带50个随从过河，第二种方法是通过计算机编程，使用程序来解决该问题，即使问题规模增大，我们也可以利用计算机强大的计算能力来解决。 数学图解法我们首先在 xOy 平面坐标系中画出如下方格，方格中的点表示状态 s = (x,y) 起始状态（下图绿色点） s1 = (3,3) , 终止状态（下图红色点） sn+1 = (0,0) 允许决策 dk 表示的是在方格中的移动，根据允许决策 dk 的定义，它每次的移动范围为1~2格，并且 k 为奇数时向左或下方或左下方移动，k 位偶数时向右或上方或右上方移动。 于是，这个问题就变成了，根据允许决策 dk ，在方格中在状态（方格点）之间移动，找到一条路径，使得能从起始状态（上图绿色点） s1 = (3,3) ,到达终止状态（上图图红色点） sn+1 = (0,0) 在下图中，我们给出了一种方案，我们可以很清楚的看到该方案绝对不是最佳方案（渡河次数最少），它只是给出了一种方案，而且我们看来是一种极其不优化的方案，但是可以很清楚地看出图解法是如何工作的。 根据上图，我们得出的方案如下： d1：两个随从划到对岸 d2：一个随从划回来 d3：两个随从划到对岸 d4：一个随从划回来 d5：两个商人划到对岸 d6：一个商人和一个随从划回来 d7：两个商人划到对岸 d8：一个随从划回来 d9：两个随从划到对岸 d10：一个商人划回来 d11：一个商人和随从划到对岸 最终商人们安全渡河 ##程序求解 我们看到上面介绍的图解法对于小规模问题很直观也很简单，但是无法应对大规模的问题，于是我们采用编程的方法来再次解决上述问题，这次我使用的编程语言为Python. ###创建允许状态集合 对于允许状态集合，我们要去使用算法对其进行计算，所谓允许状态无非就是，河岸两边的商人们都是安全的： 一种情况是：两岸的商人人数都比随从人数多（对于随从和商人人数相同的情况就是河的任一岸，商人人数等于随从人数） 另一情况为：所有商人都在河的任何一岸，此时另一岸没有任何商人，对于随从的人数在河的任一岸的数量不论是多少，此时都是安全的 按照以上方法编程如下： 123456789101112'''创建允许状态集合''' def allowset(self): allowset = [] for i in range(self.merchants + 1): for j in range(self.servants + 1): if i == 0: allowset.append([i,j]) elif i == self.merchants: allowset.append([i,j]) elif (i &gt;= j and ((self.merchants-i) &gt;= (self.servants-j))): allowset.append([i,j]) return allowset ###创建允许决策集合 对于创建允许决策集合，它和船的容量是相关的，只要每次渡河的商人数量和随从数量小于等于船的容量即可，代码如下： 12345678'''创建允许决策集合'''def allowaction(self): allowactionset = [] for i in range(self.capacity + 1): for j in range(self.capacity + 1): if (i+j) &lt;= self.capacity and (i + j) != 0: allowactionset.append([i,j]) return allowactionset ###如何渡河 对于如何渡河问题我采取的是一种随机的方法，对于当前安全状态，随机选择一种决策进行试探，如果采取该决策可以到达安全状态，则采用，如此循环，直到到达目的地。如果采取该策略不能到达安全状态，则再次随机选择一种策略。 代码如下： 12345678910111213def solve(self,allowactionset,allowstate): count = 1; current = (self.merchants,self.servants) while current != [0,0]: move = allowactionset[random.randint(0,len(allowactionset)-1)] temp = [current[0]+((-1)**count)*move[0],current[1]+((-1)**count)*move[1]] if(temp in allowstate): current = [current[0]+((-1)**count)*move[0],current[1]+((-1)**count)*move[1]] if(count % 2 == 1): print "[%d]个商人，[%d] 个随从从此岸划到对岸" %(move[0],move[1]) elif(count % 2 == 0): print "[%d]个商人，[%d] 个随从从对岸划回此岸" %(move[0],move[1]) count = count + 1 ###完整代码有了以上算法之后，我们就可以使用计算机来解决一些较大规模的问题了，完整代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# -*- coding: utf-8 -*-# Copyright (c) 2015 Jason Luo @ SDU"""解决商人安全过河问题"""import randomclass Boat(object): def __init__(self, merchants, servants, capacity): self.merchants = merchants self.servants = servants self.capacity = capacity print "Initialize: [%d] merchants and [%d] servants" %(merchants, servants) '''创建允许状态集合''' def allowset(self): allowset = [] for i in range(self.merchants + 1): for j in range(self.servants + 1): if i == 0: allowset.append([i,j]) elif i == self.merchants: allowset.append([i,j]) elif (i &gt;= j and ((self.merchants-i) &gt;= (self.servants-j))): allowset.append([i,j]) return allowset '''创建允许决策集合''' def allowaction(self): allowactionset = [] for i in range(self.capacity + 1): for j in range(self.capacity + 1): if (i+j) &lt;= self.capacity and (i + j) != 0: allowactionset.append([i,j]) return allowactionset '''渡河''' def solve(self,allowactionset,allowstate): count = 1; current = (self.merchants,self.servants) while current != [0,0]: move = allowactionset[random.randint(0,len(allowactionset)-1)] temp = [current[0]+((-1)**count)*move[0],current[1]+((-1)**count)*move[1]] if(temp in allowstate): current = [current[0]+((-1)**count)*move[0],current[1]+((-1)**count)*move[1]] if(count % 2 == 1): print "[%d]个商人，[%d] 个随从从此岸划到对岸" %(move[0],move[1]) elif(count % 2 == 0): print "[%d]个商人，[%d] 个随从从对岸划回此岸" %(move[0],move[1]) count = count + 1'''主方法''' def main(): boat = Boat(3,3,2) allowstate = boat.allowset() print "允许状态集合为：" print allowstate actionset = boat.allowaction() print "允许决策集合为：" print actionset boat.solve(actionset,allowstate)if __name__ == '__main__': main() ###运行结果 为了缩短运行结果的篇幅，我们同样采取小规模问题来验证算法的正确性，这里还是采用原问题规模，运行结果如下： 12345678910Initialize: [3] merchants and [3] servants允许状态集合为：[[0, 0], [0, 1], [0, 2], [0, 3], [1, 1], [2, 2], [3, 0], [3, 1], [3, 2], [3, 3]]允许决策集合为：[[0, 1], [0, 2], [1, 0], [1, 1], [2, 0]][1]个商人，[1] 个随从从此岸划到对岸[2]个商人，[0] 个随从从此岸划到对岸[2]个商人，[0] 个随从从对岸划回此岸[2]个商人，[0] 个随从从此岸划到对岸[0]个商人，[2] 个随从从此岸划到对岸 ###算法评价 该算法可以解决问题，但是有很多的不足，首先，由此算法得到的结果是随机的，它只是一个可行解，并不是最优解，并且其中很可能存在重复的步骤，对于一些超大规模的问题，它会产生许多重复的计算，其中会存在许多重复与环，还有许多可以改进的方法。这里我提出一种改进方法的思路，留待思考：我们可以借助图论中的深度优先算法来改进该问题从而得到最优解。如果不一定需要最优解的话，我们还可以在该算法上应用一个队列的数据结构，记录曾经在当前状态采取的策略，从而避免采取重复决策。 #参考资料 数学模型(第4版) - 姜启源 叶金星（编著） Python Cookbook(第3版) 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <categories>
        <category>数学模型</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>数学</tag>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【数学模型】椅子能在不平的地面上放平吗？（1）]]></title>
    <url>%2F2016%2F01%2F03%2F%E3%80%90%E6%95%B0%E5%AD%A6%E6%A8%A1%E5%9E%8B%E3%80%91%E6%A4%85%E5%AD%90%E8%83%BD%E5%9C%A8%E4%B8%8D%E5%B9%B3%E7%9A%84%E5%9C%B0%E9%9D%A2%E4%B8%8A%E6%94%BE%E5%B9%B3%E5%90%97%EF%BC%9F%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[近期对数学爆发出了浓厚的兴趣，再加上准备参加2016年的数学建模美赛，于是开始接触数学建模，想通过这一系列的博客记录自己学习的历程，于是将本系列博客命名为【数学模型】，同我所看的数学建模书名。第一篇文章是一个非常简单的数学模型，但是我觉得挺有意思的，而且很贴近生活，题目叫做《椅子能在不平的地面上放平吗？》 模型假设为了简化该问题，抛开一些非主干的问题，我们需要对问题做一些假设： 假设椅子的四条腿一样长，椅子腿与地面接触处抽象为一个点 椅子腿的四个点所构成的平面图形为正方形 地面高度是连续变化的，可以看做一个连续曲面 地面是相对椅子平坦的，在任何时候椅子至少要能有三条腿着地（地面不会出现深沟或者凸峰） #建立模型 首先，我们需要用数学语言来描述椅子的位置，因为我们假定椅子为正方形，我们可以通过以下图形来表示椅子的位置 如图，我们用椅子腿对角线 AC 与 x 轴的夹角 θ 来表示椅子的位置 其次，我们需要用数学语言来描述椅子腿距地面的距离，由于正方形的中心对称性，我们只需要设两个距离函数： A,C 两脚距离地面的距离和 f(θ) B,D 两脚距离地面的距离和 g(θ) 我们看到这两个函数都是关于椅子位置（θ）的函数，并且根据我们之前的假设3，我们可以知道这两个函数都是连续函数。 根据假设4（在任何时候椅子至少要能有三条腿着地），我们就可以得到，对于任意的 夹角 θ ，f(x) 与 g(x) 至少有一个为0，我们假设 g(x) = 0， f(x) &gt; 0,由于正方形的中心对称性，当椅子转动90度后，于是 f(π/2) = 0， g(π/2) &gt; 0 因此我们就把问题抽象为了一个数学命题，用数学语言描述如下： 已知 f(x) 和 g(x) 是关于 θ 的连续函数，对于任意的 θ ，f(x) * g(x) = 0 ,且 g(0) = f(π/2) = 0, f(0) &gt; 0 , g(π/2) &gt; 0 。证明：存在一个角度θ0，使得f(θ0) = g(θ0) = 0 模型求解对于以上抽象出的问题就已经很简单了，只要我们证明出了以上命题就可以得到最后问题的答案。 我们试着证明一下上面的命题，其实根据命题我们就知道根据很简单的微积分中连续函数的基本性质就可以证明出来 证明: 令h(θ) = f(θ) - g(θ),则 h(0) &gt; 0 h(π/2) &lt; 0,由于 f(x) 和 g(x) 的连续性可知 h(x) 同样也是连续函数。根据连续函数基本性质，我们可以得到必存在 θ0（0 &lt; θ0 &lt; π/2）使h(θ0) = 0,即f(θ0) = g(θ0),最后，因为f(x) * g(x) = 0,得到f(θ0) = g(θ0) = 0 最终我们得到的结论是，在我们的假设的条件下，椅子能在不平的地面上放平。 #延伸 在我们的假设中我们提到了，假设椅子腿的四个点所构成的平面图形为正方形，如果为长方形呢？还能不能证明出来呢？这个问题留给读者们思考一下，下篇文章我会用比较短的篇幅对变化后的问题做一下求解。 #参考资料 数学模型(第4版) - 姜启源 叶金星（编著） 大学数学教程:微积分1 - 高等教育出版社 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <categories>
        <category>数学模型</category>
      </categories>
      <tags>
        <tag>数学</tag>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从头开始写操作系统系列】页表以及相关的描述符详解]]></title>
    <url>%2F2015%2F12%2F26%2F%E3%80%90%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%B3%BB%E5%88%97%E3%80%91%E9%A1%B5%E8%A1%A8%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E7%9A%84%E6%8F%8F%E8%BF%B0%E7%AC%A6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[在之前的文章中，我们介绍过 GDT（全局描述符表）以及一致代码段和非一致代码段，这篇文章我们再回到描述符，这次我们来以 ARM 架构为例了解一下页表描述符。 在这篇文章中，我们会看到以下内容： 页表是什么？ 一级页表的地址变换过程 由一级描述符来获取二级描述符或者段地址的过程 页表页表是什么？页表是一种特殊的数据结构，放在系统空间的页表区，存放逻辑页与物理页帧的对应关系。 每一个进程都拥有一个自己的页表，PCB表中有指针指向页表。（来自百度百科） 通俗的来讲，页表的内容就是一个描述符（关于描述符的介绍请参看该系列文章中的《实现一个 GDT》），我们可以将 GDT 理解成为一个一级描述符表，将 LDT 理解为一个二级描述符表。这篇文章我将以 ARM 体系结构为例，介绍一级页表的地址变换过程以及根据一级页表的类型来获取二级描述符表或者段的物理地址。 MMU 中的地址变换ARM 系统中的虚拟空间到物理存储空间的映射是以内存块为单位进行的，即虚拟内存中的一块连续的空间被映射到物理存储空间一段连续的地址空间。 ARM 支持以下几种大小的存储块： 段(Section):大小为1MB 大页(Large Pages):大小为64KB 小页(Small Pages):大小为4KB 微页(Tiny Pages):大小为1KB 在页表中，每一个地址变换条目实际上记录了一个虚拟空间的存储块的基地址与物理空间存储块的对应关系，根据存储块的大小，会有多种不同的地址变换。 在 ARM 中，MMU 实现虚拟地址到物理地址的映射是通过两级页表来实现的（以段为单位的地址变换是通过一级页表实现的） ARM 中与 MMU操作相关的寄存器 寄存器 作用 C1 配置 MMU 中的一些操作 C2 保存页表的基地址 C3 设置域的访问控制属性 C4 保留 C5 内存访问失效状态指示 C6 内存访问失效时失效的地址 C8 控制与清除 TLB 内容相关操作 C10 控制与锁定 TLB 内容相关操作 #一级页表 如何获得一级页表的地址？从上表中我们可以看到 C2中保存了页表的基地址，由此，我们可以看到下图： 一级页表地址 = C2寄存器的高18位 + 虚拟地址的高22位 + 00 （共32位） 一级描述符我们得到了一级页表的地址，对应地址空间的内容就是一级描述符。 一级描述符分为以下类型： 粗粒度页表描述符 段描述符 细粒度页表描述符 从以上三幅图中我们可以看到，不同类型的描述符是由描述符的最低2位决定的，分别为： 类型 低1位 低0位 粗粒度页表描述符 0 1 段描述符 1 0 细粒度页表描述符 1 1 无效 0 0 获得二级描述符表或者段地址过程由粗粒度页表描述符获得二级描述符表 从图中我们可以清楚的看到由粗粒度描述符表得到二级描述符表地址的过程： 二级描述符表地址 = 粗粒度描述符表高22位 + 虚拟地址[19:12]位 + 00 (共32位) 由细粒度页表描述符获得二级描述符表 从图中我们可以清楚的看到由细粒度描述符表得到二级描述符表地址的过程： 二级描述符表地址 = 粗粒度描述符表高20位 + 虚拟地址[19:10]位 + 00 (共32位) 由段描述符表描述符获得段的物理地址 从图中我们可以清楚的看到由段描述符表描述符获得段的物理地址的过程： 段物理地址 = 段描述符高12位 + 虚拟地址低20位 #总结 在这篇文章中，我们加深了之前对描述符的理解，同时对描述符的作用做了更直接的解释，对于页表也进行了介绍。这篇文章中我们以 ARM 体系结构为例讲解了二级页表的工作，其实，按照同样的道理我们也可以设计出三级页表以及更多级的页表。 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <categories>
        <category>从头开始写操作系统系列</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>操作系统</tag>
        <tag>从头开始写操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ashmem 对 Android 内存分配与共享的增强]]></title>
    <url>%2F2015%2F12%2F10%2FAshmem-%E5%AF%B9-Android-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E5%85%B1%E4%BA%AB%E7%9A%84%E5%A2%9E%E5%BC%BA%2F</url>
    <content type="text"><![CDATA[Ashmem 是什么？Ashmem(Anonymous Shared Memory 匿名共享内存)，是在 Android 的内存管理中提供的一种机制。它基于mmap系统调用，不同的进程可以将同一段物理内存空间映射到各自的虚拟空间，从而实现共享。 mmap机制mmap系统调用是将一个打开的文件映射到进程的用户空间，mmap系统调用使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以像访问普通内存一样对文件进行访问，不必再调用read()，write（）等操作。 mmap 函数原型： void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); addr: 指定为文件描述符fd应被映射到的进程空间的起始地址。它通常被指定为一个空指针，这样告诉内核自己去选择起始地址。一般默认为NULL length: 是映射到调用进程地址空间中的字节数，从被映射文件开头offset个字节处开始算 prot: 负责保护内存映射区的保护。常用值是代表读写访问的PROT_READ | PROT_WRITE.当然还包括数据的执行（PROT_EXEC）、数据不可访问（PROT_NONE） flag: flags常用值有MAP_SHARED或MAP_PRIVATE这两个标志必须选一个，并可以选上MAP_FIXED。如果指定了，那么调用进程对被映射数据所做的修改只对该进程可见，而不该变其底层支撑对象。如果指定了，那么调用进程对被映射数据所作的修改对于共享该对象的所有进程都可见，而且确实改变了其底层支撑对象 fd: 参数fd为映射文件的描述符，offset为文件的起点，默认为0 offset: 偏移量 ashmem 在 mmap 上的改进ashmem通过内核驱动提供了辅助内核的内存回收算法机制(pin/unpin) 什么是pin和unpin呢? 具体来讲，就是当你使用Ashmem分配了一块内存，但是其中某些部分却不会被使用时，那么就可以将这块内存unpin掉。unpin后，内核可以将它对应的物理页面回收，以作他用。你也不用担心进程无法对unpin掉的内存进行再次访问，因为回收后的内存还可以再次被获得(通过缺页handler)，因为unpin操作并不会改变已经 mmap的地址空间。 Ashmem 的定义 我们先来看一下部分 ashmem 实现的头文件（ashmem.h） 12345678910111213141516#define ASHMEM_NAME_LEN 256//定义设备名称#define ASHMEM_NAME_DEF &quot;dev/ashmem&quot;/* 从 ASHMEM_PIN 返回的值: 判断是否要清除 */#define ASHMEM_NOT_PURGED 0#define ASHMEM_WAS_PURGED 1/*从 ASHMEM_GET_PIN_STATUS 返回的值: 是 pinned 还是 unpined */#define ASHMEM_IS_UNPINNED 0#define ASHMEM_IS_PINNED 1struct ashmem_pin &#123; __u32 offset; /* 偏移量 */ __u32 len; /* 从偏移开始的长度 */&#125;; Ashmem 是怎么实现的？下面我们开始按照 Ashmem 的实现代码来看看它是怎么样工作的（ashmem.c） 我们先来看一下两个结构体ashmem_area和ashmem_range: 12345678910111213/* * ashmem_area - anonymous shared memory area * Lifecycle: From our parent file&apos;s open() until its release() * Locking: Protected by `ashmem_mutex&apos; * Big Note: Mappings do NOT pin this structure; it dies on close() */struct ashmem_area &#123; char name[ASHMEM_FULL_NAME_LEN]; /* 用于/proc/pid/maps中的一个标识名称（可选） */ struct list_head unpinned_list; /* 所有 ashmem 共享内存区域列表 */ struct file *file; /* ashmem 支持的文件 */ size_t size; /* 区域字节大小 */ unsigned long prot_mask; /* 内存映射区的保护 */&#125;; 我们可以看到 ashmem_area 定义了一个内存共享区域，它的生命周期是从文件打开open()到它被释放release(),并且支持原子性 12345678910111213/* * ashmem_range - represents an interval of unpinned (evictable) pages * Lifecycle: From unpin to pin * Locking: Protected by `ashmem_mutex&apos; */struct ashmem_range &#123; struct list_head lru; /* LRU 列表 */ struct list_head unpinned; /* unpinned 列表 */ struct ashmem_area *asma; /* 关联的 ashmem 区域 */ size_t pgstart; /* 开始页面 */ size_t pgend; /* 结束页面 */ unsigned int purged; /* 是否要被回收 */&#125;; 我们看到ashmem_range的生命周期是从 unpin 到 pin 初始化 - ashmem_init(void)1234567891011121314151617181920212223242526272829303132static int __init ashmem_init(void)&#123; int ret; ashmem_area_cachep = kmem_cache_create(&quot;ashmem_area_cache&quot;, sizeof(struct ashmem_area), 0, 0, NULL); if (unlikely(!ashmem_area_cachep)) &#123; pr_err(&quot;failed to create slab cache\n&quot;); return -ENOMEM; &#125; ashmem_range_cachep = kmem_cache_create(&quot;ashmem_range_cache&quot;, sizeof(struct ashmem_range), 0, 0, NULL); if (unlikely(!ashmem_range_cachep)) &#123; pr_err(&quot;failed to create slab cache\n&quot;); return -ENOMEM; &#125; ret = misc_register(&amp;ashmem_misc); if (unlikely(ret)) &#123; pr_err(&quot;failed to register misc device!\n&quot;); return ret; &#125; register_shrinker(&amp;ashmem_shrinker); pr_info(&quot;initialized\n&quot;); return 0;&#125; 我们从代码中可以看到初始化函数ashmem_init(void)主要做了以下几件事： 通过kmem_cache_create[^1]创建 ahemem_area 高速缓存 通过kmem_cache_create创建 ahemem_range 高速缓存 通过misc_register将 Ashmem 注册为 misc 设备[^2] 通过register_shrinker注册回收函数 退出 - ashmem_exit(void)123456789101112131415static void __exit ashmem_exit(void)&#123; int ret; unregister_shrinker(&amp;ashmem_shrinker); ret = misc_deregister(&amp;ashmem_misc); if (unlikely(ret)) pr_err(&quot;failed to unregister misc device!\n&quot;); kmem_cache_destroy(ashmem_range_cachep); kmem_cache_destroy(ashmem_area_cachep); pr_info(&quot;unloaded\n&quot;);&#125; 我们在代码中看到了所有在退出时所做的操作： 卸载回收函数unregister_shrinker 卸载设备misc_deregister 回收两段高速缓存（ashmem_area &amp; ashmem_range）kmem_cache_destroy 对内存进行分配、释放和回收我们先看看Ashmem分配内存的流程： 打开“/dev/ashmem”文件 通过ioctl来设置名称和大小等 调用mmap将Ashmem分配的空间映射到进程空间 打开多少次/dev/ashmem设备并mmap，就会获得多少个不同的空间 我们在初始化Ashmem时注册了Ashmem设备，其中包含的相关方法及其作用如下面的代码所示： 123456789101112131415161718static const struct file_operations ashmem_fops = &#123; .owner = THIS_MODULE, .open = ashmem_open, .release = ashmem_release, .read = ashmem_read, .llseek = ashmem_llseek, .mmap = ashmem_mmap, .unlocked_ioctl = ashmem_ioctl,#ifdef CONFIG_COMPAT .compat_ioctl = compat_ashmem_ioctl,#endif&#125;;static struct miscdevice ashmem_misc = &#123; .minor = MISC_DYNAMIC_MINOR, .name = &quot;ashmem&quot;, .fops = &amp;ashmem_fops,&#125;; 其中，ashmem_open方法主要是对unpinned列表进行初始化，并将Ashmem分配的地址空间赋给file结构的private_data，这就排除了进程间共享的可能性。ashmem_release方法用于将指定的节点的空间从链表中删除并释放掉 ashmem_open 方法 1234567891011121314151617181920static int ashmem_open(struct inode *inode, struct file *file)&#123; struct ashmem_area *asma; int ret; ret = generic_file_open(inode, file); if (unlikely(ret)) return ret; asma = kmem_cache_zalloc(ashmem_area_cachep, GFP_KERNEL); if (unlikely(!asma)) return -ENOMEM; INIT_LIST_HEAD(&amp;asma-&gt;unpinned_list); memcpy(asma-&gt;name, ASHMEM_NAME_PREFIX, ASHMEM_NAME_PREFIX_LEN); asma-&gt;prot_mask = PROT_MASK; file-&gt;private_data = asma; return 0;&#125; ashmem_release 方法 12345678910111213141516static int ashmem_release(struct inode *ignored, struct file *file)&#123; struct ashmem_area *asma = file-&gt;private_data; struct ashmem_range *range, *next; mutex_lock(&amp;ashmem_mutex); list_for_each_entry_safe(range, next, &amp;asma-&gt;unpinned_list, unpinned) range_del(range); mutex_unlock(&amp;ashmem_mutex); if (asma-&gt;file) fput(asma-&gt;file); kmem_cache_free(ashmem_area_cachep, asma); return 0;&#125; 需要指出的是，当使用list_for_each_entry_safe(pos, n, head,member)函数时，需要调用者另外提供一个与pos同类型的指针n，在for循环中暂存pos节点的下一个节点的地址，避免因pos节点被释放而造成断链 接下来就是将分配的空间映射到进程空间。在ashmem_mmap函数中需要指出的是，它借助了Linux内核的shmem_file_setup(支撑文件)工具，使得我们不需要自己去实现这一复杂的过程。所以ashmem_mmap的整个实现过程很简单，大家可以参考它的源代码: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950static int ashmem_mmap(struct file *file, struct vm_area_struct *vma)&#123; struct ashmem_area *asma = file-&gt;private_data; int ret = 0; mutex_lock(&amp;ashmem_mutex); /* user needs to SET_SIZE before mapping */ if (unlikely(!asma-&gt;size)) &#123; ret = -EINVAL; goto out; &#125; /* requested protection bits must match our allowed protection mask */ if (unlikely((vma-&gt;vm_flags &amp; ~calc_vm_prot_bits(asma-&gt;prot_mask)) &amp; calc_vm_prot_bits(PROT_MASK))) &#123; ret = -EPERM; goto out; &#125; vma-&gt;vm_flags &amp;= ~calc_vm_may_flags(~asma-&gt;prot_mask); if (!asma-&gt;file) &#123; char *name = ASHMEM_NAME_DEF; struct file *vmfile; if (asma-&gt;name[ASHMEM_NAME_PREFIX_LEN] != &apos;\0&apos;) name = asma-&gt;name; /* ... and allocate the backing shmem file */ vmfile = shmem_file_setup(name, asma-&gt;size, vma-&gt;vm_flags); if (unlikely(IS_ERR(vmfile))) &#123; ret = PTR_ERR(vmfile); goto out; &#125; asma-&gt;file = vmfile; &#125; get_file(asma-&gt;file); if (vma-&gt;vm_flags &amp; VM_SHARED) shmem_set_file(vma, asma-&gt;file); else &#123; if (vma-&gt;vm_file) fput(vma-&gt;vm_file); vma-&gt;vm_file = asma-&gt;file; &#125;out: mutex_unlock(&amp;ashmem_mutex); return ret;&#125; 最后，我们还将分析通过ioctl来pin和unpin某一段映射的空间的实现方式。ashmem_ioctl函数的功能很多，它可以通过其参数cmd来处理不同的操作，包括设置(获取)名称和尺寸、pin/unpin以及获取pin的一些状态。最终对pin/unpin的处理会通过下面这个函数来完成： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081static int ashmem_pin(struct ashmem_area *asma, size_t pgstart, size_t pgend)&#123; struct ashmem_range *range, *next; int ret = ASHMEM_NOT_PURGED; list_for_each_entry_safe(range, next, &amp;asma-&gt;unpinned_list, unpinned) &#123; /* moved past last applicable page; we can short circuit */ if (range_before_page(range, pgstart)) break; /* * The user can ask us to pin pages that span multiple ranges, * or to pin pages that aren&apos;t even unpinned, so this is messy. * * Four cases: * 1. The requested range subsumes an existing range, so we * just remove the entire matching range. * 2. The requested range overlaps the start of an existing * range, so we just update that range. * 3. The requested range overlaps the end of an existing * range, so we just update that range. * 4. The requested range punches a hole in an existing range, * so we have to update one side of the range and then * create a new range for the other side. */ if (page_range_in_range(range, pgstart, pgend)) &#123; ret |= range-&gt;purged; /* Case #1: Easy. Just nuke the whole thing. */ if (page_range_subsumes_range(range, pgstart, pgend)) &#123; range_del(range); continue; &#125; /* Case #2: We overlap from the start, so adjust it */ if (range-&gt;pgstart &gt;= pgstart) &#123; range_shrink(range, pgend + 1, range-&gt;pgend); continue; &#125; /* Case #3: We overlap from the rear, so adjust it */ if (range-&gt;pgend &lt;= pgend) &#123; range_shrink(range, range-&gt;pgstart, pgstart-1); continue; &#125; range_alloc(asma, range, range-&gt;purged, pgend + 1, range-&gt;pgend); range_shrink(range, range-&gt;pgstart, pgstart - 1); break; &#125; &#125; return ret;&#125;static int ashmem_unpin(struct ashmem_area *asma, size_t pgstart, size_t pgend)&#123; struct ashmem_range *range, *next; unsigned int purged = ASHMEM_NOT_PURGED;restart: list_for_each_entry_safe(range, next, &amp;asma-&gt;unpinned_list, unpinned) &#123; /* short circuit: this is our insertion point */ if (range_before_page(range, pgstart)) break; if (page_range_subsumed_by_range(range, pgstart, pgend)) return 0; if (page_range_in_range(range, pgstart, pgend)) &#123; pgstart = min_t(size_t, range-&gt;pgstart, pgstart), pgend = max_t(size_t, range-&gt;pgend, pgend); purged |= range-&gt;purged; range_del(range); goto restart; &#125; &#125; return range_alloc(asma, range, purged, pgstart, pgend);&#125; 最后需要说明：回收函数cache_shrinker同样也参考了Linux内核的slab分配算法用于页面回收的回调函数。具体实现如下： 12345678910111213141516171819202122232425262728293031static int ashmem_shrink(struct shrinker *s, struct shrink_control *sc)&#123; struct ashmem_range *range, *next; /* We might recurse into filesystem code, so bail out if necessary */ if (sc-&gt;nr_to_scan &amp;&amp; !(sc-&gt;gfp_mask &amp; __GFP_FS)) return -1; if (!sc-&gt;nr_to_scan) return lru_count; if (!mutex_trylock(&amp;ashmem_mutex)) return -1; list_for_each_entry_safe(range, next, &amp;ashmem_lru_list, lru) &#123; loff_t start = range-&gt;pgstart * PAGE_SIZE; loff_t end = (range-&gt;pgend + 1) * PAGE_SIZE; range-&gt;asma-&gt;file-&gt;f_op-&gt;fallocate(range-&gt;asma-&gt;file, FALLOC_FL_PUNCH_HOLE | FALLOC_FL_KEEP_SIZE, start, end - start); range-&gt;purged = ASHMEM_WAS_PURGED; lru_del(range); sc-&gt;nr_to_scan -= range_size(range); if (sc-&gt;nr_to_scan &lt;= 0) break; &#125; mutex_unlock(&amp;ashmem_mutex); return lru_count;&#125; cache_shrinker同样先取得了ashmem_mutex，通过list_for_each_entry_safe来确保其被安全释放。该方法会被mm/vmscan.c :: shrink_slab调用，其中参数nr_to_scan表示有多少个页面对象。如果该参数为0，则表示查询所有的页面对象总数。而“gfp_mask”是一个配置，返回值为被回收之后剩下的页面数量;如果返回-1，则表示由于配置文件(gfp_mask)产生的问题，使得mutex_lock不能进行安全的死锁 本文所分析的代码为 Android 3.10 版本代码（ashmem.h^3 &amp; ashmem.c^4） [^1]:kmem_cache_create (const char *name, size_t size, size_t align, unsigned long flags,void (*ctor)(void*, struct kmem_cache *, unsigned long)) 用于创建 SLAB 高速缓存 [^2]:Minimal instruction set computer ==== 本文的版权归作者 罗远航 所有，采用 Attribution-NonCommercial 3.0 License。任何人可以进行转载、分享，但不可在未经允许的情况下用于商业用途；转载请注明出处。感谢配合！]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【人人都要学算法】网络流算法远比你想的要好玩]]></title>
    <url>%2F2015%2F11%2F17%2F%E3%80%90%E4%BA%BA%E4%BA%BA%E9%83%BD%E8%A6%81%E5%AD%A6%E7%AE%97%E6%B3%95%E3%80%91%E7%BD%91%E7%BB%9C%E6%B5%81%E7%AE%97%E6%B3%95%E8%BF%9C%E6%AF%94%E4%BD%A0%E6%83%B3%E7%9A%84%E8%A6%81%E5%A5%BD%E7%8E%A9%2F</url>
    <content type="text"><![CDATA[这个问题的由来是想起来明天将会有国足世预赛的比赛，于是今天去看了看国足目前在小组中的积分。在积分榜中，我们可以看到与中国同组的马尔代夫和不丹都已经没有了出线的机会，即使他们剩余的比赛全胜也不可能出线了。我在想，有没有一个通用的方法，可以算出各支队还有没有出现的可能。 ==== 现在我们来回归正题： 网络流(network-flows)是一种类比水流的解决问题方法，与线性规划密切相关。网络流的理论和应用在不断发展，出现了具有增益的流、多终端流、多商品流以及网络流的分解与合成等新课题。网络流的应用已遍及通讯、运输、电力、工程规划、任务分派、设备更新以及计算机辅助设计等众多领域。 其实网络流没有那么复杂，我们来用交通网示意图来举个例子： 我们来看这个交通网示意图，假设 S 为入口，T 为出口，图中的单向箭头表示从一个地方到另一个地方的可允许通过的方向，箭头上的数字表示该路线所能承载的最大的车流量（例如：a,b 两点，只能从 a 地到 b 地，并且该路线同时只能有4辆车同时通过） 我们需要解决的一个问题是如何安排好车的流量，例如现在有6辆车进入入口，我们可以如下图这样安排车的流量： 从图中我们可以看出来各个路线的最大承载量与当前的车流量，如上图的情况，我们说它是安全的。只要每一个地点它的驶入量与驶出量是相等的，我们就可以说它是安全的。另外，对于这个问题，我们会发现有的路线会是一个环（a-&gt;b-&gt;c-&gt;a）,我们暂且不考虑这个问题，我们只关注当前的交通系统是安全的，至于有的车可能一直在绕圈圈我们不会去考虑。 现在又出现了一个新的问题：现在的交通实际车流量并没有达到最大，似乎还能增大 S 点的驶入量，这时我们可以再寻找一条从 S 到 T 的路经：S-&gt;a-&gt;b-&gt;c-&gt;T。把每条路径的实际流量加1，我们会发现情况依旧是安全的，此时的驶入量为7： 现在实际交通流量达到最大了吗？这次好像没有那么容易看出来了。我们来看一下这条路经：S-&gt;b-&gt;a-&gt;c-&gt;T,我们看到这条路经并不是完全顺着我们的路线的，只有 S-&gt;b 和 c-&gt;T 是顺着路线的，b-&gt;a 和 a-&gt;c 是逆着路线的。我们把顺着的路线流量都+1，把逆着的路线流量都-1，我们得到了下面的图： 此时，我们看这个图，它依旧是安全的，并且流量增加了1，现在驶入量是8。 现在我们得到了两种方式可以增大网络流流量的方法： 从 S -&gt; T 寻找一条路径，每一条的子路径的承载量都未满，我们可以通过该路径增加流量。 从 S -&gt; T 寻找一条路径，顺着方向的路径流量能+1（未满），逆着方向的路径流量能-1（非空），我们也可以通过该路径来增大流量。 我们把这两种路径叫做增广路径 ，如果我们不能在图中找到任何增广路径，那么我们就说它以及达到了最大流量。 ==== 现在，我们想想如何用网络流的模型来解决一支队是否有夺得第一名的可能。 现在我们来假设一种比赛，共有若干支队伍，互相之间要进行多场比赛，其中的5只队伍胜负情况如下表（其中 A 为联赛第一名，E 为联赛最后一名）： TEAM 胜 负 剩余 A 75 59 28 B 72 62 28 C 69 66 27 D 60 75 27 E 49 86 27 剩余比赛的状况如下表： TEAM A B C D E A 0 3 8 7 3 B 3 0 2 7 4 C 8 2 0 0 0 D 7 7 0 0 0 E 3 4 0 0 0 我们现在考虑 E 队还有没有机会夺冠，也就是说在最好的情况下 E 能不能夺得第一名，即在剩下的比赛中 E 获得全胜。 现在我们考虑 E 如何才能夺得冠军，我们可以看到 E 还剩下27场比赛，如果它全胜的话，最后的胜局数量将会是49+27=76，那么也就是说，若使 E 保留夺冠可能，A 最多还能赢1场，B 最多还能赢4场，C 最多能赢7场，D 最多能赢16场。 现在我们来看看赛程，A、B 直接还有3场比赛，A、C 之间还有8场比赛，A、D 之间还有7场比赛，B、C 之间还有2场比赛，B、D之间还有7场比赛 我们把上述情况总结成一个网络流图： 我们来解释下这一个图： 从 S 点出发的路线表示某两只队之间的剩余比赛数，到 T 点的路线表示某队最多能赢的场数。例如，我们设置了一个 A-B 结点，然后从 S 引出一条道路指向这个结点，并将其最大流量设定为 3 ；再从这个结点出发，引出两条道路，分别指向 A 和 B ，其最大流量可以均设为 3 ，或者任意比 3 大的值（一般设为无穷大，以表示无需限制）。因而，在一个网络流中，结点 A-B 将会从源点 S 处获得最多 3 个单位的流量，并将所得的流量再分给结点 A 和结点 B 。如果把每个单位的流量理解成一个一个的胜局，那么网络流也就可以理解为这些胜局的来源和去向。类似的我们有 A-B,A-C,A-D,B-C,B-D 五个结点。因此这个图中的任意一个合法的网络流都表示一种比赛结果 因此，现在如果我们能使该图的最大流量到达27，那么我们就可以合理的安排比赛，使得每支队伍都不超过所能允许的最多生理场次。 现在图中的最大流量是26，我们看看还能不能增加一个流量，即找到一个增广路径（图中 n 表示无穷大）： 很显然，我们在图中找不到另外的增广路径了，因此该图的最大流量为26，因此，E 队不论多么努力，他们都将会与冠军无缘~]]></content>
      <categories>
        <category>人人都要学算法</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KNN 在手写识别中的应用（Java 实现）]]></title>
    <url>%2F2015%2F09%2F07%2FKNN-%E5%9C%A8%E6%89%8B%E5%86%99%E8%AF%86%E5%88%AB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%EF%BC%88Java-%E5%AE%9E%E7%8E%B0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这篇博文主要介绍了一种基于机器学习的分类方法，K-邻近（KNN），并且使用这种方法来完成了一个简单的手写数字识别系统。 #KNN 概述 ##什么是 KNN KNN（K–nearest-neighbor），即 K-邻近算法， 所谓 K 邻近，就是 K 个最近邻居的意思，说的是每个样本都可以用与它最接近的K 个邻居来表示。 ##工作原理 存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所述分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据的分类标签，一般来讲，我们只取样本集数据中前 K 个最相似的数据，最后在这 K 个数据中统计处出现次数最多的分类，最为新数据的分类。 ##算法特点 优点：精度高、对异常值不敏感、无数据输入假定 缺点：计算复杂度高、空间复杂度高 适用数据范围：数值型和标称型 ##算法流程 对未知类别属性的数据集中的每个店依次执行以下操作： 计算已知类别数据集中的点与当前点之间的距离 按照距离递增次序排列 选取与当前点距离最小的 K 个点 确定前 K 个点所在类别的出现频率 返回前 K 个点出现频率最高的类别作为当前点的预测分类 对于距离的计算，我们采用欧氏距离公式： #KNN的应用实例 - 手写识别（Java） ##简述 我们所做的手写识别是来识别简单的手写数字，数据形式是如下图的文本文件： 我们有一些样本数据，然后用一些测试数据来进行算法的测试。 对于算法源码以及数据样本，详情见：https://github.com/luoyhang003/machine-learning-in-java/tree/master/k-Nearest-Neighbour ##具体实现 代码写的比较烂，只是实现了 KNN 的算法，并没有优化，敬请见谅！ 首先我们需要将这些文本转换为向量，可以存储于数组中 123456789101112131415161718192021222324public static int[] data2Vec(String fileName)&#123; int arr[] = new int[32 * 32]; try&#123; FileReader reader = new FileReader(fileName); BufferedReader buffer = new BufferedReader(reader); for(int index = 0; index &lt; 32; index++)&#123; String str = buffer.readLine(); int length = str.length(); for(int i = 0; i &lt; length; i++)&#123; String c = str.substring(i, i + 1); arr[32*index+i] = Integer.parseInt(c); &#125; &#125; &#125;catch (FileNotFoundException e)&#123; e.printStackTrace(); &#125;catch (IOException e)&#123; e.printStackTrace(); &#125; return arr;&#125; 需要定义一个算法来计算每两个向量之间的距离 12345678910public static double calDistance(int[] a, int[] b)&#123; double result = 0.0; int temp = 0; for(int i = 0; i &lt; a.length; i++)&#123; temp += (a[i] - b[i])*(a[i] - b[i]); &#125; result = Math.sqrt(temp); return result;&#125; 然后我们就可以开始进行分类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public static int[] classify(String fileName)&#123; int result[] = new int[2]; int arr[] = data2Vec(&quot;samples/testDigits/&quot;+fileName); result[0] = Integer.parseInt(fileName.split(&quot;_&quot;)[0]); double dis[] = new double[K]; int num[] = new int[K]; for(int index = 0; index &lt; K; index++)&#123; dis[index] = 32; num[index] = -1; &#125; for(int i = 0; i &lt;= 9; i++)&#123; for(int j = 0; j &lt; 100; j++)&#123; int temp_arr[] = data2Vec(&quot;samples/trainingDigits/&quot;+i+&quot;_&quot;+j+&quot;.txt&quot;); double temp_dis = calDistance(arr, temp_arr); for(int k = 0; k &lt; K; k++)&#123; if(temp_dis &lt; dis[k])&#123; dis[k] = temp_dis; num[k] = i; break; &#125; &#125; &#125; &#125; int count[] = new int[10]; for(int i = 0; i &lt; 10; i++) count[i] = 0; for(int i = 0; i &lt; K; i++)&#123; if(num[i]!=-1) count[num[i]]++; &#125; int max = 0; for(int i = 0; i &lt; 10; i++)&#123; if(count[i]&gt;max)&#123; max = count[i]; result[1] = i; &#125; &#125; return result;&#125; 最后我们来测试一下算法 12345678910111213141516171819202122 public static void main(String args[])&#123; double right = 0; double sum = 0; for(int i = 0; i &lt; 10; i++)&#123; for(int j = 0; j &lt; 50; j++)&#123; int result[] = classify(&quot;&quot;+i+&quot;_&quot;+j+&quot;.txt&quot;); System.out.println(&quot;the classifier came back with: &quot;+result[1]+&quot; , the real answer is: &quot; +result[0]); sum++; if(result[0]==result[1]) right++; &#125; &#125; System.out.println(&quot;right:&quot;+right); System.out.println(&quot;sum:&quot;+sum); double rate = right/sum; System.out.println(&quot;the total right rate is: &quot; + rate);&#125; 得到的结果是： 123456789101112131415the classifier came back with: 0 , the real answer is: 0the classifier came back with: 0 , the real answer is: 0the classifier came back with: 0 , the real answer is: 0the classifier came back with: 0 , the real answer is: 0……the classifier came back with: 9 , the real answer is: 9the classifier came back with: 9 , the real answer is: 9the classifier came back with: 9 , the real answer is: 9the classifier came back with: 9 , the real answer is: 9the classifier came back with: 9 , the real answer is: 9right:486.0sum:500.0the total right rate is: 0.972 完整的代码与测试数据详见：https://github.com/luoyhang003/machine-learning-in-java/tree/master/k-Nearest-Neighbour 版权声明：本文为博主原创文章，未经博主允许不得转载。 文章来源：http://blog.luoyuanhang.com]]></content>
      <tags>
        <tag>技术</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从头开始写操作系统系列】一致代码段与非一致代码段]]></title>
    <url>%2F2015%2F08%2F18%2F%E3%80%90%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%B3%BB%E5%88%97%E3%80%91%E4%B8%80%E8%87%B4%E4%BB%A3%E7%A0%81%E6%AE%B5%E4%B8%8E%E9%9D%9E%E4%B8%80%E8%87%B4%E4%BB%A3%E7%A0%81%E6%AE%B5%2F</url>
    <content type="text"><![CDATA[上几篇文章，我们一直在讨论的都是 GDT 相关的一些问题，现在我们知道在系统在从实模式向保护模式跳转时，GDT 是必须要准备的结构。在介绍这一跳转之前，这篇文章我们来介绍两个概念：一致代码段和非一致代码段。 首先，我们先来看几个问题： 一致代码段和非一致代码段是什么？ 为什么要有一致代码段和非一致代码段？ 系统提供怎样的机制来使用户程序访问内核数据？ 程序如何在段与段之间跳转？ 接下来，我们将讨论上述这些问题。 #特权级 为了更好的理解之后的问题，我们先来讨论一个概念：特权级。 特权级是一种机制来保护数据和防止恶意行为，特权级分4种：0，1，2，3。0为最高特权级，4为最低。（在 Linux 中只使用了0和3） 这些特权级是通过三个标志来表示的：CPL，DPL，RPL CPL 是存放于如 CS、SS 寄存器中的，表示当前特权级 DPL 是在 GDT（全局描述符表）/LDT（局部描述符表）中的，静态的 RPL是代码中根据不同段跳转而确定，用于刷新 CPL CPL（Current Privilege Level）是表示当前执行程序的特权级，它被存放在CS 和 SS 的第0位和第1位。通常情况下，CPL等于代码的段的特权级。在遇到一致代码段时，一致代码段可以被相同或者更低特权级的代码段访问。当处理器访问一个与 CPL特权级不同的代码段时，CPL 不会改变。 DPL（Descriptor Privilege Level）表示段或者门的特权级，它被存储在段描述符或门描述符的 DPL 字段中。当当前代码段要访问一个段或门时，DPL 会和 CPL 以及段选择子或门选择子的 RPL 进行比较，根据段或门的不同类型，DPL 将会被区别对待 数据段：DPL 规定了可以访问该段的最低特权级，如果 DPL 为1，那么只有运行在CPL 为0或者1的程序才有权访问它。 非一致代码段（不使用调用门的情况下）：DPL 规定了可以访问该段的特权级，如果 DPL 为1，那么只有运行在 CPL 为1的程序才有权访问它。 调用门：DPL 规定了当前运行程序可以访问调用门的最低特权级（和数据段访问规则相同） 一致代码段和通过调用门访问的非一致代码段：DPL 规定了有权访问该段的最高特权级。例，一个一致代码段的 DPL 为2，那么运行在 CPL 为0，1的程序无权访问此段。 RPL（Request Privilege Level）：RPL 是通过选择子的第0，1位表现出来的，处理器通过检查 CPL 和 RPL来确认一个访问请求是否合法。 #一致代码段与非一致代码段 一致代码段：通俗的讲，一致代码段就是系统用来共享、提供给低特权级的程序使用调用的代码。 非一致代码段：为了避免被低特权级程序访问而被系统保护起来的代码。 ##一致代码段限制 特权级高的程序不允许访问特权级低的数据，即核心态程序不能访问用户态数据。 特权级低的程序可以访问特权级高的程序，但是特权级不会因此而改变。 ##非一致代码段限制 只允许同级之间访问 不允许不同级之间访问，核心态不能访问用户态，用户态也不能访问核心态 通常低特权值代码必须通过『门』来完成对高特权值代码的调用 ##为什么要定义一致代码段与非一致代码段？ 定义这个概念主要是为了系统安全：内核要和用户程序分开，内核一定要安全不能被用户程序干涉。但有时候用户程序也需要读取内核的某些数据。于是操作系统内核程序开辟一些可以供用用户程序访问的段，但是不允许用户程序写入数据。内核不用知道用户程序的数据，内核不用调用用户程序的数据，内核不用转移到用户程序中来。用户程序只能访问到内核的某些共享的段，我们称这些段为一致代码段。用户程序不能访问内核不共享的段。 #门描述符 ##门描述符结构 ##调用门的使用方式 ##门描述符的实现 123456789101112; 门描述符; 4个参数: ; 1.选择子：16位; 2.偏移量：32位; 3.DCount; 4.属性%macro Gate 4 dw (%2 &amp; 0FFFFh) ;取参数2的低16位填充一个 WORD dw %1 ;取参数1填充一个 WORD dw (%3 &amp; 1Fh) | ((%4 &lt;&lt; 8) &amp; 0FF00h) ; 属性 dw ((%2 &gt;&gt; 16) &amp; 0FFFFh) ; 偏移2%endmacro ; 共 8 字节 #不同特权级代码段的转移 使用 jmp 和 call 可以实现下列4种转移： 目标操作数包含目标代码段的段选择子 目标操作数指向包含目标代码段段选择子的门描述符 目标操作数指向包含目标代码段段选择子的 TTS（Task-State Stack） 目标操作数指向一个任务门，这个任务门指向包含目标代码段段选择子对 TTS 这四种方式可以分为两类：一是，通过 call 或 jmp 的直接转移，二是，通过某个描述符的间接转移 ##通过 call 和 jmp 直接转移 目标代码段 条件 CPL 变化 非一致代码段 CPL=DPLRPL&lt;=DPL 当转移到目标代码段时，CPL=DPL 一致代码段 CPL&gt;DPL，RPL 不做检查 当转移到目标代码段时，CPL 会延续下来 ##通过门描述符的转移 假设我们想由代码A转移到代码B，运用一个调用门G，即调用门G中的目标选择子指向代码B的段。实际上，这个问题主要涉及这几个元素：CPL、RPL、代码B的DPL（记做DPL_B），调用门G的DPL（记做DPL_G）。 目标代码段 call jmp 非一致代码段 CPL&lt;=DPL_GRPL&lt;=DPL_GDPL_B&lt;=CPL CPL&lt;=DPL_GRPL&lt;=DPL_GDPL_B=CPL 一致代码段 CPL&lt;=DPL_GRPL&lt;=DPL_GDPL_B&lt;=CPL CPL&lt;=DPL_GRPL&lt;=DPL_GDPL_B&lt;=CPL 通过调用门和 call 指令，可以实现低特权级到高特权级的转移，无论目标代码段是一致的还是非一致的 通过门调用和 jmp 指令，如果目标代码段是一致的，则可以实现低特权级到高特权级的转移；如果是非一致的，那么只能实现相同特权级的转移 版权声明：本文为博主原创文章，未经博主允许不得转载。 文章来源：http://blog.luoyuanhang.com]]></content>
      <categories>
        <category>从头开始写操作系统系列</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>操作系统</tag>
        <tag>从头开始写操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从头开始写操作系统系列】实现一个 GDT（3）]]></title>
    <url>%2F2015%2F08%2F11%2F%E3%80%90%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%B3%BB%E5%88%97%E3%80%91%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA-GDT%EF%BC%883%EF%BC%89%2F</url>
    <content type="text"><![CDATA[上两篇文章，【从头开始写操作系统系列】实现一个-GDT（1）、【从头开始写操作系统系列】实现一个-GDT（2），主要介绍了段描述符结构以及实现和选择子结构。这篇文章，我们结合之前所述，对 GDT 做一个总结。 #全局描述符表（GDT） 全局描述符表是在保护模式下才用到的结构。在整个系统中，全局描述符表只有一张，可以放在内存的任何位置，但是CPU必须知道它的入口地址，也就是其基地址（Base），Intel 处理器的设计者专门设计了一个寄存器用于存放该地址，叫GDTR。程序员将 GDT 设置于内存的某个位置之后，通过 lgdt 指令将其入口地址放于 GDTR 中，之后，CPU 会根据该寄存器的值来访问 GDT。 GDTR 结构如下图： #段选择子（Selector） 在上一篇文章中我们已经知道，我们是通过段描述符在段描述符表中的位置来进行访问段描述符的。段选择子就是这样的一个16位的标识符，它标识了段描述符在段描述符表中的位置。 我们来看一下段选择子的结构： 索引：表示所需要的段在 GDT 中的位置 TI：引用描述符表指示位。 TI = 0，表示从全局描述符表中读取描述符 TI = 1，表示从局部描述符表中读取描述符 RPL：请求特权级，用于特权检查，占用两位，共有4级。 说明：任务中的每一个段都有一个特权级，每当程序想要访问一个段时，要将该程序所拥有的特权级与要访问的段特权级进行比较，来决定是否能访问该段。系统规定，CPU 只能访问同一特权级或较低特权级的段。 我们来举一个例子： 将逻辑地址（21h:12345678h）转换为线性地址。 选择子（21h） SEL = 21h = 0000000000100 0 01 INDEX = 0000000000100， TI = 0， RPL = 01 表示：从 GDT 中读取第4个（0100b）描述符，特权级为01 偏移量（12345678h） 线性地址 = 12345678h + GDT 中第4个描述符的基地址（Base） #局部描述符表（LDT） 局部描述符表（LDT）在系统中可以有若干张，一个任务可以有一张。LDT 和 GDT 在本质上是相同的，LDT 嵌套在 GDT 中。LDTR 记录 LDT 的起始地址，其中的内容是一个选择子，LDTR 在程序中可以通过 lldt 指令随时改变。由于 LDT 也是一段内存，也是一个段，因此同样需要一个描述符描述它，这个描述符存在于 GDT 中，并且这个描述符也对应一个选择子，LDTR 中存放的就是这个选择子。 具体结构如图： 我们再来举一个例子： 在表LDT2中选择第三个描述符所描述的段的地址12345678h 首先，装载 LDTR 使其指向 LDT2，使用 lldt 指令将 Selector2装载至 LDTR 通过逻辑地址（SEL:OFFSET），将 SEL 的 Index = 3（选择第三个描述符），TI = 1（在 LDT 读取描述符），OFFSET = 12345678h，因此逻辑地址为：(1C:12345678h) 由 SEL 选择出相应的段描述符，段描述符中的基地址（Base）+ OFFSET 即为线性地址。 #总结 这篇文章，我们介绍了一下局部描述符表，并且复习和补充了关于 GDT 的知识。现在，我们了解了 GDT,GDT 是系统进入保护模式必备的结构。因此，接下来我们会进入保护模式的世界。后边的文章将会讨论，系统是怎么从实模式跳转到保护模式的。 版权声明：本文为博主原创文章，未经博主允许不得转载。 文章来源：http://blog.luoyuanhang.com]]></content>
      <categories>
        <category>从头开始写操作系统系列</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>操作系统</tag>
        <tag>从头开始写操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从头开始写操作系统系列】实现一个 GDT（2）]]></title>
    <url>%2F2015%2F08%2F07%2F%E3%80%90%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%B3%BB%E5%88%97%E3%80%91%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA-GDT%EF%BC%882%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在这篇文章我们将要做: 介绍选择子 实现一个选择子结构 #选择子是什么 在上篇文章中我们介绍了段描述符以及段描述符表，这篇文章我们复习一下段和段描述符以及段描述符表的功能，并且介绍一下段选择子以及段描述符表。 段（Segment）：在80X86中我们知道分段机制将内存空间分为了多个线性区域，我们把这些线性区域称为段。由于我们要将这些段区分开来，于是我们对段赋予3个属性。他们分别是段基址（Base）、段界限（Limit）、段属性（Attribute），段基址表示了一个段在线性空间中的开始地址，段界限表示段内最大偏移量，也就是说，它定义了段的大小，段属性描述了段的一些特性，包括可读可写可执行、特权级等。 段描述符（Descriptor）：在程序中我们需要定义一个数据结构来表示段，包括段基址（Base）、段界限（Limit）、段属性（Attribute）这3个属性，这个数据结构叫做 段描述符（Descriptor）。段是一个逻辑概念，段描述符是对应的数据结构。 段描述符表（Descriptor Table）：在一个程序中，不仅仅是只有一个段（段描述符），我们需要一种方法将它们组织起来，也就是说需要一个数组来保存它们，这个结构就是段描述符表。段描述符表分为两种，一种是全局描述符表（GDT），一种是局部描述符表（LDT），系统中供所有任务使用的是全局描述符表，每个任务使用的是它自己的局部描述符表。 段选择子（Selector）：我们已经知道段描述符是存储于段描述符表中的，当我们需要访问段描述符时是如何访问的呢？其实，我们是通过段描述符在段描述符表中的位置来进行访问的。段选择子就是这样的一个16位的标识符，它标识了段描述符在段描述符表中的位置。 段描述表寄存器：如何让系统知道段描述符表在什么地方呢？处理器提供了内存管理寄存器，分别是全局描述符表寄存器(GDTR)、局部描述符表寄存器(LDTR)。GDTR寄存器中用于存放全局描述符表GDT的32位线性基地址和16位的表的长度值。LDTR寄存器中用于存放局部描述符表LDT的32位线性基地址和16位的表的长度值。通过系统指令，lgdt将GDT的线性基址和长度值加载到GDTR寄存器中，lldt将LDT的线性基址和长度值加载到LDTR寄存器中。 #动手实现选择子 ##选择子结构 ##选择子的汇编实现 testgdt.asm 12345678910111213141516[SECTION .gdt]; 定义GDT数据段LABEL_GDT: Descriptor 0, 0, 0 ; 空描述符LABEL_DESC_CODE32: Descriptor 0, SegCode32Len - 1, DA_C + DA_32; 非一致代码段LABEL_DESC_VIDEO: Descriptor 0B8000h, 0ffffh, DA_DRW ; 显存首地址; GDT 结束GdtLen equ $ - LABEL_GDT ; GDT长度GdtPtr dw GdtLen - 1 ; GDT界限 dd 0 ; GDT基地址; GDT 选择子SelectorCode32 equ LABEL_DESC_CODE32 - LABEL_GDTSelectorVideo equ LABEL_DESC_VIDEO - LABEL_GDT; END of [SECTION .gdt] pm.inc 1234567891011121314151617181920212223; 描述符类型DA_32 EQU 4000h ; 32 位段; 存储段描述符类型DA_DRW EQU 92h ; 存在的可读写数据段属性值DA_C EQU 98h ; 存在的只执行代码段属性值DA_CR EQU 9Ah ; 存在的可执行可读代码段属性值DA_CCO EQU 9Ch ; 存在的只执行一致代码段属性值DA_CCOR EQU 9Eh ; 存在的可执行可读一致代码段属性值;描述符;3个参数：; 1.段基址：32位（4字节）; 2.段界限：低20位; 3.属性：12位（高字节中的低4位总是0）%macro Descriptor 3 ;定义宏Descriptor,有3个参数 dw %2 &amp; 0FFFFh ;用参数2的低16位填充一个WORD dw %1 &amp; 0FFFFh ;用参数1的低16位填充一个WORD db (%1 &gt;&gt; 16) &amp; 0FFh ;用参数1的17-25位填充一个BYTE dw ((%2 &gt;&gt; 8) &amp; 0F00h) | (%3 &amp; 0F0FFh) ;用参数2的17-21位以及参数3的1-8位和13-16位填充一个WORD dw (%1 &gt;&gt; 24) &amp; 0FFh ;用参数1的25-32位填充一个WORD%endmacro 现在选择子已经初步完成，下篇文章我们重点讲解 GDT 以及它的实现。 版权声明：本文为博主原创文章，未经博主允许不得转载。 文章来源：http://blog.luoyuanhang.com]]></content>
      <categories>
        <category>从头开始写操作系统系列</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>操作系统</tag>
        <tag>从头开始写操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从头开始写操作系统系列】实现一个 GDT（1）]]></title>
    <url>%2F2015%2F08%2F07%2F%E3%80%90%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%B3%BB%E5%88%97%E3%80%91%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA-GDT%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在这篇文章中我们完成了以下内容： 介绍 GDT 介绍段描述符 实现一个段描述符 #介绍 GDT ##GDT 是什么？ GDT（Global Descriptor Table）是一种数据结构，用来提供段式存储机制，这种机制是通过段寄存器和 GDT 中的描述符共同提供的。 在保护模式下，虽然现在的寄存器已经有32位的，但是我们依旧采用『段：偏移』的形式来寻址，只不过『段』的概念就相当于 GDT，段值仍然由16位的 cs、ds 等寄存器表示，但是这时段值仅仅是相当于一个索引，指向一个数据结构，这个数据结构就是 GDT一个表项，这个表项定义有段的起始地址、界限、属性等内容，这个表项也叫做描述符（descriptor） ##描述符结构 代码段和数据段描述符 段描述符是一个8个字节的结构体，其中包含了段基址、段界限、段属性等信息 段基址（32位）：表示物理地址 段界限（20位）：表示段的长度（并不是地址，而是字节长度） 段属性（12位）：系统、门、数据等属性 下面我们来实现这个结构体： 12345678910111213;描述符;3个参数：; 1.段基址：32位（4字节）; 2.段界限：低20位; 3.属性：12位（高字节中的低4位总是0）%macro Descriptor 3 ;定义宏Descriptor,有3个参数 dw %2 &amp; 0FFFFh ;用参数2的低16位填充一个WORD dw %1 &amp; 0FFFFh ;用参数1的低16位填充一个WORD db (%1 &gt;&gt; 16) &amp; 0FFh ;用参数1的17-25位填充一个BYTE dw ((%2 &gt;&gt; 8) &amp; 0F00h) | (%3 &amp; 0F0FFh) ;用参数2的17-21位以及参数3的1-8位和13-16位填充一个WORD db (%1 &gt;&gt; 24) &amp; 0FFh ;用参数1的25-32位填充一个BYTE%endmacro 从代码中我们可以分析出各个参数的有效位：（F为有效） 段基址：0xFFFFFFFF 段界限：0x000FFFFF 属性：0x0000F0FF 我们得到了如下图所示的结构： 下面我们来介绍每一位的作用： 第0、1字节：表示段界限 第2、3、4字节：表示段基址 第5、6字节比较复杂 第5字节（从低到高）： 0-3：TYPE，说明存储段描述符所描述的存储段的具体属性 4：S,说明描述符的类型。对于存储段描述符而言，S=1，以区别与系统段描述符和门描述符(S=0)。 5-6:DPL,表示描述符特权级(Descriptor Privilege level)，共2位。它规定了所描述段的特权级，用于特权检查，以决定对该段能否访问。 7:P,存在(Present)位。 P=1 表示描述符对地址转换是有效的，或者说该描述符所描述的段存在，即在内存中 P=0 表示描述符对地址转换无效，即该段不存在。使用该描述符进行内存访问时会引起异常。 第6字节 0-3：段界限 4：AVL，软件可利用位。80386对该位的使用未做规定，Intel公司也保证今后开发生产的处理器只要与80386兼容，就不会对该位的使用做任何定义或规定。 5：0（未定义） 6：D/B，D位是一个很特殊的位，在描述可执行段、向下扩展数据段或由SS寄存器寻址的段(通常是堆栈段)的三种描述符中的意义各不相同。 在描述可执行段的描述符中，D位决定了指令使用的地址及操作数所默认的大小 D=1表示默认情况下指令使用32位地址及32位或8位操作数，这样的代码段也称为32位代码段； D=0 表示默认情况下，使用16位地址及16位或8位操作数，这样的代码段也称为16位代码段，它与80286兼容。可以使用地址大小前缀和操作数大小前缀分别改变默认的地址或操作数的大小。 在向下扩展数据段的描述符中，D位决定段的上部边界 D=1表示段的上部界限为4G D=0表示段的上部界限为64K，这是为了与80286兼容 在描述由SS寄存器寻址的段描述符中，D位决定隐式的堆栈访问指令(如PUSH和POP指令)使用何种堆栈指针寄存器 D=1表示使用32位堆栈指针寄存器ESP； D=0表示使用16位堆栈指针寄存器SP，这与80286兼容 7:G,段界限粒度(Granularity)位 G=0 表示界限粒度为字节 G=1 表示界限粒度为4K 字节 注意，界限粒度只对段界限有效，对段基地址无效，段基地址总是以字节为单位 S 段类型 类型值（TYPE） 说明 1 数据段 0000 只读 1 数据段 0001 只读、已访问 1 数据段 0010 读/写 1 数据段 0011 读/写、已访问 1 数据段 0100 只读、向下扩展 1 数据段 0101 只读、向下扩展、已访问 1 数据段 0110 写、向下扩展 1 数据段 0111 写、向下扩展、已访问 1 代码段 1000 只执行 1 代码段 1001 只执行、已访问 1 代码段 1010 执行/读 1 代码段 1011 执行/读、已访问 1 代码段 1100 只执行、一致码段 1 代码段 1101 只执行、一致码段、已访问 1 代码段 1110 执行/读、一致码段 1 代码段 1111 执行/读、一致码段、已访问 0 系统段 0000 （未定义） 0 系统段 0001 可用286TSS 0 系统段 0010 LDT 0 系统段 0011 忙的286TSS 0 系统段 0100 286调用门 0 系统段 0101 任务门 0 系统段 0110 286中断门 0 系统段 0111 286陷阱门 0 系统段 1000 （未定义） 0 系统段 1001 可用386TSS 0 系统段 1010 （未定义） 0 系统段 1011 忙的386TSS 0 系统段 1100 386调用门 0 系统段 1101 （未定义） 0 系统段 1110 386中断门 0 系统段 1111 386陷阱门 版权声明：本文为博主原创文章，未经博主允许不得转载。 文章来源：http://blog.luoyuanhang.com]]></content>
      <categories>
        <category>从头开始写操作系统系列</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>操作系统</tag>
        <tag>从头开始写操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从头开始写操作系统系列】使用 bochs 调试操作系统]]></title>
    <url>%2F2015%2F08%2F04%2F%E3%80%90%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%B3%BB%E5%88%97%E3%80%91%E4%BD%BF%E7%94%A8-bochs-%E8%B0%83%E8%AF%95%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[在上一篇文章《环境搭建以及第一个Hello-World》中，笔者讲了如何安装 bochs 以及运行一个 helloworld 操作系统，但是使用上一篇文章中的方法安装的 bochs 是不支持调试的，下面我讲介绍如何使用源码编译的方法来安装 bochs，以及使用 bochs 来调试操作系统。 #编译安装 Bochs 下载 bochs 源码 http://sourceforge.net/projects/bochs/files/bochs/2.6.8/ 解压之后进入该目录，进行配置 sudo ./configure --enable-debugger --enable-disasm 编译安装 sudo make sudo make install 这时，bochs 就编译安装完成了，接下来我们继续使用上一篇文章中所使用的软盘映像。 #用 Bochs 调试操作系统 启动带有调试的 bochs 之后，我们会看到bochs 会进入一个选项界面，我们选择『6.Begin simulation』就可以开始调试了 ##部分 Bochs 调试指令 行为 指令 举例 在某物理地址设置断点 b addr b 0x7c00 显示当前所有断点信息 info break info break 继续执行，直至遇到断点 c c 单步执行 s s 单步执行（遇到函数跳过） n n 查看寄存器信息 info cpurfpsregcreg info cpurfpsregcre 查看堆栈 print-stack print-stack 查看内存物理地址内容 xp /nuf addr xp /40bx 0x9013e 查看线性地址内容 x /nuf addr x /40bx 0x13e 反汇编一段内存 u start end u 0x30400 0x3040d 反汇编执行的每一条指令 trace-on trace-on 每执行一条指令就打印 CPU 信息 trace-reg trace-reg 我们可以使用 help 来查看调试帮助 ##举例 采用上一篇文章中的镜像来进行调试 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;bochs:1&gt; b 0x7c00&lt;bochs:2&gt; c00000003305i[BIOS ] $Revision: 1.257 $ $Date: 2011/01/26 09:52:02 $……00014041008i[BIOS ] Booting from 0000:7c00(0) Breakpoint 1, 0x00007c00 in ?? ()Next at t=14041069(0) [0x000000007c00] 0000:7c00 (unk. ctxt): mov ax, cs ; 8cc8&lt;bochs:4&gt; x /64xb 0x7c00[bochs]:0x00007c00 &lt;bogus+ 0&gt;: 0x8c 0xc8 0x8e 0xd8 0x8e 0xc0 0xe8 0x020x00007c08 &lt;bogus+ 8&gt;: 0x00 0xeb 0xfe 0xb8 0x1e 0x7c 0x89 0xc50x00007c10 &lt;bogus+ 16&gt;: 0xb9 0x0d 0x00 0xb8 0x01 0x13 0xbb 0x0c0x00007c18 &lt;bogus+ 24&gt;: 0x00 0xb2 0x00 0xcd 0x10 0xc3 0x48 0x650x00007c20 &lt;bogus+ 32&gt;: 0x6c 0x6c 0x6f 0x2c 0x20 0x77 0x6f 0x720x00007c28 &lt;bogus+ 40&gt;: 0x6c 0x64 0x21 0x00 0x00 0x00 0x00 0x000x00007c30 &lt;bogus+ 48&gt;: 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x000x00007c38 &lt;bogus+ 56&gt;: 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00&lt;bochs:5&gt; nNext at t=14041070(0) [0x000000007c02] 0000:7c02 (unk. ctxt): mov ds, ax ; 8ed8&lt;bochs:6&gt; trace-reg onRegister-Tracing enabled for CPU0&lt;bochs:7&gt; nNext at t=14041071eax: 0x00000000 0ecx: 0x00090000 589824edx: 0x00000000 0ebx: 0x00000000 0esp: 0x0000ffd6 65494ebp: 0x00000000 0esi: 0x000e472c 935724edi: 0x0000ffac 65452eip: 0x00007c04eflags 0x00000082: id vip vif ac vm rf nt IOPL=0 of df if tf SF zf af pf cf(0) [0x000000007c04] 0000:7c04 (unk. ctxt): mov es, ax ; 8ec0&lt;bochs:8&gt; c……]]></content>
      <categories>
        <category>从头开始写操作系统系列</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>操作系统</tag>
        <tag>从头开始写操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从头开始写操作系统系列】环境搭建以及第一个Hello World]]></title>
    <url>%2F2015%2F08%2F04%2F%E3%80%90%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%B3%BB%E5%88%97%E3%80%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E4%BB%A5%E5%8F%8A%E7%AC%AC%E4%B8%80%E4%B8%AAHello-World%2F</url>
    <content type="text"><![CDATA[#写在最前 笔者在动手写此操作系统时是一名大学本科大二的学生，可能文章中会有好多地方我没有解释清楚，可能也会有许多地方出现错误，我恳请各位读者能提出质疑和纠正我的错误，谢谢！ 参考书籍： 《30天自制操作系统》川合秀实 《ORANGE’S：一个操作系统的实现》 ##开发环境 笔者采用以下开发环境 Apple Macbook Air Ubuntu 12.04 LTS(32 bit) ##读者准备 毕竟是动手写一个操作系统，对读者的要求也会相应要求高一些，对计算机编程0基础的读者还是不建议直接看这个系列的文章。希望读者能有 汇编语言、C 语言的基础，对操作系统最好有了解（推荐书籍《操作系统概念》），另外由于开发是在 Ubuntu 的环境中进行的，读者最好对 Linux 的命令、操作等比较熟悉。 #环境搭建 ##安装Bochs 等 Bochs是一个x86硬件平台的开源模拟器。它可以模拟各种硬件的配置。Bochs模拟的是整个PC平台，包括I/O设备、内存和BIOS。更为有趣的是，甚至可以不使用PC硬件来运行Bochs。事实上，它可以在任何编译运行Bochs的平台上模拟x86硬件。通过改变配置，可以指定使用的CPU(386、486或者586)，以及内存大小等。一句话，Bochs是电脑里的“PC”。根据需要，Bochs还可以模拟多台PC，此外，它甚至还有自己的电源按钮。 我们所写的操作系统就是模拟在 Bochs 来运行和调试的。 我们使用以下的命令来安装 bochs 等一些工具 sudo apt-get install vgabios bochs bochs-x bximage bochs-sdl #第一个 Hello World ##创建软盘镜像 使用bximage 命令 按照以下来进行配置 1234567891011121314151617181920212223242526272829======================================================================== bximage Disk Image Creation Tool for Bochs $Id: bximage.c,v 1.34 2009/04/14 09:45:22 sshwarts Exp $========================================================================Do you want to create a floppy disk image or a hard disk image?Please type hd or fd. [hd] fdChoose the size of floppy disk image to create, in megabytes.Please type 0.16, 0.18, 0.32, 0.36, 0.72, 1.2, 1.44, 1.68, 1.72, or 2.88. [1.44] 1.44I will create a floppy image with cyl=80 heads=2 sectors per track=18 total sectors=2880 total bytes=1474560What should I name the image?[a.img] helloworld.imgWriting: [] Done.I wrote 1474560 bytes to helloworld.img.The following line should appear in your bochsrc: floppya: image=&quot;helloworld.img&quot;, status=inserted 最终我们得到了一个名叫『helloworld.img』的文件，它就是我们创建的软盘镜像 ##操作系统源码 hello.asm 123456789101112131415161718 org 07c00h mov ax, cs mov ds, ax mov es, ax call DispStr jmp $DispStr: mov ax, Str mov bp, ax mov cx, 13 mov ax, 01301h mov bx, 000ch mov dl, 0 int 10h retStr: db &quot;Hello, world!&quot;times 510-($-$$) db 0 dw 0xaa55 下面我们来逐行分析这段汇编代码 org 07c00h 指定程序的起始地址,告诉编译器程序从这里开始 org是Origin的缩写：起始地址源。在汇编语言源程序的开始通常都用一条org伪指令来实现规定程序的起始地址。 mov ax, cs 将 cs（代码段寄存器）中的值赋值给 ax 寄存器 mov ds, ax 将 ax 中的值赋值给 ds（ 一个段寄存器） mov es, ax 将 ax 中的值赋值给 es（） call DispStr 跳转执行到 DispStr jump $ 死循环 mov ax, Str 将 Str 的首地址放入 ax mov bp, ax 将 ax 的值赋给 bp（栈底指针） mov cx, 13 将13放入 ax 寄存器 mov ax, 01301h ax 寄存器高位AH=13，低位 AL=01h mov bx, 000ch 将000ch 放入 bx 寄存器 mov dl, 0 将光标设置为0行0列 int 10h 调用10h 中断 int 10h 中断功能介绍 AH 功能 调用参数 返回参数 1 置光标类型 (CH）0―3 = 光标开始行（CL）0―3 = 光标结束行 无 2 置光标位置 BH = 页号DH = 行DL = 列 无 3 读光标位置 BH = 页号 CH = 光标开始行CL = 光标结束行DH = 行DL = 列 4 读光笔位置 AH=0 光笔未触发AH=1 光笔触发CH=象素行BX=象素列DH=字符行DL=字符列 5 显示页 AL = 显示页号 6 屏幕初始化或上卷 AL = 上卷行数AL =0全屏幕为空白BH = 卷入行属性CH = 左上角行号CL = 左上角列号DH = 右下角行号DL = 右下角列号 7 屏幕初始化或下卷 AL = 上卷行数AL =0全屏幕为空白BH = 卷入行属性CH = 左上角行号CL = 左上角列号DH = 右下角行号DL = 右下角列号 8 读光标位置的属性和字符 BH = 显示页 AH = 属性AL = 字符 9 在光标位置显示字符及其属性 BH = 显示页AL = 字符BL = 属性CX = 字符重复次数 A 在光标位置只显示字符 BH = 显示页AL = 字符CX = 字符重复次数 E 显示字符(光标前移) AL = 字符BL = 前景色 13 显示字符串 ES:BP = 串地址CX = 串长度DH， DL = 起始行列BH = 页号AL = 0，BL = 属性串：Char，char，……，charAL = 1，BL = 属性串：Char，char，……，charAL = 2串：Char，attr，……，char，attrAL = 3串：Char，attr，……，char，attr times 510-($-$$) db 0 将剩余的位置都填充为0 dw 0xaa55 结束标志 ##制作操作系统镜像 编译源码 nasm hello.asm -o hello.bin 写入软盘镜像扇区 dd if=hello.bin of=helloworld.img bs=512 count=1 conv=notrunc #运行 HelloWorld ##编写 bochs 配置文件 - bochsrc 12345678910111213141516171819202122232425262728################################################################ Configuration file for Bochs################################################################ how much memory the emulated machine will havemegs: 32# filename of ROM imagesromimage: file=/usr/share/bochs/BIOS-bochs-latestvgaromimage: file=/usr/share/vgabios/vgabios.bin# what disk images will be usedfloppya: 1_44=helloworld.img, status=inserted# choose the boot disk.boot: floppy# where do we send log messages?# log: bochsout.txt# disable the mousemouse: enabled=0# enable key mapping, using US layout as default.keyboard_mapping: enabled=1, map=/usr/share/bochs/keymaps/x11-pc-us.mapdisplay_library: sdl ##运行bochs bochs -f bochsrc 运行结果如下图：]]></content>
      <categories>
        <category>从头开始写操作系统系列</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>操作系统</tag>
        <tag>从头开始写操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分析Linux内核创建一个新进程的过程]]></title>
    <url>%2F2015%2F07%2F27%2F%E5%88%86%E6%9E%90Linux%E5%86%85%E6%A0%B8%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[##进程描述 进程描述符（task_struct） 用来描述进程的数据结构，可以理解为进程的属性。比如进程的状态、进程的标识（PID）等，都被封装在了进程描述符这个数据结构中，该数据结构被定义为task_struct 进程控制块（PCB） 是操作系统核心中一种数据结构，主要表示进程状态。 进程状态 fork() fork()在父、子进程各返回一次。在父进程中返回子进程的 pid，在子进程中返回0。 fork一个子进程的代码 123456789101112131415161718192021222324252627282930#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;int main(int argc, char * argv[])&#123; int pid; /* fork another process */ pid = fork(); if (pid &lt; 0) &#123; /* error occurred */ fprintf(stderr,&quot;Fork Failed!&quot;); exit(-1); &#125; else if (pid == 0) &#123; /* child process */ printf(&quot;This is Child Process!\n&quot;); &#125; else &#123; /* parent process */ printf(&quot;This is Parent Process!\n&quot;); /* parent will wait for the child to complete*/ wait(NULL); printf(&quot;Child Complete!\n&quot;); &#125;&#125; ##进程创建 ###大致流程 fork 通过0x80中断（系统调用）来陷入内核，由系统提供的相应系统调用来完成进程的创建。 fork.c 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//fork#ifdef __ARCH_WANT_SYS_FORKSYSCALL_DEFINE0(fork)&#123;#ifdef CONFIG_MMU return do_fork(SIGCHLD, 0, 0, NULL, NULL);#else /* can not support in nommu mode */ return -EINVAL;#endif&#125;#endif//vfork#ifdef __ARCH_WANT_SYS_VFORKSYSCALL_DEFINE0(vfork)&#123; return do_fork(CLONE_VFORK | CLONE_VM | SIGCHLD, 0, 0, NULL, NULL);&#125;#endif//clone#ifdef __ARCH_WANT_SYS_CLONE#ifdef CONFIG_CLONE_BACKWARDSSYSCALL_DEFINE5(clone, unsigned long, clone_flags, unsigned long, newsp, int __user *, parent_tidptr, int, tls_val, int __user *, child_tidptr)#elif defined(CONFIG_CLONE_BACKWARDS2)SYSCALL_DEFINE5(clone, unsigned long, newsp, unsigned long, clone_flags, int __user *, parent_tidptr, int __user *, child_tidptr, int, tls_val)#elif defined(CONFIG_CLONE_BACKWARDS3)SYSCALL_DEFINE6(clone, unsigned long, clone_flags, unsigned long, newsp, int, stack_size, int __user *, parent_tidptr, int __user *, child_tidptr, int, tls_val)#elseSYSCALL_DEFINE5(clone, unsigned long, clone_flags, unsigned long, newsp, int __user *, parent_tidptr, int __user *, child_tidptr, int, tls_val)#endif&#123; return do_fork(clone_flags, newsp, 0, parent_tidptr, child_tidptr);&#125;#endif 通过看上边的代码，我们可以清楚的看到，不论是使用 fork 还是 vfork 来创建进程，最终都是通过 do_fork() 方法来实现的。接下来我们可以追踪到 do_fork()的代码（部分代码，经过笔者的精简）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455long do_fork(unsigned long clone_flags, unsigned long stack_start, unsigned long stack_size, int __user *parent_tidptr, int __user *child_tidptr)&#123; //创建进程描述符指针 struct task_struct *p; //…… //复制进程描述符，copy_process()的返回值是一个 task_struct 指针。 p = copy_process(clone_flags, stack_start, stack_size, child_tidptr, NULL, trace); if (!IS_ERR(p)) &#123; struct completion vfork; struct pid *pid; trace_sched_process_fork(current, p); //得到新创建的进程描述符中的pid pid = get_task_pid(p, PIDTYPE_PID); nr = pid_vnr(pid); if (clone_flags &amp; CLONE_PARENT_SETTID) put_user(nr, parent_tidptr); //如果调用的 vfork()方法，初始化 vfork 完成处理信息。 if (clone_flags &amp; CLONE_VFORK) &#123; p-&gt;vfork_done = &amp;vfork; init_completion(&amp;vfork); get_task_struct(p); &#125; //将子进程加入到调度器中，为其分配 CPU，准备执行 wake_up_new_task(p); //fork 完成，子进程即将开始运行 if (unlikely(trace)) ptrace_event_pid(trace, pid); //如果是 vfork，将父进程加入至等待队列，等待子进程完成 if (clone_flags &amp; CLONE_VFORK) &#123; if (!wait_for_vfork_done(p, &amp;vfork)) ptrace_event_pid(PTRACE_EVENT_VFORK_DONE, pid); &#125; put_pid(pid); &#125; else &#123; nr = PTR_ERR(p); &#125; return nr;&#125; ###do_fork 流程 调用 copy_process 为子进程复制出一份进程信息 如果是 vfork 初始化完成处理信息 调用 wake_up_new_task 将子进程加入调度器，为之分配 CPU 如果是 vfork，父进程等待子进程完成 exec 替换自己的地址空间 ###copy_process 流程 追踪copy_process 代码（部分） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106static struct task_struct *copy_process(unsigned long clone_flags, unsigned long stack_start, unsigned long stack_size, int __user *child_tidptr, struct pid *pid, int trace)&#123; int retval; //创建进程描述符指针 struct task_struct *p; //…… //复制当前的 task_struct p = dup_task_struct(current); //…… //初始化互斥变量 rt_mutex_init_task(p); //检查进程数是否超过限制，由操作系统定义 if (atomic_read(&amp;p-&gt;real_cred-&gt;user-&gt;processes) &gt;= task_rlimit(p, RLIMIT_NPROC)) &#123; if (p-&gt;real_cred-&gt;user != INIT_USER &amp;&amp; !capable(CAP_SYS_RESOURCE) &amp;&amp; !capable(CAP_SYS_ADMIN)) goto bad_fork_free; &#125; //…… //检查进程数是否超过 max_threads 由内存大小决定 if (nr_threads &gt;= max_threads) goto bad_fork_cleanup_count; //…… //初始化自旋锁 spin_lock_init(&amp;p-&gt;alloc_lock); //初始化挂起信号 init_sigpending(&amp;p-&gt;pending); //初始化 CPU 定时器 posix_cpu_timers_init(p); //…… //初始化进程数据结构，并把进程状态设置为 TASK_RUNNING retval = sched_fork(clone_flags, p); //复制所有进程信息，包括文件系统、信号处理函数、信号、内存管理等 if (retval) goto bad_fork_cleanup_policy; retval = perf_event_init_task(p); if (retval) goto bad_fork_cleanup_policy; retval = audit_alloc(p); if (retval) goto bad_fork_cleanup_perf; /* copy all the process information */ shm_init_task(p); retval = copy_semundo(clone_flags, p); if (retval) goto bad_fork_cleanup_audit; retval = copy_files(clone_flags, p); if (retval) goto bad_fork_cleanup_semundo; retval = copy_fs(clone_flags, p); if (retval) goto bad_fork_cleanup_files; retval = copy_sighand(clone_flags, p); if (retval) goto bad_fork_cleanup_fs; retval = copy_signal(clone_flags, p); if (retval) goto bad_fork_cleanup_sighand; retval = copy_mm(clone_flags, p); if (retval) goto bad_fork_cleanup_signal; retval = copy_namespaces(clone_flags, p); if (retval) goto bad_fork_cleanup_mm; retval = copy_io(clone_flags, p); //初始化子进程内核栈 retval = copy_thread(clone_flags, stack_start, stack_size, p); //为新进程分配新的 pid if (pid != &amp;init_struct_pid) &#123; retval = -ENOMEM; pid = alloc_pid(p-&gt;nsproxy-&gt;pid_ns_for_children); if (!pid) goto bad_fork_cleanup_io; &#125; //设置子进程 pid p-&gt;pid = pid_nr(pid); //…… //返回结构体 p return p; 调用 dup_task_struct 复制当前的 task_struct 检查进程数是否超过限制 初始化自旋锁、挂起信号、CPU 定时器等 调用 sched_fork 初始化进程数据结构，并把进程状态设置为 TASK_RUNNING 复制所有进程信息，包括文件系统、信号处理函数、信号、内存管理等 调用 copy_thread 初始化子进程内核栈 为新进程分配并设置新的 pid ###dup_task_struct 流程 1234567891011121314151617181920212223242526static struct task_struct *dup_task_struct(struct task_struct *orig)&#123; struct task_struct *tsk; struct thread_info *ti; int node = tsk_fork_get_node(orig); int err; //分配一个 task_struct 节点 tsk = alloc_task_struct_node(node); if (!tsk) return NULL; //分配一个 thread_info 节点，包含进程的内核栈，ti 为栈底 ti = alloc_thread_info_node(tsk, node); if (!ti) goto free_tsk; //将栈底的值赋给新节点的栈 tsk-&gt;stack = ti; //…… return tsk;&#125; 调用alloc_task_struct_node分配一个 task_struct 节点 调用alloc_thread_info_node分配一个 thread_info 节点，其实是分配了一个thread_union联合体,将栈底返回给 ti 1234union thread_union &#123; struct thread_info thread_info; unsigned long stack[THREAD_SIZE/sizeof(long)];&#125;; 最后将栈底的值 ti 赋值给新节点的栈 最终执行完dup_task_struct之后，子进程除了tsk-&gt;stack指针不同之外，全部都一样！ ###sched_fork 流程 core.c 123456789101112131415161718int sched_fork(unsigned long clone_flags, struct task_struct *p)&#123; unsigned long flags; int cpu = get_cpu(); __sched_fork(clone_flags, p); //将子进程状态设置为 TASK_RUNNING p-&gt;state = TASK_RUNNING; //…… //为子进程分配 CPU set_task_cpu(p, cpu); put_cpu(); return 0;&#125; 我们可以看到sched_fork大致完成了两项重要工作，一是将子进程状态设置为 TASK_RUNNING，二是为其分配 CPU ###copy_thread 流程 1234567891011121314151617181920212223242526272829303132333435363738394041424344int copy_thread(unsigned long clone_flags, unsigned long sp, unsigned long arg, struct task_struct *p)&#123; //获取寄存器信息 struct pt_regs *childregs = task_pt_regs(p); struct task_struct *tsk; int err; p-&gt;thread.sp = (unsigned long) childregs; p-&gt;thread.sp0 = (unsigned long) (childregs+1); memset(p-&gt;thread.ptrace_bps, 0, sizeof(p-&gt;thread.ptrace_bps)); if (unlikely(p-&gt;flags &amp; PF_KTHREAD)) &#123; //内核线程 memset(childregs, 0, sizeof(struct pt_regs)); p-&gt;thread.ip = (unsigned long) ret_from_kernel_thread; task_user_gs(p) = __KERNEL_STACK_CANARY; childregs-&gt;ds = __USER_DS; childregs-&gt;es = __USER_DS; childregs-&gt;fs = __KERNEL_PERCPU; childregs-&gt;bx = sp; /* function */ childregs-&gt;bp = arg; childregs-&gt;orig_ax = -1; childregs-&gt;cs = __KERNEL_CS | get_kernel_rpl(); childregs-&gt;flags = X86_EFLAGS_IF | X86_EFLAGS_FIXED; p-&gt;thread.io_bitmap_ptr = NULL; return 0; &#125; //将当前寄存器信息复制给子进程 *childregs = *current_pt_regs(); //子进程 eax 置 0，因此fork 在子进程返回0 childregs-&gt;ax = 0; if (sp) childregs-&gt;sp = sp; //子进程ip 设置为ret_from_fork，因此子进程从ret_from_fork开始执行 p-&gt;thread.ip = (unsigned long) ret_from_fork; //…… return err;&#125; copy_thread 这段代码为我们解释了两个相当重要的问题！ 一是，为什么 fork 在子进程中返回0，原因是childregs-&gt;ax = 0;这段代码将子进程的 eax 赋值为0 二是，p-&gt;thread.ip = (unsigned long) ret_from_fork;将子进程的 ip 设置为 ret_form_fork 的首地址，因此子进程是从 ret_from_fork 开始执行的 ##总结 新进程的执行源于以下前提： dup_task_struct中为其分配了新的堆栈 调用了sched_fork，将其置为TASK_RUNNING copy_thread中将父进程的寄存器上下文复制给子进程，保证了父子进程的堆栈信息是一致的 将ret_from_fork的地址设置为eip寄存器的值 最终子进程从ret_from_fork开始执行]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Linux内核</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用 Arduino Uno 给 Arduino Mini（Pro）烧录程序]]></title>
    <url>%2F2015%2F07%2F24%2F%E7%94%A8-Arduino-Uno-%E7%BB%99-Arduino-Mini%EF%BC%88Pro%EF%BC%89%E7%83%A7%E5%BD%95%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[##准备 Arduino Uno Arduino Mini（Pro） 杜邦线若干 ##接线 首先去掉 Arduino 上的芯片ATMEGA328P 接线 Uno —– Mini0(RX) – 0(RX)1(TX) – 1(TX)VCC —- VCCGND —- GNDRESET – RST ##刷入程序 ###将 Arduino 连接至计算机 在 工具 -&gt; 板 中找到所对应的 Arduino 板子（Arduino Pro or Pro Mini） 在 工具 -&gt; 端口中找到 A4对弄对应端口（Mac 上是/dev/tty.usbmodem 或 /dev/tty.usbserial） ###输入示例 Sketch（blink） 文件 -&gt; 示例 -&gt; 01.Basic -&gt; Blink 然后在 IDE 中点击 『上传』 完成上传后，Arduino Mini(Pro) 灯开始闪烁 版权声明：本文为博主原创文章，未经博主允许不得转载。 文章来源：http://blog.luoyuanhang.com]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Arduino</tag>
        <tag>嵌入式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Arduino初探：让 Arduino 闪起来]]></title>
    <url>%2F2015%2F07%2F24%2FArduino%E5%88%9D%E6%8E%A2%EF%BC%9A%E8%AE%A9-Arduino-%E9%97%AA%E8%B5%B7%E6%9D%A5%2F</url>
    <content type="text"><![CDATA[准备： 一台电脑（笔者使用的是 Mac） Arduino（笔者使用的是 Arduino UNO） ##安装 Arduino IDE 在官网（www.arduino.cc）下载相应的 IDE，解压并安装。 打开IDE。 ##将 Arduino 连接至计算机 在 Mac 上会自动安装好驱动。 在 工具 -&gt; 板 中找到所对应的 Arduino 板子（笔者的是：Arduino UNO） 在 工具 -&gt; 端口中找到 A4对弄对应端口（Mac 上是/dev/tty.usbmodem 或 /dev/tty.usbserial） ##输入示例 Sketch（blink） 文件 -&gt; 示例 -&gt; 01.Basic -&gt; Blink 然后在 IDE 中点击 『上传』 完成上传后，Arduino 灯开始闪烁 ##分析 Blink 代码 1234567891011121314// the setup function runs once when you press reset or power the boardvoid setup() &#123; // initialize digital pin 13 as an output. pinMode(13, OUTPUT);&#125;// the loop function runs over and over again forevervoid loop() &#123; digitalWrite(13, HIGH); // turn the LED on (HIGH is the voltage level) delay(1000); // wait for a second digitalWrite(13, LOW); // turn the LED off by making the voltage LOW delay(1000); // wait for a second&#125; void setup()是两个必须包含在 Arduino 程序中的函数之一，函数是一段执行特殊任务的代码。其中的代码会在每次程序启动时执行一次。 pinMode(13, OUTPUT)设置引脚的工作模式，此代码意思是将13号引脚设置为输出引脚。 void loop()第二个必要的函数，函数内的代码会在 Arduino 工作过程中重复循环执行。 digitalWrite()用于设置一个引脚的状态。 delay()该函数接受一个参数，表示延时时间，以 ms 为单位。]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Arduino</tag>
        <tag>嵌入式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分析system_call中断处理过程]]></title>
    <url>%2F2015%2F07%2F19%2F%E5%88%86%E6%9E%90system-call%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[使用gdb跟踪分析一个系统调用内核函数（以 sys_chmod为例） 启动调试内核 qemu -kernel linux-3.18.6/arch/x86/boot/bzImage -initrd rootfs.img -s -S gdb 调试 另开 shell 1234gdb(gdb) file linux-3.18.6/vmlinux #在 gdb 界面中 target remote之前加载符号表(gdb) target remote :1234 #建立连接(gdb) break start_kernel #设置断点 系统启动 设置断点 sys_chmod (gbd)b sys_chmod 执行命令 chmod 触发 gdb 中断 单步执行 (gbd) s 继续执行 (gbd) c 系统调用完成，返回 ##system_call中断处理过程图解]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Linux内核</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析 Linux 系统调用]]></title>
    <url>%2F2015%2F07%2F11%2F%E6%B5%85%E6%9E%90-Linux-%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[##用户态、内核态以及中断 具有高执行级别的程序可以执行特权指令 intel X86 CPU 具有4种级别：0 ~ 3 Linux 只用了0和3（0表示内核态，3表示用户态） 特权级的表示：使用 CS 寄存器的低2位 内核态逻辑地址空间：0xc0000000以上 用户态逻辑地址空间：0x00000000 ~ 0xbfffffff 中断是从用户态到内核态的一种方式，即通过系统调用（系统调用是一种特殊的中断） 中断过程寄存器上下文的保存 保存到什么地方？堆栈 保存的内容： 用户态栈顶地址、当时的状态字、当时的 cs:eip的值 ##系统调用概述 系统调用是操作系统为用户态进程和硬件设备交互提供的一组接口 把用户从底层编程中解放出来 提高系统安全性 提高用户程序的可移植性 API（应用编程接口） libc库定义的一些 API引用了封装例程（为了发布系统调用） 一般一个系统调用对应一个封装例程 库通过封装例程定义提供给用户的 API 不是每个 API都对应一个特定的系统调用 API 可能直接提供用户态的服务 一个 API 可能对应几个系统调用 不同的 API 可能对应一个系统调用 系统调用和 API 比较： 系统调用通过软中断向内核发出一个明确的请求 API只是一个函数定义 使用寄存器传递参数 传递一个重要的参数系统调用号：使用 eax 寄存器 每个参数长度不能超过寄存器长度 每个参数长度不能超过6个 如果超过6个？把某一个寄存器作为指针指向内存地址空间 ##实验 ###使用库 API 来完成系统调用 chmod 源代码(chmod.c) #include&lt;sys/types.h&gt; #include&lt;stdio.h&gt; #include&lt;sys/stat.h&gt; #include&lt;errno.h&gt; int main() { int i; i = chmod(&quot;file&quot;, 0777); if(i == -1) fprintf(stderr,&quot;chmod failed, errer number = %d\n&quot;,errno); else printf(&quot;chmod success !\n&quot;); return 0; } 编译&amp;执行 gcc chmod.c -o chmod -m32 ./chmod 执行结果 如果不存在 file 建立文件 file 之后，chmod 成功 ###使用汇编来完成系统调用 chmod 找到 chmod 对应的系统调用号 在 arch/x86/syscalls/syscall_32.tbl 中我们可以找到15 i386 chmod sys_chmod,由此可知，chmod 系统中断号为15（0xf） 源代码（chmod_asm.c） #include&lt;sys/types.h&gt; #include&lt;stdio.h&gt; #include&lt;sys/stat.h&gt; #include&lt;errno.h&gt; int main() { int i; char* name = &quot;file&quot;; asm volatile( &quot;mov $0777, %%ecx\n\t&quot; &quot;mov $0xf, %%eax\n\t&quot; &quot;int $0x80\n\t&quot; &quot;mov %%eax, %0\n\t&quot; :&quot;=m&quot; (i) :&quot;b&quot; (name) ); if(i == -1) fprintf(stderr,&quot;chmod failed, errer number = %d\n&quot;,errno); else printf(&quot;chmod success !\n&quot;); return 0; } 编译&amp;执行 gcc chmod_asm.c -o chmod_asm -m32 ./chmod_asm 执行结果 汇编代码分析 mov $0777, %%ecx\n\t: 将chmod参数放入 ecx 寄存器 mov $0xf, %%eax\n\t: 将系统调用号15（0xf对应 chmod）放入 eax 寄存器 int $0x80\n\t: 启动系统调用（中断号0x80） mov %%eax, %0\n\t: 将执行完 chmod 的返回值返回至 i :&quot;=m&quot; (i): i 作为输出参数 :&quot;b&quot; (name): name 作为输入参数放入 ebx 中 ###简述系统调用 chmod 的过程 首先程序触发中断 int 0x80（系统中断），然后存放于 eax 中的数值作为系统调用号，这样系统就知道对应的是哪一个系统调用，然后系统会检查参数无误后，将返回值置于 eax 中。 版权声明：本文为博主原创文章，未经博主允许不得转载。 文章来源：http://blog.luoyuanhang.com]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Linux内核</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跟踪分析Linux内核的启动过程]]></title>
    <url>%2F2015%2F07%2F10%2F%E8%B7%9F%E8%B8%AA%E5%88%86%E6%9E%90Linux%E5%86%85%E6%A0%B8%E7%9A%84%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[##使用 gdb 跟踪调试内核 使用 qemu qemu -kernel linux-3.18.6 /arch/x86/boot/bzImage -initrd rootfs.img -s -S 参数： -s：在初始化时冻结 CPU -S: 为 gdb 分配1234端口 gdb 调试 另开 shell gdb (gdb) file linux-3.18.6/vmlinux #在 gdb 界面中 target remote之前加载符号表 (gdb) target remote :1234 #建立连接 (gdb) break start_kernel #设置断点 ##从 start_kernel 开始到 init 进程启动 set_task_stack_end_magic() 为了检测栈溢出 smp_setup_processor_id（） 设置对称多处理器 cgroup_init_early () 初始化 Control Groups Control Groups provide a mechanism for aggregating/partitioning sets oftasks, and all their future children, into hierarchical groups withspecialized behaviour. page_address_init() 页地址初始化（属于内存管理部分） setup_arch() setup_arch - architecture-specific boot-time initializations build_all_zonelists() Called with zonelists_mutex held always unless system_state == SYSTEM_BOOTING. page_alloc_init () setup_log_buf () 初始化log 缓冲区（kernel/printk/printk.c） pidhash_init () 初始化 pid 哈希表 The pid hash table is scaled according to the amount of memory in the machine. From a minimum of 16 slots up to 4096 slots at one gigabyte or more. vfs_caches_init_early () sort_main_extable () Sort the kernel’s built-in exception table trap_init () 初始化中断向量 mm_init () 内存管理初始化 sched_init () 调度服务初始化 …… rest_init() 剩余初始化 + kernel_init:init进程 + kthreadd:内核线程 + cpu_idle进程：代码中一直循环，如果系统中没有可执行的进程时，执行 idle 进程 ##总结 在 start_kernel执行到最后部分时，在 rest_init 中 新建了kernel_init 进程，kernel_thread(kernel_init, NULL, CLONE_FS);，init 进程是系统中的1号进程，是以后所有用户态进程的祖先，然后新建kthreadd进程，pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES);，kthreadd 作为2号进程，是所有内核线程的祖先，在cpu_startup_entry(CPUHP_ONLINE)中，是一个 while（1）循环，始终有一个 idle 进程在执行，如果系统还总没有任何可以执行的进程时，idle 进程会执行。 最后引用孟宁老师的一段话： 道生一：（start_kernel） 一生二：(kernel_init 和 kthreadd) 二生三：（即0，1，2号进程） 三生万物：（1号进程是所有用户态进程祖先，2号进程是所有内核线程祖先）]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Linux内核</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[完成一个简单的时间片轮转多道程序内核代码]]></title>
    <url>%2F2015%2F07%2F07%2F%E5%AE%8C%E6%88%90%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%BD%AC%E5%A4%9A%E9%81%93%E7%A8%8B%E5%BA%8F%E5%86%85%E6%A0%B8%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[先上代码： myPCB.h /* * linux/mykernel/mypcb.h * * describe PCB * * by Yuanhang Luo * */ #define MAX_TASK_NUM 4 #define KERNEL_STACK_SIZE 1024*8 struct Thread{ unsigned long ip; /* save the state of ip */ unsigned long sp; /* save the state of sp */ }; typedef struct PCB{ int pid; volatile long state; char stack[KERNEL_STACK_SIZE]; struct Thread thread; unsigned long task_entry; struct PCB *next; }tPCB; void my_schedule(void); mymain.c /* * linux/mykernel/mymain.c * * Kernel internal my_start_kernel * * by Yuanhang Luo * */ #include &lt;linux/types.h&gt; #include &lt;linux/string.h&gt; #include &lt;linux/ctype.h&gt; #include &lt;linux/tty.h&gt; #include &lt;linux/vmalloc.h&gt; #include &quot;mypcb.h&quot; tPCB task[MAX_TASK_NUM]; tPCB * my_current_task = NULL; volatile int my_need_sched = 0; void my_process(void); void __init my_start_kernel(void) { int pid = 0; int i; /* Initialize process 0*/ task[pid].pid = pid; task[pid].state = 0;/* -1 unrunnable, 0 runnable, &gt;0 stopped */ task[pid].task_entry = task[pid].thread.ip = (unsigned long)my_process; task[pid].thread.sp = (unsigned long)&amp;task[pid].stack[KERNEL_STACK_SIZE-1]; task[pid].next = &amp;task[pid]; /*fork more process */ for(i=1;i&lt;MAX_TASK_NUM;i++) { memcpy(&amp;task[i],&amp;task[0],sizeof(tPCB)); task[i].pid = i; task[i].state = -1; task[i].thread.sp = (unsigned long)&amp;task[i].stack[KERNEL_STACK_SIZE-1]; task[i].next = task[i-1].next; task[i-1].next = &amp;task[i]; } /* start process 0 by task[0] */ pid = 0; my_current_task = &amp;task[pid]; asm volatile( &quot;movl %1,%%esp\n\t&quot; /* set task[pid].thread.sp to esp */ &quot;pushl %1\n\t&quot; /* push ebp */ &quot;pushl %0\n\t&quot; /* push task[pid].thread.ip */ &quot;ret\n\t&quot; /* pop task[pid].thread.ip to eip */ &quot;popl %%ebp\n\t&quot; : : &quot;c&quot; (task[pid].thread.ip),&quot;d&quot; (task[pid].thread.sp) /* input c or d mean %ecx/%edx*/ ); } void my_process(void) { int i = 0; while(1) { i++; if(i%10000000 == 0) { printk(KERN_NOTICE &quot;this is process %d -\n&quot;,my_current_task-&gt;pid); if(my_need_sched == 1) { my_need_sched = 0; my_schedule(); } printk(KERN_NOTICE &quot;this is process %d +\n&quot;,my_current_task-&gt;pid); } } } myinterrupt.c /* * linux/mykernel/myinterrupt.c * * Kernel internal my_timer_handler * * Copyright (C) 2013 Mengning * */ #include &lt;linux/types.h&gt; #include &lt;linux/string.h&gt; #include &lt;linux/ctype.h&gt; #include &lt;linux/tty.h&gt; #include &lt;linux/vmalloc.h&gt; #include &quot;mypcb.h&quot; extern tPCB task[MAX_TASK_NUM]; extern tPCB * my_current_task; extern volatile int my_need_sched; volatile int time_count = 0; /* * Called by timer interrupt. */ void my_timer_handler(void) { #if 1 if(time_count%1000 == 0 &amp;&amp; my_need_sched != 1) { printk(KERN_NOTICE &quot;&gt;&gt;&gt;my_timer_handler here&lt;&lt;&lt;\n&quot;); my_need_sched = 1; } time_count ++ ; #endif return; } void my_schedule(void) { tPCB *prev; tPCB *next; if(my_current_task == NULL || my_current_task-&gt;next == NULL) { return; } printk(KERN_NOTICE &quot;&gt;&gt;&gt;MY SCHEDULE&lt;&lt;&lt;&quot;); next = my_current_task-&gt;next; prev = my_current_task; if(next-&gt;state == 0)/* -1 unrunnable, 0 runnable, &gt;0 stopped */ { /* switch to next process */ asm volatile( &quot;pushl %%ebp\n\t&quot; /* save ebp */ &quot;movl %%esp,%0\n\t&quot; /* save esp */ &quot;movl %2,%%esp\n\t&quot; /* restore esp */ &quot;movl $1f,%1\n\t&quot; /* save eip */ &quot;pushl %3\n\t&quot; &quot;ret\n\t&quot; /* restore eip */ &quot;1:\t&quot; /* next process start here */ &quot;popl %%ebp\n\t&quot; : &quot;=m&quot; (prev-&gt;thread.sp),&quot;=m&quot; (prev-&gt;thread.ip) : &quot;m&quot; (next-&gt;thread.sp),&quot;m&quot; (next-&gt;thread.ip) ); my_current_task = next; printk(KERN_NOTICE &quot;&gt;&gt;&gt;switch %d to %d&lt;&lt;&lt;\n&quot;,prev-&gt;pid,next-&gt;pid); } else { next-&gt;state = 0; my_current_task = next; printk(KERN_NOTICE &quot;&gt;&gt;&gt;switch %d to %d&lt;&lt;&lt;\n&quot;,prev-&gt;pid,next-&gt;pid); /* switch to new process */ asm volatile( &quot;pushl %%ebp\n\t&quot; /* save ebp */ &quot;movl %%esp,%0\n\t&quot; /* save esp */ &quot;movl %2,%%esp\n\t&quot; /* restore esp */ &quot;movl %2,%%ebp\n\t&quot; /* restore ebp */ &quot;movl $1f,%1\n\t&quot; /* save eip */ &quot;pushl %3\n\t&quot; &quot;ret\n\t&quot; /* restore eip */ : &quot;=m&quot; (prev-&gt;thread.sp),&quot;=m&quot; (prev-&gt;thread.ip) : &quot;m&quot; (next-&gt;thread.sp),&quot;m&quot; (next-&gt;thread.ip) ); } return; } ##重要汇编代码分析 asm volatile( &quot;movl %1,%%esp\n\t&quot; &quot;pushl %1\n\t&quot; &quot;pushl %0\n\t&quot; &quot;ret\n\t&quot; &quot;popl %%ebp\n\t&quot; : : &quot;c&quot; (task[pid].thread.ip),&quot;d&quot; (task[pid].thread.sp) ); 保存恢复进程上下文 asm volatile( &quot;pushl %%ebp\n\t&quot; //保存当前 ebp &quot;movl %%esp,%0\n\t&quot; //保存 esp &quot;movl %2,%%esp\n\t&quot; //载入下一个进程的 esp &quot;movl $1f,%1\n\t&quot; //保存 eip &quot;pushl %3\n\t&quot; // &quot;ret\n\t&quot; //载入 eip &quot;1:\t&quot; //下一个进程开始执行 &quot;popl %%ebp\n\t&quot; // : &quot;=m&quot; (prev-&gt;thread.sp),&quot;=m&quot; (prev-&gt;thread.ip) : &quot;m&quot; (next-&gt;thread.sp),&quot;m&quot; (next-&gt;thread.ip) ); //如果没有正在运行的进程 asm volatile( &quot;pushl %%ebp\n\t&quot; //保存 ebp &quot;movl %%esp,%0\n\t&quot; //保存 esp &quot;movl %2,%%esp\n\t&quot; //载入 esp &quot;movl %2,%%ebp\n\t&quot; //载入 ebp &quot;movl $1f,%1\n\t&quot; //保存 eip &quot;pushl %3\n\t&quot; &quot;ret\n\t&quot; //载入上下文 : &quot;=m&quot; (prev-&gt;thread.sp),&quot;=m&quot; (prev-&gt;thread.ip) : &quot;m&quot; (next-&gt;thread.sp),&quot;m&quot; (next-&gt;thread.ip) ); ##举例分析：如果有三个进程 从 mymain.c 中的__init my_start_kernel方法开始执行 新建 pid=0的进程，并且将其状态设置为0（runnable），设置进程入口地址、栈地址 从0号进程复制1、2号进程，并且将0的 next 赋值为1号的入口地址，1号赋值为2号的入口地址 将0号进程赋值为当前正在执行进程（my_current_task = &amp;task[0];） 执行汇编代码：保存进程信息，开始执行0号进程 发生中断，需要切换进程 执行汇编代码：保存当前进程的ebp、esp、eip（当前进程上下文） 载入下一个进程（1号）的上下文（esp、eip） 下一个进程（1号）开始执行 再次发生中断，需要切换进程…… …… ##总结 CPU 和内核代码共同完成保存现场和恢复现场 操作系统『两把剑』 中断上下文切换 进程上下文切换]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Linux 内核</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[几种基本汇编指令详解]]></title>
    <url>%2F2015%2F07%2F07%2F%E5%87%A0%E7%A7%8D%E5%9F%BA%E6%9C%AC%E6%B1%87%E7%BC%96%E6%8C%87%E4%BB%A4%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[##常见寄存器 寄存器 16位 32位 64位 累加寄存器 AX EAX RAX 基址寄存器 BX EBX RBX 计数寄存器 CX ECX RCX 数据寄存器 DX EDX RDX 堆栈基指针 BP EBP RBP 变址寄存器 SI ESI RSI 堆栈顶指针 SP ESP RSP 指令寄存器 IP EIP RIP ##汇编指令 ##mov movb（8位）、movw（16位）、movl（32位）、movq（64位） 寄存器寻址：movl %eax, %edxeax -&gt; edx 立即数寻址：movl $0x123, %edx 数字-&gt;寄存器 直接寻址：movl 0x123, %edx直接访问内存地址数据，edx = *(int32_t *)0x123; 间接寻址：movl (%ebx), %edx%ebx 是个内存地址，(%ebx)指的是该地址中的数据，edx = *(int32_t*)ebx; 变址寻址：movl 4(%ebx), %edxedx = *(int32_t*)(ebx+4); ##push &amp; pull ###堆栈数据结构简介 ####作用: 程序调用框架 传递参数 保存返回地址 提供局部变量 …… ####结构: 相关寄存器： esp， ebp 相关操作： pop， push //建立被调用者函数的堆栈框架 pushl %ebp movl %esp, %ebp //拆除框架 movl %ebp, %esp popl %ebp ret ###push:压栈 push %eax相当于: subl $4, %esp //栈顶指针减4 movl %eax, (%esp) //%eax -&gt; esp 地址 ###pop:出栈 pop %eax相当于： movl (%esp), %eax addl %4, %esp //栈顶指针加4 ##call&amp;ret ###call call 0x12345相当于： pushl %eip movl $0x12345, %eip //当前地址压栈，存入新地址 ###ret 相当于： popl %eip //栈 -&gt; eip ##enter&amp;leave ###enter push %ebp movl %esp, %ebp //将堆栈置空（栈上重堆） ###leave movl %ebp, %esp popl %ebp //将堆栈置空（撤销堆栈） ##例子：分析一段汇编代码 pushl $8 ① movl %ebp, %esp ② subl $4, %esp ③ movl $8, (%esp) ④]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Linux内核</tag>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反汇编一个简单的C程序并分析]]></title>
    <url>%2F2015%2F07%2F03%2F%E5%8F%8D%E6%B1%87%E7%BC%96%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84C%E7%A8%8B%E5%BA%8F%E5%B9%B6%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[#反汇编一个简单的C程序并分析 C 源码： int g(int x) { return x+1; } int f(int x) { return g(x); } int main(void) { return f(2) + 3; } 汇编源码： 1 g: 2 pushl %ebp 3 movl %esp, %ebp 4 movl 8(%ebp), %eax 5 addl $1, %eax 6 popl %ebp 7 ret 8 f: 9 pushl %ebp 10 movl %esp, %ebp 11 subl $4, %esp 12 movl 8(%ebp), %eax 13 movl %eax, (%esp) 14 call g 15 leave 16 ret 17 main: 18 pushl %ebp 19 movl %esp, %ebp 20 subl $4, %esp 21 movl $2, (%esp) 22 call f 23 addl $3, %eax 24 leave 25 ret 执行过程：（从 main 开始） 原创作品转载请注明出处 http://blog.luoyuanhang.cn MOOC课程《Linux内核分析》 Created By 罗远航 &#108;&#x75;&#x6f;&#121;&#104;&#x61;&#110;&#x67;&#x30;&#48;&#x33;&#64;&#104;&#111;&#116;&#109;&#97;&#105;&#108;&#x2e;&#99;&#x6f;&#109; July 03，2015]]></content>
      <tags>
        <tag>技术</tag>
        <tag>C</tag>
        <tag>Linux内核</tag>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intel Galileo Gen 2入门]]></title>
    <url>%2F2015%2F04%2F28%2FIntel-Galileo-Gen-2%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[#Intel Galileo Gen 2入门 本文所介绍内容 Intel Galileo Gen 2简介 在Ubuntu上搭建环境 使用Arduino IDE刷入Sketch 在Galileo Gen 2中刷入定制版Linux系统 在Galileo Gen 2中刷入Debian系统 在Galileo Gen 2中编译运行OpenCV ##Intel Galileo Gen 2简介 Intel Galileo Gen 2是一款与Arduino兼容、搭载英特尔架构的开发板，相比上一代的Intel Galileo Gen相比，性能上有了很大的提升。 （图为Intel Galileo Gen 2） 特点： 采用标准USB母座作为USB Host 串口使用的是TTL电平规范 单一IO快速电平切换 可使用GUI简化Yocto开发环境定制系统 直接通过连接USB调试Shell ##第一部分：在Ubuntu上搭建环境 ###下载所需材料： Arduino IDE32位Linux：http://downloadmirror.intel.com/24783/eng/IntelArduino-1.6.0-Linux32.txz64位Linux:http://downloadmirror.intel.com/24783/eng/IntelArduino-1.6.0-Linux64.txz ###安装并启动Arduino IDE： 解压下载好的安装包 打开终端，cd至该目录下 ./arduino (可能之前还需要，sudo chmod 777 arduino) Arduino IDE已经打开 （图为Arduino IDE） ###将Intel Galileo Gen 2连接至计算机 一定要先连接电源线！！！ 然后连接USB线 ###配置Arduino IDE 注意：Arduino IDE的使用必须有Java环境 打开Arduino IDE Tools &gt; Boards &gt; Intel Galileo Gen2 Tools &gt; Ports &gt; 找到对应的端口（我的是tty.ACM0） 至此搭建环境的工作告一段落 ##第二部分：使用Arduino IDE刷入Sketch ###准备工作： 将Intel Galileo Gen 2通过USB线连接至Ubuntu 打开Arduio IDE ###搭建简单调试电路 ###将Sketch刷入开发版 打开Arduino IDE,File &gt; Demo &gt; 01.Basics &gt; Blink 之后单击Vertify &gt; Upload将Sketch刷入开发版 示例程序： 灯被点亮 我们可以看到Intel Galileo Gen 2具备有Arduino的特性 ##第三部分：在Galileo Gen 2中刷入定制版Linux系统（Yocto） ###下载系统镜像并解压至micro SD卡 下载地址：http://downloadmirror.intel.com/24355/eng/SDCard.1.0.4.tar.bz2 解压至micro SD卡，大概300多M ###从SD卡启动Intel Galileo Gen 2 将micro SD卡插入板子，接上电源 如果板子上的SD灯在闪就说明，正在从SD卡启动，整个过程需要不到一分钟 ###通过串口调试板子 ####准备材料 FT232RL串口转USB(图为FT232RL) screen命令：sudo apt-get install screen ####通过FT232连接板子和电脑 接线 Board —— FT232RL CTS ——– CTS TXO ——– RXD RXI ——– TXD RTS ——– RTS GND ——– GND 3.3V ——– VCC 给板子上电 ####开始调试 执行命令:sudo chmod 777 /dev/tty.usb0(找到你电脑上对应的设备)sudo screen /dev/tty.usb0 115200 这是你会发现终端中，会出现系统的启动信息，启动完成之后会让你登录，默认登录用户：root默认登录密码：root 至此就登录进了板子中刚刚刷入的Yocto的系统 ##第四部分：在Galileo Gen 2中刷入Debian系统 ###下载系统镜像并解压至micro SD卡 下载地址：http://downloadmirror.intel.com/24355/eng/SDCard.1.0.4.tar.bz2 解压至micro SD卡 ###从SD卡启动Intel Galileo Gen 2 将micro SD卡插入板子，接上电源 如果板子上的SD灯在闪就说明，正在从SD卡启动 ###通过串口调试板子调试过程同上 1.Debian启动 2.启动过程 3.登录系统 ##第五部分：在Galileo Gen 2中编译运行OpenCV ###准备： 将板子通过以太网口接入网线 使用FT232调试开发版 登录Debian系统 ###1.安装CmakeOpenCV需要使用Cmake生成Makefile文件，因此需要安装Cmake ####直接安装 执行apt-get install cmake ####下载安装包安装 从官网下载安装包，放入SD卡 tar zxvf [压缩包] -C /usr/local/ sudo vi /home/emouse/.bashrc 设置环境变量，在文件后添加export PATH=$PATH:/usr/local/[文件夹名]/bin ####查看版本，检查是否安装成功 cmake –version ###2.安装OpenCV ####安装libgtk2.0-dev和pkg-config 12apt-get install libgtk2.0-devapt-get install pkg-config ####下载、安装OpenCV 通过官网下载，装入SD卡并解压 cd值目录下通过config来进行配置 之后使用make和make install来进行安装 ####配置OpenCV环境变量1sudo vi /etc/ld.so.conf.d/opencv.conf 添加以下内容 1/usr/local/lib 配置库 1sudo ldconfig 更改环境变量 1sudo vi /etc/bash.bashrc 在文件后添加： 12PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/usr/local/lib/pkgconfigexport PKG_CONFIG_PATH 至此OpenCV就已经安装完成 ##之后内容： 编译用户定制Linux内核 使用Intel提供的Quark环境定制Yocto系统 ……]]></content>
      <tags>
        <tag>技术</tag>
        <tag>嵌入式</tag>
        <tag>开发板</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用ICTCLAS2015进行分词]]></title>
    <url>%2F2015%2F03%2F24%2F%E4%BD%BF%E7%94%A8ICTCLAS2015%E8%BF%9B%E8%A1%8C%E5%88%86%E8%AF%8D%2F</url>
    <content type="text"><![CDATA[#使用ICTCLAS2015进行分词 在今年的Imagine Cup中使用到了语义分析的部分，其中需要分词作为基础，我是用的是中科院的ICTCLA2015，本篇博客我来讲讲如何使用ICTCLAS2015进行分词 ##ICTCLAS2015 ###简介 中文词法分析是中文信息处理的基础与关键。中国科学院计算技术研究所在多年研究工作积累的基础上，研制出了汉语词法分析系统ICTCLAS(Institute of Computing Technology, Chinese Lexical Analysis System)，主要功能包括中文分词；词性标注；命名实体识别；新词识别；同时支持用户词典。先后精心打造五年，内核升级6次，目前已经升级到了ICTCLAS3.0。ICTCLAS3.0分词速度单机996KB/s，分词精度98.45%，API不超过200KB，各种词典数据压缩后不到3M，是当前世界上最好的汉语词法分析器。 ###下载地址 http://ictclas.nlpir.org/downloads ##使用ICTCLAS2015进行开发 ###本文所采用开发平台 操作系统：Windows 8.1 x64 开发语言：Java 开发工具：Eclipse ###开发实例 ####准备 复制Data文件夹和NLPIR.dll至开发目录 下载JNA类库， jna-platform-4.1.0.jar ####使用JNA调用C++接口 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112//定义JNA接口public interface CLibrary extends Library&#123;//建立实例CLibrary Instance = (CLibrary)Native.loadLibrary(&quot;./libs/NLPIR&quot;, CLibrary.class);//系统初始化public int NLPIR_Init(byte[] sDataPath, int encoding,byte[] sLicenceCode);//段落处理public String NLPIR_ParagraphProcess(String sSrc, int bPOSTagged);//获取关键词public String NLPIR_GetKeyWords(String sLine, int nMaxKeyLimit,boolean bWeightOut);//退出函数public void NLPIR_Exit();//文档处理public double NLPIR_FileProcess(String sSourceFilename,String sResultFilename,int bPOStagged);//引入用户自定义词典public int NLPIR_ImportUserDict(String sFilename,Boolean bOverwrite);//添加用户新词并标注词性public int NLPIR_AddUserWord(String sWords);&#125;####对一段文字进行分词，返回标注词性的分词结果/*** 对一段文字进行分词，返回标注词性的分词结果* * @param fileName* @return words* @throws Exception*/public static String[] Segment(String fileName) throws Exception&#123;//保存分词结果String result[]=&#123;&quot;&quot;,&quot;&quot;&#125;;String sourceString = &quot;&quot;;//从文件中读入文本try &#123; String encoding=&quot;UTF-8&quot;; File file=new File(fileName); if(file.isFile() &amp;&amp; file.exists())&#123; //判断文件是否存在 String temp = null; InputStreamReader read = new InputStreamReader(new FileInputStream(file),encoding); BufferedReader bufferedReader = new BufferedReader(read); while((temp = bufferedReader.readLine()) != null)&#123; sourceString += temp; &#125; read.close(); &#125;else&#123; System.out.println(&quot;找不到指定的文件&quot;); &#125;&#125; catch (Exception e) &#123;System.out.println(&quot;读取文件内容出错&quot;);e.printStackTrace();&#125;//进行分词，对NLPIR初始化String argu = &quot;&quot;;String system_charset = &quot;UTF-8&quot;;int charset_type = 1;int init_flag = CLibrary.Instance.NLPIR_Init(argu.getBytes(system_charset), charset_type, &quot;1&quot;.getBytes(system_charset));AddUserWords(&quot;dic/dic.txt&quot;);if(0 == init_flag)&#123;System.out.println(&quot;init fail!&quot;);return null;&#125;//保存分词结果String nativeBytes = null;//保存关键词String nativeByte = null;try&#123;//分词nativeBytes = CLibrary.Instance.NLPIR_ParagraphProcess(sourceString, 1);//获取关键词nativeByte = CLibrary.Instance.NLPIR_GetKeyWords(sourceString, 5, true);&#125;catch(Exception e)&#123;e.printStackTrace();&#125;result[0] = nativeBytes;result[1] = nativeByte;//返回分词结果return result;&#125;####添加用户词典并进行词性标注/*** 添加用户词典并进行词性标注* @param filePath*/public static void AddUserWords(String filePath)&#123;try&#123;String encoding = &quot;UTF-8&quot;;File file = new File(filePath);if(file.isFile()&amp;&amp;file.exists())&#123;InputStreamReader read = new InputStreamReader(new FileInputStream(file), encoding);BufferedReader bufferReader = new BufferedReader(read);String lineText = &quot;&quot;;while((lineText = bufferReader.readLine()) != null)&#123;CLibrary.Instance.NLPIR_AddUserWord(lineText);&#125;&#125;else&#123;System.out.println(&quot;未找到文件！&quot;);&#125;&#125;catch(Exception e)&#123;e.printStackTrace();&#125;&#125;]]></content>
      <tags>
        <tag>技术</tag>
        <tag>NLP</tag>
        <tag>开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的第一篇博文]]></title>
    <url>%2F2015%2F03%2F24%2F%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E6%96%87%2F</url>
    <content type="text"><![CDATA[#我的第一篇博文 我只是一个码农，却假装是程序员 之所以搭建起了属于自己的博客并给它起了个名字『罗远航1.0』，是因为我想要在这个博客上总结自己的点点滴滴，分享自己的学习经历，记录自己的生活足迹。至于为什么叫『1.0』，我想，这是一个我重新开始的起点，这会是我的又一个人生起点，也希望是我的一个人生转折点，当然这个转折点会是我再攀高峰的起点。 现在是北京时间凌晨两点多，身为码农的我还在码字，希望有一天也能和科比一样骄傲的问别人，你见过凌晨两点的山东大学软件园校区吗？我，每天都是。 Written By Yuanhang Luo Mar 24th, 2015 www.luoyuanhang.com]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
</search>
